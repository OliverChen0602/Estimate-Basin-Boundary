{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following system:\n",
    "$$\\frac{dx}{dt}=-x-y-x^{2}$$\n",
    "$$\\frac{dy}{dt}=x-y-y^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We solve for equilibrium: $(0,0)$ and (numerical approximate) $(0.83928, -1.54368)$. By linearization near the equilibrium and computing the Jacobian matrix, $(0,0)$ is a spiral sink and $(0.83928, -1.54368)$ is a saddle. We are interested to approximate the basin of attraction of $(0,0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bisection method to generate near-boundary points\n",
    "def bisection(a, b, delta=0.01): ## a has label +1 and b has label -1\n",
    "    distance = np.linalg.norm(np.array([a[0]-b[0], a[1]-b[1]]))\n",
    "    if distance < delta:\n",
    "        return (a, b)\n",
    "    else:\n",
    "        c = ((a[0]+b[0])/2, (a[1]+b[1])/2)\n",
    "        if simulation(c[0], c[1]):\n",
    "            return bisection(c, b, delta)\n",
    "        else:\n",
    "            return bisection(a, c, delta)\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    point1, point2 = np.array(point1), np.array(point2)\n",
    "    return np.sqrt(np.sum((point1 - point2) ** 2))\n",
    "\n",
    "spiral_sink = (0, 0)\n",
    "\n",
    "# Check if the trajectory is attracted to the concerned spiral attractor\n",
    "def is_attracted(x, y):\n",
    "    return euclidean_distance((x, y), spiral_sink) < 1e-5\n",
    "\n",
    "## Implement the simulation process and decide if the trajectory is attracted by the Lorenz attractor\n",
    "def simulation(x0 ,y0):\n",
    "    tmax, n = 1500, 100000\n",
    "    soln = solve_ivp(system, (0, tmax), (x0, y0),dense_output=True)\n",
    "    t = np.linspace(0, tmax, n)\n",
    "    x, y= soln.sol(t)\n",
    "    return is_attracted(x[n-1], y[n-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system(t, X):\n",
    "    x, y = X\n",
    "    xp = -x-y-x*x\n",
    "    yp = x-y-y*y\n",
    "    return xp, yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the system of equations\n",
    "Y, X = np.mgrid[-3:3:45j, -3:3:45j] \n",
    "U, V = system(0, (X, Y))\n",
    "\n",
    "# Normalize arrows\n",
    "N = np.sqrt(U**2 + V**2)\n",
    "U = U / N\n",
    "V = V / N\n",
    "\n",
    "plt.quiver(X, Y, U, V, color='r')\n",
    "\n",
    "# Highlight critical points\n",
    "plt.scatter([0, 0.83928], [0, -1.54368], color='blue', s=15) \n",
    "\n",
    "# Add axes\n",
    "plt.axhline(0, color='black',linewidth=0.5)\n",
    "plt.axvline(0, color='black',linewidth=0.5)\n",
    "\n",
    "plt.xlim([-2, 2])  # x-axis limits include negative values\n",
    "plt.ylim([-2, 2])  # y-axis limits include negative values\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training: standard logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With traditional neural network classfier, we require good initial dataset to achieve good classification result. Suppose the dataset is of poor quality, such as the size is small/all datapoints are concentrated near the attractor, the performance will decay significantly. However, with our approach of data enhancement and adaptive training, we could enhance the dataset based on in-progress training result, reducing dependence on initial dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 1000 random points for each dimension\n",
    "# X = np.random.uniform(-2, 2, 1000)\n",
    "# Y = np.random.uniform(-2, 2, 1000)\n",
    "\n",
    "# Create the dataset\n",
    "# df = pd.DataFrame(columns=['x0', 'y0', 'attracted'])\n",
    "# for i in tqdm(range(1000)):  # wrap range with tqdm for progress bar\n",
    "#    x0, y0 = X[i], Y[i]\n",
    "#    attracted_result = simulation(x0, y0)\n",
    "#    attracted_result = 1 if attracted_result else -1  # map True to 1 and False to -1\n",
    "#    df.loc[i] = [x0, y0, attracted_result]\n",
    "\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# df.to_csv('dataset_arbi2d_1000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot the sampled datapoints\n",
    "df = pd.read_csv('dataset_arbi2d_1000.csv')\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(df['x0'], df['y0'], c=df['attracted'], cmap='coolwarm', s=1)\n",
    "plt.xlabel('$x_0$')\n",
    "plt.ylabel('$y_0$')\n",
    "plt.title('Sampled datapoints')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SystemDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.data.iloc[idx, 0:2].values).float()\n",
    "        y = torch.tensor(self.data.iloc[idx, 2]).float()\n",
    "        return x, y\n",
    "    \n",
    "dataset_train = SystemDataset(\"dataset_arbi2d_1000.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the neural network. The complexity of the network is a hyperparameter.\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_bce(net, dataset_train, batchsize, epochs, lr):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batchsize, shuffle=True)\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        mini_batch_count = 0\n",
    "        for features, labels in dataloader_train:\n",
    "            labels = ((labels + 1) / 2).float()\n",
    "            labels = labels.view(-1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(features).view(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            mini_batch_count += 1\n",
    "        print('Finished training for epoch %d, loss: %.3f' % (epoch + 1, running_loss / mini_batch_count))\n",
    "    return net\n",
    "\n",
    "def test_model(net, dataset_test):\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=False)\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    probability_list = []\n",
    "    predictions_list = []\n",
    "    acc = Accuracy(task = 'binary')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in dataloader_test:\n",
    "            labels = ((labels + 1) / 2).float()\n",
    "            probability = net(features)\n",
    "            outputs = (probability > 0.5).float()\n",
    "            outputs = outputs.squeeze()\n",
    "\n",
    "            acc.update(outputs, labels)\n",
    "\n",
    "            # Move features, labels, and outputs to CPU and convert them to numpy arrays\n",
    "            features_list.append(features.numpy())\n",
    "            labels_list.append(labels.numpy())\n",
    "            probability_list.append(probability.numpy())\n",
    "            predictions_list.append(outputs.numpy())\n",
    "    accuracy = acc.compute()\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "\n",
    "    # Concatenate all batches\n",
    "    features = np.concatenate(features_list, axis=0)\n",
    "    labels = np.concatenate(labels_list, axis=0)\n",
    "    probability = np.concatenate(probability_list, axis=0)\n",
    "    predictions = np.concatenate(predictions_list, axis=0)\n",
    "\n",
    "    # Create a 2D scatter plot\n",
    "    #fig = plt.figure()\n",
    "    #ax = fig.add_subplot(111)\n",
    "\n",
    "    # Plot the features colored by the predictions\n",
    "    #scatter = ax.scatter(features[:, 0], features[:, 1], c=probability, cmap='coolwarm')\n",
    "\n",
    "    # Add a color bar\n",
    "    #plt.colorbar(scatter)\n",
    "\n",
    "    #plt.show()\n",
    "\n",
    "    #plt.hist(probability, bins=20)\n",
    "    #plt.show()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training for epoch 1, loss: 0.643\n",
      "Finished training for epoch 2, loss: 0.520\n",
      "Finished training for epoch 3, loss: 0.331\n",
      "Finished training for epoch 4, loss: 0.200\n",
      "Finished training for epoch 5, loss: 0.128\n",
      "Finished training for epoch 6, loss: 0.090\n",
      "Finished training for epoch 7, loss: 0.074\n",
      "Finished training for epoch 8, loss: 0.064\n",
      "Finished training for epoch 9, loss: 0.053\n",
      "Finished training for epoch 10, loss: 0.049\n",
      "Finished training for epoch 11, loss: 0.043\n",
      "Finished training for epoch 12, loss: 0.039\n",
      "Finished training for epoch 13, loss: 0.037\n",
      "Finished training for epoch 14, loss: 0.033\n",
      "Finished training for epoch 15, loss: 0.039\n",
      "Finished training for epoch 16, loss: 0.033\n",
      "Finished training for epoch 17, loss: 0.030\n",
      "Finished training for epoch 18, loss: 0.029\n",
      "Finished training for epoch 19, loss: 0.029\n",
      "Finished training for epoch 20, loss: 0.026\n",
      "Finished training for epoch 21, loss: 0.025\n",
      "Finished training for epoch 22, loss: 0.023\n",
      "Finished training for epoch 23, loss: 0.022\n",
      "Finished training for epoch 24, loss: 0.021\n",
      "Finished training for epoch 25, loss: 0.021\n",
      "Finished training for epoch 26, loss: 0.023\n",
      "Finished training for epoch 27, loss: 0.022\n",
      "Finished training for epoch 28, loss: 0.023\n",
      "Finished training for epoch 29, loss: 0.023\n",
      "Finished training for epoch 30, loss: 0.019\n",
      "Finished training for epoch 31, loss: 0.022\n",
      "Finished training for epoch 32, loss: 0.020\n",
      "Finished training for epoch 33, loss: 0.024\n",
      "Finished training for epoch 34, loss: 0.019\n",
      "Finished training for epoch 35, loss: 0.016\n",
      "Finished training for epoch 36, loss: 0.019\n",
      "Finished training for epoch 37, loss: 0.016\n",
      "Finished training for epoch 38, loss: 0.016\n",
      "Finished training for epoch 39, loss: 0.019\n",
      "Finished training for epoch 40, loss: 0.017\n",
      "Finished training for epoch 41, loss: 0.018\n",
      "Finished training for epoch 42, loss: 0.018\n",
      "Finished training for epoch 43, loss: 0.014\n",
      "Finished training for epoch 44, loss: 0.014\n",
      "Finished training for epoch 45, loss: 0.015\n",
      "Finished training for epoch 46, loss: 0.021\n",
      "Finished training for epoch 47, loss: 0.015\n",
      "Finished training for epoch 48, loss: 0.012\n",
      "Finished training for epoch 49, loss: 0.013\n",
      "Finished training for epoch 50, loss: 0.014\n",
      "Finished training for epoch 51, loss: 0.014\n",
      "Finished training for epoch 52, loss: 0.014\n",
      "Finished training for epoch 53, loss: 0.012\n",
      "Finished training for epoch 54, loss: 0.012\n",
      "Finished training for epoch 55, loss: 0.012\n",
      "Finished training for epoch 56, loss: 0.013\n",
      "Finished training for epoch 57, loss: 0.011\n",
      "Finished training for epoch 58, loss: 0.012\n",
      "Finished training for epoch 59, loss: 0.016\n",
      "Finished training for epoch 60, loss: 0.013\n",
      "Finished training for epoch 61, loss: 0.016\n",
      "Finished training for epoch 62, loss: 0.014\n",
      "Finished training for epoch 63, loss: 0.014\n",
      "Finished training for epoch 64, loss: 0.016\n",
      "Finished training for epoch 65, loss: 0.023\n",
      "Finished training for epoch 66, loss: 0.013\n",
      "Finished training for epoch 67, loss: 0.012\n",
      "Finished training for epoch 68, loss: 0.012\n",
      "Finished training for epoch 69, loss: 0.013\n",
      "Finished training for epoch 70, loss: 0.018\n",
      "Finished training for epoch 71, loss: 0.013\n",
      "Finished training for epoch 72, loss: 0.010\n",
      "Finished training for epoch 73, loss: 0.015\n",
      "Finished training for epoch 74, loss: 0.010\n",
      "Finished training for epoch 75, loss: 0.012\n",
      "Finished training for epoch 76, loss: 0.013\n",
      "Finished training for epoch 77, loss: 0.010\n",
      "Finished training for epoch 78, loss: 0.009\n",
      "Finished training for epoch 79, loss: 0.014\n",
      "Finished training for epoch 80, loss: 0.012\n",
      "Finished training for epoch 81, loss: 0.011\n",
      "Finished training for epoch 82, loss: 0.010\n",
      "Finished training for epoch 83, loss: 0.009\n",
      "Finished training for epoch 84, loss: 0.011\n",
      "Finished training for epoch 85, loss: 0.010\n",
      "Finished training for epoch 86, loss: 0.008\n",
      "Finished training for epoch 87, loss: 0.013\n",
      "Finished training for epoch 88, loss: 0.012\n",
      "Finished training for epoch 89, loss: 0.008\n",
      "Finished training for epoch 90, loss: 0.013\n",
      "Finished training for epoch 91, loss: 0.010\n",
      "Finished training for epoch 92, loss: 0.012\n",
      "Finished training for epoch 93, loss: 0.007\n",
      "Finished training for epoch 94, loss: 0.013\n",
      "Finished training for epoch 95, loss: 0.008\n",
      "Finished training for epoch 96, loss: 0.009\n",
      "Finished training for epoch 97, loss: 0.009\n",
      "Finished training for epoch 98, loss: 0.007\n",
      "Finished training for epoch 99, loss: 0.018\n",
      "Finished training for epoch 100, loss: 0.015\n",
      "Finished training for epoch 101, loss: 0.023\n",
      "Finished training for epoch 102, loss: 0.014\n",
      "Finished training for epoch 103, loss: 0.023\n",
      "Finished training for epoch 104, loss: 0.012\n",
      "Finished training for epoch 105, loss: 0.008\n",
      "Finished training for epoch 106, loss: 0.007\n",
      "Finished training for epoch 107, loss: 0.007\n",
      "Finished training for epoch 108, loss: 0.009\n",
      "Finished training for epoch 109, loss: 0.013\n",
      "Finished training for epoch 110, loss: 0.008\n",
      "Finished training for epoch 111, loss: 0.008\n",
      "Finished training for epoch 112, loss: 0.008\n",
      "Finished training for epoch 113, loss: 0.007\n",
      "Finished training for epoch 114, loss: 0.008\n",
      "Finished training for epoch 115, loss: 0.009\n",
      "Finished training for epoch 116, loss: 0.007\n",
      "Finished training for epoch 117, loss: 0.009\n",
      "Finished training for epoch 118, loss: 0.010\n",
      "Finished training for epoch 119, loss: 0.008\n",
      "Finished training for epoch 120, loss: 0.011\n",
      "Finished training for epoch 121, loss: 0.010\n",
      "Finished training for epoch 122, loss: 0.016\n",
      "Finished training for epoch 123, loss: 0.012\n",
      "Finished training for epoch 124, loss: 0.007\n",
      "Finished training for epoch 125, loss: 0.007\n",
      "Finished training for epoch 126, loss: 0.013\n",
      "Finished training for epoch 127, loss: 0.010\n",
      "Finished training for epoch 128, loss: 0.009\n",
      "Finished training for epoch 129, loss: 0.018\n",
      "Finished training for epoch 130, loss: 0.016\n",
      "Finished training for epoch 131, loss: 0.009\n",
      "Finished training for epoch 132, loss: 0.007\n",
      "Finished training for epoch 133, loss: 0.009\n",
      "Finished training for epoch 134, loss: 0.006\n",
      "Finished training for epoch 135, loss: 0.007\n",
      "Finished training for epoch 136, loss: 0.010\n",
      "Finished training for epoch 137, loss: 0.013\n",
      "Finished training for epoch 138, loss: 0.011\n",
      "Finished training for epoch 139, loss: 0.006\n",
      "Finished training for epoch 140, loss: 0.008\n",
      "Finished training for epoch 141, loss: 0.007\n",
      "Finished training for epoch 142, loss: 0.008\n",
      "Finished training for epoch 143, loss: 0.011\n",
      "Finished training for epoch 144, loss: 0.013\n",
      "Finished training for epoch 145, loss: 0.012\n",
      "Finished training for epoch 146, loss: 0.011\n",
      "Finished training for epoch 147, loss: 0.011\n",
      "Finished training for epoch 148, loss: 0.030\n",
      "Finished training for epoch 149, loss: 0.010\n",
      "Finished training for epoch 150, loss: 0.007\n",
      "Finished training for epoch 151, loss: 0.007\n",
      "Finished training for epoch 152, loss: 0.010\n",
      "Finished training for epoch 153, loss: 0.010\n",
      "Finished training for epoch 154, loss: 0.006\n",
      "Finished training for epoch 155, loss: 0.007\n",
      "Finished training for epoch 156, loss: 0.006\n",
      "Finished training for epoch 157, loss: 0.012\n",
      "Finished training for epoch 158, loss: 0.009\n",
      "Finished training for epoch 159, loss: 0.009\n",
      "Finished training for epoch 160, loss: 0.006\n",
      "Finished training for epoch 161, loss: 0.010\n",
      "Finished training for epoch 162, loss: 0.012\n",
      "Finished training for epoch 163, loss: 0.007\n",
      "Finished training for epoch 164, loss: 0.005\n",
      "Finished training for epoch 165, loss: 0.005\n",
      "Finished training for epoch 166, loss: 0.006\n",
      "Finished training for epoch 167, loss: 0.005\n",
      "Finished training for epoch 168, loss: 0.009\n",
      "Finished training for epoch 169, loss: 0.007\n",
      "Finished training for epoch 170, loss: 0.010\n",
      "Finished training for epoch 171, loss: 0.010\n",
      "Finished training for epoch 172, loss: 0.010\n",
      "Finished training for epoch 173, loss: 0.006\n",
      "Finished training for epoch 174, loss: 0.009\n",
      "Finished training for epoch 175, loss: 0.008\n",
      "Finished training for epoch 176, loss: 0.006\n",
      "Finished training for epoch 177, loss: 0.008\n",
      "Finished training for epoch 178, loss: 0.008\n",
      "Finished training for epoch 179, loss: 0.006\n",
      "Finished training for epoch 180, loss: 0.011\n",
      "Finished training for epoch 181, loss: 0.009\n",
      "Finished training for epoch 182, loss: 0.006\n",
      "Finished training for epoch 183, loss: 0.011\n",
      "Finished training for epoch 184, loss: 0.006\n",
      "Finished training for epoch 185, loss: 0.015\n",
      "Finished training for epoch 186, loss: 0.014\n",
      "Finished training for epoch 187, loss: 0.011\n",
      "Finished training for epoch 188, loss: 0.012\n",
      "Finished training for epoch 189, loss: 0.026\n",
      "Finished training for epoch 190, loss: 0.017\n",
      "Finished training for epoch 191, loss: 0.006\n",
      "Finished training for epoch 192, loss: 0.009\n",
      "Finished training for epoch 193, loss: 0.006\n",
      "Finished training for epoch 194, loss: 0.009\n",
      "Finished training for epoch 195, loss: 0.009\n",
      "Finished training for epoch 196, loss: 0.007\n",
      "Finished training for epoch 197, loss: 0.010\n",
      "Finished training for epoch 198, loss: 0.005\n",
      "Finished training for epoch 199, loss: 0.009\n",
      "Finished training for epoch 200, loss: 0.013\n",
      "Finished training for epoch 201, loss: 0.010\n",
      "Finished training for epoch 202, loss: 0.007\n",
      "Finished training for epoch 203, loss: 0.006\n",
      "Finished training for epoch 204, loss: 0.006\n",
      "Finished training for epoch 205, loss: 0.004\n",
      "Finished training for epoch 206, loss: 0.003\n",
      "Finished training for epoch 207, loss: 0.006\n",
      "Finished training for epoch 208, loss: 0.004\n",
      "Finished training for epoch 209, loss: 0.009\n",
      "Finished training for epoch 210, loss: 0.008\n",
      "Finished training for epoch 211, loss: 0.005\n",
      "Finished training for epoch 212, loss: 0.004\n",
      "Finished training for epoch 213, loss: 0.007\n",
      "Finished training for epoch 214, loss: 0.004\n",
      "Finished training for epoch 215, loss: 0.008\n",
      "Finished training for epoch 216, loss: 0.011\n",
      "Finished training for epoch 217, loss: 0.007\n",
      "Finished training for epoch 218, loss: 0.004\n",
      "Finished training for epoch 219, loss: 0.008\n",
      "Finished training for epoch 220, loss: 0.007\n",
      "Finished training for epoch 221, loss: 0.004\n",
      "Finished training for epoch 222, loss: 0.006\n",
      "Finished training for epoch 223, loss: 0.008\n",
      "Finished training for epoch 224, loss: 0.012\n",
      "Finished training for epoch 225, loss: 0.007\n",
      "Finished training for epoch 226, loss: 0.005\n",
      "Finished training for epoch 227, loss: 0.011\n",
      "Finished training for epoch 228, loss: 0.010\n",
      "Finished training for epoch 229, loss: 0.012\n",
      "Finished training for epoch 230, loss: 0.007\n",
      "Finished training for epoch 231, loss: 0.007\n",
      "Finished training for epoch 232, loss: 0.013\n",
      "Finished training for epoch 233, loss: 0.009\n",
      "Finished training for epoch 234, loss: 0.006\n",
      "Finished training for epoch 235, loss: 0.007\n",
      "Finished training for epoch 236, loss: 0.005\n",
      "Finished training for epoch 237, loss: 0.009\n",
      "Finished training for epoch 238, loss: 0.016\n",
      "Finished training for epoch 239, loss: 0.006\n",
      "Finished training for epoch 240, loss: 0.007\n",
      "Finished training for epoch 241, loss: 0.024\n",
      "Finished training for epoch 242, loss: 0.011\n",
      "Finished training for epoch 243, loss: 0.007\n",
      "Finished training for epoch 244, loss: 0.004\n",
      "Finished training for epoch 245, loss: 0.006\n",
      "Finished training for epoch 246, loss: 0.007\n",
      "Finished training for epoch 247, loss: 0.003\n",
      "Finished training for epoch 248, loss: 0.007\n",
      "Finished training for epoch 249, loss: 0.008\n",
      "Finished training for epoch 250, loss: 0.009\n",
      "Finished training for epoch 251, loss: 0.006\n",
      "Finished training for epoch 252, loss: 0.005\n",
      "Finished training for epoch 253, loss: 0.007\n",
      "Finished training for epoch 254, loss: 0.005\n",
      "Finished training for epoch 255, loss: 0.007\n",
      "Finished training for epoch 256, loss: 0.006\n",
      "Finished training for epoch 257, loss: 0.004\n",
      "Finished training for epoch 258, loss: 0.004\n",
      "Finished training for epoch 259, loss: 0.008\n",
      "Finished training for epoch 260, loss: 0.020\n",
      "Finished training for epoch 261, loss: 0.005\n",
      "Finished training for epoch 262, loss: 0.006\n",
      "Finished training for epoch 263, loss: 0.006\n",
      "Finished training for epoch 264, loss: 0.006\n",
      "Finished training for epoch 265, loss: 0.006\n",
      "Finished training for epoch 266, loss: 0.005\n",
      "Finished training for epoch 267, loss: 0.004\n",
      "Finished training for epoch 268, loss: 0.006\n",
      "Finished training for epoch 269, loss: 0.008\n",
      "Finished training for epoch 270, loss: 0.015\n",
      "Finished training for epoch 271, loss: 0.009\n",
      "Finished training for epoch 272, loss: 0.010\n",
      "Finished training for epoch 273, loss: 0.007\n",
      "Finished training for epoch 274, loss: 0.004\n",
      "Finished training for epoch 275, loss: 0.008\n",
      "Finished training for epoch 276, loss: 0.004\n",
      "Finished training for epoch 277, loss: 0.006\n",
      "Finished training for epoch 278, loss: 0.007\n",
      "Finished training for epoch 279, loss: 0.008\n",
      "Finished training for epoch 280, loss: 0.009\n",
      "Finished training for epoch 281, loss: 0.013\n",
      "Finished training for epoch 282, loss: 0.004\n",
      "Finished training for epoch 283, loss: 0.004\n",
      "Finished training for epoch 284, loss: 0.004\n",
      "Finished training for epoch 285, loss: 0.007\n",
      "Finished training for epoch 286, loss: 0.006\n",
      "Finished training for epoch 287, loss: 0.004\n",
      "Finished training for epoch 288, loss: 0.005\n",
      "Finished training for epoch 289, loss: 0.010\n",
      "Finished training for epoch 290, loss: 0.006\n",
      "Finished training for epoch 291, loss: 0.008\n",
      "Finished training for epoch 292, loss: 0.009\n",
      "Finished training for epoch 293, loss: 0.016\n",
      "Finished training for epoch 294, loss: 0.008\n",
      "Finished training for epoch 295, loss: 0.012\n",
      "Finished training for epoch 296, loss: 0.010\n",
      "Finished training for epoch 297, loss: 0.004\n",
      "Finished training for epoch 298, loss: 0.005\n",
      "Finished training for epoch 299, loss: 0.005\n",
      "Finished training for epoch 300, loss: 0.004\n",
      "Finished training for epoch 301, loss: 0.004\n",
      "Finished training for epoch 302, loss: 0.005\n",
      "Finished training for epoch 303, loss: 0.003\n",
      "Finished training for epoch 304, loss: 0.003\n",
      "Finished training for epoch 305, loss: 0.003\n",
      "Finished training for epoch 306, loss: 0.004\n",
      "Finished training for epoch 307, loss: 0.005\n",
      "Finished training for epoch 308, loss: 0.007\n",
      "Finished training for epoch 309, loss: 0.005\n",
      "Finished training for epoch 310, loss: 0.004\n",
      "Finished training for epoch 311, loss: 0.006\n",
      "Finished training for epoch 312, loss: 0.009\n",
      "Finished training for epoch 313, loss: 0.012\n",
      "Finished training for epoch 314, loss: 0.005\n",
      "Finished training for epoch 315, loss: 0.004\n",
      "Finished training for epoch 316, loss: 0.009\n",
      "Finished training for epoch 317, loss: 0.014\n",
      "Finished training for epoch 318, loss: 0.012\n",
      "Finished training for epoch 319, loss: 0.006\n",
      "Finished training for epoch 320, loss: 0.005\n",
      "Finished training for epoch 321, loss: 0.013\n",
      "Finished training for epoch 322, loss: 0.012\n",
      "Finished training for epoch 323, loss: 0.015\n",
      "Finished training for epoch 324, loss: 0.009\n",
      "Finished training for epoch 325, loss: 0.008\n",
      "Finished training for epoch 326, loss: 0.008\n",
      "Finished training for epoch 327, loss: 0.007\n",
      "Finished training for epoch 328, loss: 0.005\n",
      "Finished training for epoch 329, loss: 0.003\n",
      "Finished training for epoch 330, loss: 0.003\n",
      "Finished training for epoch 331, loss: 0.004\n",
      "Finished training for epoch 332, loss: 0.010\n",
      "Finished training for epoch 333, loss: 0.011\n",
      "Finished training for epoch 334, loss: 0.007\n",
      "Finished training for epoch 335, loss: 0.010\n",
      "Finished training for epoch 336, loss: 0.004\n",
      "Finished training for epoch 337, loss: 0.003\n",
      "Finished training for epoch 338, loss: 0.003\n",
      "Finished training for epoch 339, loss: 0.003\n",
      "Finished training for epoch 340, loss: 0.002\n",
      "Finished training for epoch 341, loss: 0.004\n",
      "Finished training for epoch 342, loss: 0.004\n",
      "Finished training for epoch 343, loss: 0.003\n",
      "Finished training for epoch 344, loss: 0.005\n",
      "Finished training for epoch 345, loss: 0.006\n",
      "Finished training for epoch 346, loss: 0.010\n",
      "Finished training for epoch 347, loss: 0.005\n",
      "Finished training for epoch 348, loss: 0.006\n",
      "Finished training for epoch 349, loss: 0.006\n",
      "Finished training for epoch 350, loss: 0.005\n",
      "Finished training for epoch 351, loss: 0.007\n",
      "Finished training for epoch 352, loss: 0.010\n",
      "Finished training for epoch 353, loss: 0.004\n",
      "Finished training for epoch 354, loss: 0.006\n",
      "Finished training for epoch 355, loss: 0.004\n",
      "Finished training for epoch 356, loss: 0.004\n",
      "Finished training for epoch 357, loss: 0.005\n",
      "Finished training for epoch 358, loss: 0.002\n",
      "Finished training for epoch 359, loss: 0.002\n",
      "Finished training for epoch 360, loss: 0.002\n",
      "Finished training for epoch 361, loss: 0.002\n",
      "Finished training for epoch 362, loss: 0.005\n",
      "Finished training for epoch 363, loss: 0.008\n",
      "Finished training for epoch 364, loss: 0.003\n",
      "Finished training for epoch 365, loss: 0.006\n",
      "Finished training for epoch 366, loss: 0.005\n",
      "Finished training for epoch 367, loss: 0.007\n",
      "Finished training for epoch 368, loss: 0.009\n",
      "Finished training for epoch 369, loss: 0.010\n",
      "Finished training for epoch 370, loss: 0.014\n",
      "Finished training for epoch 371, loss: 0.014\n",
      "Finished training for epoch 372, loss: 0.009\n",
      "Finished training for epoch 373, loss: 0.007\n",
      "Finished training for epoch 374, loss: 0.006\n",
      "Finished training for epoch 375, loss: 0.003\n",
      "Finished training for epoch 376, loss: 0.002\n",
      "Finished training for epoch 377, loss: 0.002\n",
      "Finished training for epoch 378, loss: 0.004\n",
      "Finished training for epoch 379, loss: 0.006\n",
      "Finished training for epoch 380, loss: 0.002\n",
      "Finished training for epoch 381, loss: 0.003\n",
      "Finished training for epoch 382, loss: 0.004\n",
      "Finished training for epoch 383, loss: 0.002\n",
      "Finished training for epoch 384, loss: 0.007\n",
      "Finished training for epoch 385, loss: 0.003\n",
      "Finished training for epoch 386, loss: 0.003\n",
      "Finished training for epoch 387, loss: 0.004\n",
      "Finished training for epoch 388, loss: 0.003\n",
      "Finished training for epoch 389, loss: 0.004\n",
      "Finished training for epoch 390, loss: 0.003\n",
      "Finished training for epoch 391, loss: 0.004\n",
      "Finished training for epoch 392, loss: 0.004\n",
      "Finished training for epoch 393, loss: 0.003\n",
      "Finished training for epoch 394, loss: 0.007\n",
      "Finished training for epoch 395, loss: 0.008\n",
      "Finished training for epoch 396, loss: 0.004\n",
      "Finished training for epoch 397, loss: 0.006\n",
      "Finished training for epoch 398, loss: 0.007\n",
      "Finished training for epoch 399, loss: 0.006\n",
      "Finished training for epoch 400, loss: 0.008\n",
      "Finished training for epoch 401, loss: 0.007\n",
      "Finished training for epoch 402, loss: 0.011\n",
      "Finished training for epoch 403, loss: 0.010\n",
      "Finished training for epoch 404, loss: 0.006\n",
      "Finished training for epoch 405, loss: 0.003\n",
      "Finished training for epoch 406, loss: 0.002\n",
      "Finished training for epoch 407, loss: 0.003\n",
      "Finished training for epoch 408, loss: 0.004\n",
      "Finished training for epoch 409, loss: 0.003\n",
      "Finished training for epoch 410, loss: 0.003\n",
      "Finished training for epoch 411, loss: 0.001\n",
      "Finished training for epoch 412, loss: 0.004\n",
      "Finished training for epoch 413, loss: 0.011\n",
      "Finished training for epoch 414, loss: 0.014\n",
      "Finished training for epoch 415, loss: 0.003\n",
      "Finished training for epoch 416, loss: 0.004\n",
      "Finished training for epoch 417, loss: 0.004\n",
      "Finished training for epoch 418, loss: 0.005\n",
      "Finished training for epoch 419, loss: 0.019\n",
      "Finished training for epoch 420, loss: 0.007\n",
      "Finished training for epoch 421, loss: 0.015\n",
      "Finished training for epoch 422, loss: 0.022\n",
      "Finished training for epoch 423, loss: 0.006\n",
      "Finished training for epoch 424, loss: 0.007\n",
      "Finished training for epoch 425, loss: 0.008\n",
      "Finished training for epoch 426, loss: 0.010\n",
      "Finished training for epoch 427, loss: 0.004\n",
      "Finished training for epoch 428, loss: 0.005\n",
      "Finished training for epoch 429, loss: 0.003\n",
      "Finished training for epoch 430, loss: 0.002\n",
      "Finished training for epoch 431, loss: 0.002\n",
      "Finished training for epoch 432, loss: 0.002\n",
      "Finished training for epoch 433, loss: 0.005\n",
      "Finished training for epoch 434, loss: 0.016\n",
      "Finished training for epoch 435, loss: 0.050\n",
      "Finished training for epoch 436, loss: 0.030\n",
      "Finished training for epoch 437, loss: 0.007\n",
      "Finished training for epoch 438, loss: 0.008\n",
      "Finished training for epoch 439, loss: 0.003\n",
      "Finished training for epoch 440, loss: 0.002\n",
      "Finished training for epoch 441, loss: 0.002\n",
      "Finished training for epoch 442, loss: 0.002\n",
      "Finished training for epoch 443, loss: 0.003\n",
      "Finished training for epoch 444, loss: 0.002\n",
      "Finished training for epoch 445, loss: 0.004\n",
      "Finished training for epoch 446, loss: 0.003\n",
      "Finished training for epoch 447, loss: 0.003\n",
      "Finished training for epoch 448, loss: 0.004\n",
      "Finished training for epoch 449, loss: 0.005\n",
      "Finished training for epoch 450, loss: 0.004\n",
      "Finished training for epoch 451, loss: 0.004\n",
      "Finished training for epoch 452, loss: 0.004\n",
      "Finished training for epoch 453, loss: 0.003\n",
      "Finished training for epoch 454, loss: 0.001\n",
      "Finished training for epoch 455, loss: 0.002\n",
      "Finished training for epoch 456, loss: 0.001\n",
      "Finished training for epoch 457, loss: 0.006\n",
      "Finished training for epoch 458, loss: 0.003\n",
      "Finished training for epoch 459, loss: 0.001\n",
      "Finished training for epoch 460, loss: 0.002\n",
      "Finished training for epoch 461, loss: 0.003\n",
      "Finished training for epoch 462, loss: 0.005\n",
      "Finished training for epoch 463, loss: 0.003\n",
      "Finished training for epoch 464, loss: 0.006\n",
      "Finished training for epoch 465, loss: 0.024\n",
      "Finished training for epoch 466, loss: 0.010\n",
      "Finished training for epoch 467, loss: 0.010\n",
      "Finished training for epoch 468, loss: 0.007\n",
      "Finished training for epoch 469, loss: 0.004\n",
      "Finished training for epoch 470, loss: 0.003\n",
      "Finished training for epoch 471, loss: 0.007\n",
      "Finished training for epoch 472, loss: 0.011\n",
      "Finished training for epoch 473, loss: 0.006\n",
      "Finished training for epoch 474, loss: 0.003\n",
      "Finished training for epoch 475, loss: 0.009\n",
      "Finished training for epoch 476, loss: 0.010\n",
      "Finished training for epoch 477, loss: 0.003\n",
      "Finished training for epoch 478, loss: 0.007\n",
      "Finished training for epoch 479, loss: 0.002\n",
      "Finished training for epoch 480, loss: 0.002\n",
      "Finished training for epoch 481, loss: 0.005\n",
      "Finished training for epoch 482, loss: 0.004\n",
      "Finished training for epoch 483, loss: 0.006\n",
      "Finished training for epoch 484, loss: 0.006\n",
      "Finished training for epoch 485, loss: 0.003\n",
      "Finished training for epoch 486, loss: 0.006\n",
      "Finished training for epoch 487, loss: 0.002\n",
      "Finished training for epoch 488, loss: 0.005\n",
      "Finished training for epoch 489, loss: 0.002\n",
      "Finished training for epoch 490, loss: 0.002\n",
      "Finished training for epoch 491, loss: 0.003\n",
      "Finished training for epoch 492, loss: 0.006\n",
      "Finished training for epoch 493, loss: 0.002\n",
      "Finished training for epoch 494, loss: 0.003\n",
      "Finished training for epoch 495, loss: 0.002\n",
      "Finished training for epoch 496, loss: 0.003\n",
      "Finished training for epoch 497, loss: 0.002\n",
      "Finished training for epoch 498, loss: 0.007\n",
      "Finished training for epoch 499, loss: 0.007\n",
      "Finished training for epoch 500, loss: 0.002\n",
      "Finished training for epoch 501, loss: 0.005\n",
      "Finished training for epoch 502, loss: 0.001\n",
      "Finished training for epoch 503, loss: 0.002\n",
      "Finished training for epoch 504, loss: 0.007\n",
      "Finished training for epoch 505, loss: 0.003\n",
      "Finished training for epoch 506, loss: 0.009\n",
      "Finished training for epoch 507, loss: 0.007\n",
      "Finished training for epoch 508, loss: 0.002\n",
      "Finished training for epoch 509, loss: 0.001\n",
      "Finished training for epoch 510, loss: 0.001\n",
      "Finished training for epoch 511, loss: 0.002\n",
      "Finished training for epoch 512, loss: 0.005\n",
      "Finished training for epoch 513, loss: 0.006\n",
      "Finished training for epoch 514, loss: 0.014\n",
      "Finished training for epoch 515, loss: 0.009\n",
      "Finished training for epoch 516, loss: 0.007\n",
      "Finished training for epoch 517, loss: 0.006\n",
      "Finished training for epoch 518, loss: 0.007\n",
      "Finished training for epoch 519, loss: 0.004\n",
      "Finished training for epoch 520, loss: 0.002\n",
      "Finished training for epoch 521, loss: 0.004\n",
      "Finished training for epoch 522, loss: 0.002\n",
      "Finished training for epoch 523, loss: 0.002\n",
      "Finished training for epoch 524, loss: 0.003\n",
      "Finished training for epoch 525, loss: 0.001\n",
      "Finished training for epoch 526, loss: 0.001\n",
      "Finished training for epoch 527, loss: 0.001\n",
      "Finished training for epoch 528, loss: 0.006\n",
      "Finished training for epoch 529, loss: 0.005\n",
      "Finished training for epoch 530, loss: 0.003\n",
      "Finished training for epoch 531, loss: 0.007\n",
      "Finished training for epoch 532, loss: 0.004\n",
      "Finished training for epoch 533, loss: 0.015\n",
      "Finished training for epoch 534, loss: 0.019\n",
      "Finished training for epoch 535, loss: 0.008\n",
      "Finished training for epoch 536, loss: 0.007\n",
      "Finished training for epoch 537, loss: 0.002\n",
      "Finished training for epoch 538, loss: 0.001\n",
      "Finished training for epoch 539, loss: 0.002\n",
      "Finished training for epoch 540, loss: 0.002\n",
      "Finished training for epoch 541, loss: 0.001\n",
      "Finished training for epoch 542, loss: 0.002\n",
      "Finished training for epoch 543, loss: 0.001\n",
      "Finished training for epoch 544, loss: 0.002\n",
      "Finished training for epoch 545, loss: 0.002\n",
      "Finished training for epoch 546, loss: 0.002\n",
      "Finished training for epoch 547, loss: 0.003\n",
      "Finished training for epoch 548, loss: 0.008\n",
      "Finished training for epoch 549, loss: 0.003\n",
      "Finished training for epoch 550, loss: 0.003\n",
      "Finished training for epoch 551, loss: 0.004\n",
      "Finished training for epoch 552, loss: 0.004\n",
      "Finished training for epoch 553, loss: 0.001\n",
      "Finished training for epoch 554, loss: 0.001\n",
      "Finished training for epoch 555, loss: 0.001\n",
      "Finished training for epoch 556, loss: 0.001\n",
      "Finished training for epoch 557, loss: 0.001\n",
      "Finished training for epoch 558, loss: 0.001\n",
      "Finished training for epoch 559, loss: 0.001\n",
      "Finished training for epoch 560, loss: 0.001\n",
      "Finished training for epoch 561, loss: 0.001\n",
      "Finished training for epoch 562, loss: 0.004\n",
      "Finished training for epoch 563, loss: 0.007\n",
      "Finished training for epoch 564, loss: 0.001\n",
      "Finished training for epoch 565, loss: 0.001\n",
      "Finished training for epoch 566, loss: 0.001\n",
      "Finished training for epoch 567, loss: 0.002\n",
      "Finished training for epoch 568, loss: 0.001\n",
      "Finished training for epoch 569, loss: 0.001\n",
      "Finished training for epoch 570, loss: 0.000\n",
      "Finished training for epoch 571, loss: 0.000\n",
      "Finished training for epoch 572, loss: 0.000\n",
      "Finished training for epoch 573, loss: 0.001\n",
      "Finished training for epoch 574, loss: 0.001\n",
      "Finished training for epoch 575, loss: 0.001\n",
      "Finished training for epoch 576, loss: 0.001\n",
      "Finished training for epoch 577, loss: 0.013\n",
      "Finished training for epoch 578, loss: 0.001\n",
      "Finished training for epoch 579, loss: 0.003\n",
      "Finished training for epoch 580, loss: 0.004\n",
      "Finished training for epoch 581, loss: 0.007\n",
      "Finished training for epoch 582, loss: 0.005\n",
      "Finished training for epoch 583, loss: 0.021\n",
      "Finished training for epoch 584, loss: 0.004\n",
      "Finished training for epoch 585, loss: 0.006\n",
      "Finished training for epoch 586, loss: 0.014\n",
      "Finished training for epoch 587, loss: 0.003\n",
      "Finished training for epoch 588, loss: 0.001\n",
      "Finished training for epoch 589, loss: 0.001\n",
      "Finished training for epoch 590, loss: 0.001\n",
      "Finished training for epoch 591, loss: 0.001\n",
      "Finished training for epoch 592, loss: 0.001\n",
      "Finished training for epoch 593, loss: 0.001\n",
      "Finished training for epoch 594, loss: 0.006\n",
      "Finished training for epoch 595, loss: 0.011\n",
      "Finished training for epoch 596, loss: 0.002\n",
      "Finished training for epoch 597, loss: 0.005\n",
      "Finished training for epoch 598, loss: 0.021\n",
      "Finished training for epoch 599, loss: 0.014\n",
      "Finished training for epoch 600, loss: 0.009\n",
      "Finished training for epoch 601, loss: 0.008\n",
      "Finished training for epoch 602, loss: 0.011\n",
      "Finished training for epoch 603, loss: 0.015\n",
      "Finished training for epoch 604, loss: 0.006\n",
      "Finished training for epoch 605, loss: 0.006\n",
      "Finished training for epoch 606, loss: 0.003\n",
      "Finished training for epoch 607, loss: 0.001\n",
      "Finished training for epoch 608, loss: 0.001\n",
      "Finished training for epoch 609, loss: 0.001\n",
      "Finished training for epoch 610, loss: 0.001\n",
      "Finished training for epoch 611, loss: 0.001\n",
      "Finished training for epoch 612, loss: 0.001\n",
      "Finished training for epoch 613, loss: 0.001\n",
      "Finished training for epoch 614, loss: 0.001\n",
      "Finished training for epoch 615, loss: 0.001\n",
      "Finished training for epoch 616, loss: 0.001\n",
      "Finished training for epoch 617, loss: 0.001\n",
      "Finished training for epoch 618, loss: 0.001\n",
      "Finished training for epoch 619, loss: 0.001\n",
      "Finished training for epoch 620, loss: 0.001\n",
      "Finished training for epoch 621, loss: 0.001\n",
      "Finished training for epoch 622, loss: 0.001\n",
      "Finished training for epoch 623, loss: 0.001\n",
      "Finished training for epoch 624, loss: 0.001\n",
      "Finished training for epoch 625, loss: 0.001\n",
      "Finished training for epoch 626, loss: 0.001\n",
      "Finished training for epoch 627, loss: 0.001\n",
      "Finished training for epoch 628, loss: 0.001\n",
      "Finished training for epoch 629, loss: 0.001\n",
      "Finished training for epoch 630, loss: 0.000\n",
      "Finished training for epoch 631, loss: 0.001\n",
      "Finished training for epoch 632, loss: 0.001\n",
      "Finished training for epoch 633, loss: 0.001\n",
      "Finished training for epoch 634, loss: 0.017\n",
      "Finished training for epoch 635, loss: 0.012\n",
      "Finished training for epoch 636, loss: 0.021\n",
      "Finished training for epoch 637, loss: 0.014\n",
      "Finished training for epoch 638, loss: 0.009\n",
      "Finished training for epoch 639, loss: 0.001\n",
      "Finished training for epoch 640, loss: 0.002\n",
      "Finished training for epoch 641, loss: 0.001\n",
      "Finished training for epoch 642, loss: 0.001\n",
      "Finished training for epoch 643, loss: 0.001\n",
      "Finished training for epoch 644, loss: 0.002\n",
      "Finished training for epoch 645, loss: 0.023\n",
      "Finished training for epoch 646, loss: 0.005\n",
      "Finished training for epoch 647, loss: 0.010\n",
      "Finished training for epoch 648, loss: 0.015\n",
      "Finished training for epoch 649, loss: 0.009\n",
      "Finished training for epoch 650, loss: 0.007\n",
      "Finished training for epoch 651, loss: 0.002\n",
      "Finished training for epoch 652, loss: 0.002\n",
      "Finished training for epoch 653, loss: 0.003\n",
      "Finished training for epoch 654, loss: 0.002\n",
      "Finished training for epoch 655, loss: 0.002\n",
      "Finished training for epoch 656, loss: 0.002\n",
      "Finished training for epoch 657, loss: 0.002\n",
      "Finished training for epoch 658, loss: 0.002\n",
      "Finished training for epoch 659, loss: 0.002\n",
      "Finished training for epoch 660, loss: 0.007\n",
      "Finished training for epoch 661, loss: 0.010\n",
      "Finished training for epoch 662, loss: 0.006\n",
      "Finished training for epoch 663, loss: 0.007\n",
      "Finished training for epoch 664, loss: 0.007\n",
      "Finished training for epoch 665, loss: 0.005\n",
      "Finished training for epoch 666, loss: 0.007\n",
      "Finished training for epoch 667, loss: 0.007\n",
      "Finished training for epoch 668, loss: 0.002\n",
      "Finished training for epoch 669, loss: 0.002\n",
      "Finished training for epoch 670, loss: 0.002\n",
      "Finished training for epoch 671, loss: 0.001\n",
      "Finished training for epoch 672, loss: 0.001\n",
      "Finished training for epoch 673, loss: 0.002\n",
      "Finished training for epoch 674, loss: 0.003\n",
      "Finished training for epoch 675, loss: 0.002\n",
      "Finished training for epoch 676, loss: 0.001\n",
      "Finished training for epoch 677, loss: 0.002\n",
      "Finished training for epoch 678, loss: 0.001\n",
      "Finished training for epoch 679, loss: 0.003\n",
      "Finished training for epoch 680, loss: 0.001\n",
      "Finished training for epoch 681, loss: 0.002\n",
      "Finished training for epoch 682, loss: 0.004\n",
      "Finished training for epoch 683, loss: 0.001\n",
      "Finished training for epoch 684, loss: 0.001\n",
      "Finished training for epoch 685, loss: 0.001\n",
      "Finished training for epoch 686, loss: 0.003\n",
      "Finished training for epoch 687, loss: 0.006\n",
      "Finished training for epoch 688, loss: 0.009\n",
      "Finished training for epoch 689, loss: 0.002\n",
      "Finished training for epoch 690, loss: 0.001\n",
      "Finished training for epoch 691, loss: 0.001\n",
      "Finished training for epoch 692, loss: 0.002\n",
      "Finished training for epoch 693, loss: 0.002\n",
      "Finished training for epoch 694, loss: 0.001\n",
      "Finished training for epoch 695, loss: 0.002\n",
      "Finished training for epoch 696, loss: 0.001\n",
      "Finished training for epoch 697, loss: 0.004\n",
      "Finished training for epoch 698, loss: 0.003\n",
      "Finished training for epoch 699, loss: 0.006\n",
      "Finished training for epoch 700, loss: 0.014\n",
      "Finished training for epoch 701, loss: 0.018\n",
      "Finished training for epoch 702, loss: 0.002\n",
      "Finished training for epoch 703, loss: 0.002\n",
      "Finished training for epoch 704, loss: 0.002\n",
      "Finished training for epoch 705, loss: 0.007\n",
      "Finished training for epoch 706, loss: 0.007\n",
      "Finished training for epoch 707, loss: 0.005\n",
      "Finished training for epoch 708, loss: 0.003\n",
      "Finished training for epoch 709, loss: 0.006\n",
      "Finished training for epoch 710, loss: 0.003\n",
      "Finished training for epoch 711, loss: 0.002\n",
      "Finished training for epoch 712, loss: 0.004\n",
      "Finished training for epoch 713, loss: 0.005\n",
      "Finished training for epoch 714, loss: 0.010\n",
      "Finished training for epoch 715, loss: 0.009\n",
      "Finished training for epoch 716, loss: 0.003\n",
      "Finished training for epoch 717, loss: 0.006\n",
      "Finished training for epoch 718, loss: 0.005\n",
      "Finished training for epoch 719, loss: 0.004\n",
      "Finished training for epoch 720, loss: 0.003\n",
      "Finished training for epoch 721, loss: 0.003\n",
      "Finished training for epoch 722, loss: 0.002\n",
      "Finished training for epoch 723, loss: 0.003\n",
      "Finished training for epoch 724, loss: 0.005\n",
      "Finished training for epoch 725, loss: 0.011\n",
      "Finished training for epoch 726, loss: 0.005\n",
      "Finished training for epoch 727, loss: 0.002\n",
      "Finished training for epoch 728, loss: 0.002\n",
      "Finished training for epoch 729, loss: 0.002\n",
      "Finished training for epoch 730, loss: 0.002\n",
      "Finished training for epoch 731, loss: 0.001\n",
      "Finished training for epoch 732, loss: 0.001\n",
      "Finished training for epoch 733, loss: 0.002\n",
      "Finished training for epoch 734, loss: 0.001\n",
      "Finished training for epoch 735, loss: 0.001\n",
      "Finished training for epoch 736, loss: 0.001\n",
      "Finished training for epoch 737, loss: 0.002\n",
      "Finished training for epoch 738, loss: 0.001\n",
      "Finished training for epoch 739, loss: 0.001\n",
      "Finished training for epoch 740, loss: 0.002\n",
      "Finished training for epoch 741, loss: 0.003\n",
      "Finished training for epoch 742, loss: 0.002\n",
      "Finished training for epoch 743, loss: 0.002\n",
      "Finished training for epoch 744, loss: 0.003\n",
      "Finished training for epoch 745, loss: 0.005\n",
      "Finished training for epoch 746, loss: 0.001\n",
      "Finished training for epoch 747, loss: 0.001\n",
      "Finished training for epoch 748, loss: 0.001\n",
      "Finished training for epoch 749, loss: 0.002\n",
      "Finished training for epoch 750, loss: 0.002\n",
      "Finished training for epoch 751, loss: 0.010\n",
      "Finished training for epoch 752, loss: 0.024\n",
      "Finished training for epoch 753, loss: 0.004\n",
      "Finished training for epoch 754, loss: 0.002\n",
      "Finished training for epoch 755, loss: 0.002\n",
      "Finished training for epoch 756, loss: 0.004\n",
      "Finished training for epoch 757, loss: 0.002\n",
      "Finished training for epoch 758, loss: 0.002\n",
      "Finished training for epoch 759, loss: 0.003\n",
      "Finished training for epoch 760, loss: 0.003\n",
      "Finished training for epoch 761, loss: 0.002\n",
      "Finished training for epoch 762, loss: 0.003\n",
      "Finished training for epoch 763, loss: 0.002\n",
      "Finished training for epoch 764, loss: 0.001\n",
      "Finished training for epoch 765, loss: 0.002\n",
      "Finished training for epoch 766, loss: 0.002\n",
      "Finished training for epoch 767, loss: 0.005\n",
      "Finished training for epoch 768, loss: 0.011\n",
      "Finished training for epoch 769, loss: 0.003\n",
      "Finished training for epoch 770, loss: 0.003\n",
      "Finished training for epoch 771, loss: 0.005\n",
      "Finished training for epoch 772, loss: 0.002\n",
      "Finished training for epoch 773, loss: 0.004\n",
      "Finished training for epoch 774, loss: 0.003\n",
      "Finished training for epoch 775, loss: 0.004\n",
      "Finished training for epoch 776, loss: 0.001\n",
      "Finished training for epoch 777, loss: 0.001\n",
      "Finished training for epoch 778, loss: 0.002\n",
      "Finished training for epoch 779, loss: 0.002\n",
      "Finished training for epoch 780, loss: 0.001\n",
      "Finished training for epoch 781, loss: 0.003\n",
      "Finished training for epoch 782, loss: 0.001\n",
      "Finished training for epoch 783, loss: 0.001\n",
      "Finished training for epoch 784, loss: 0.001\n",
      "Finished training for epoch 785, loss: 0.002\n",
      "Finished training for epoch 786, loss: 0.003\n",
      "Finished training for epoch 787, loss: 0.003\n",
      "Finished training for epoch 788, loss: 0.003\n",
      "Finished training for epoch 789, loss: 0.003\n",
      "Finished training for epoch 790, loss: 0.002\n",
      "Finished training for epoch 791, loss: 0.004\n",
      "Finished training for epoch 792, loss: 0.004\n",
      "Finished training for epoch 793, loss: 0.021\n",
      "Finished training for epoch 794, loss: 0.010\n",
      "Finished training for epoch 795, loss: 0.005\n",
      "Finished training for epoch 796, loss: 0.012\n",
      "Finished training for epoch 797, loss: 0.004\n",
      "Finished training for epoch 798, loss: 0.005\n",
      "Finished training for epoch 799, loss: 0.002\n",
      "Finished training for epoch 800, loss: 0.001\n",
      "Finished training for epoch 801, loss: 0.001\n",
      "Finished training for epoch 802, loss: 0.001\n",
      "Finished training for epoch 803, loss: 0.001\n",
      "Finished training for epoch 804, loss: 0.001\n",
      "Finished training for epoch 805, loss: 0.001\n",
      "Finished training for epoch 806, loss: 0.002\n",
      "Finished training for epoch 807, loss: 0.001\n",
      "Finished training for epoch 808, loss: 0.001\n",
      "Finished training for epoch 809, loss: 0.002\n",
      "Finished training for epoch 810, loss: 0.001\n",
      "Finished training for epoch 811, loss: 0.001\n",
      "Finished training for epoch 812, loss: 0.001\n",
      "Finished training for epoch 813, loss: 0.003\n",
      "Finished training for epoch 814, loss: 0.003\n",
      "Finished training for epoch 815, loss: 0.011\n",
      "Finished training for epoch 816, loss: 0.010\n",
      "Finished training for epoch 817, loss: 0.004\n",
      "Finished training for epoch 818, loss: 0.002\n",
      "Finished training for epoch 819, loss: 0.002\n",
      "Finished training for epoch 820, loss: 0.002\n",
      "Finished training for epoch 821, loss: 0.002\n",
      "Finished training for epoch 822, loss: 0.002\n",
      "Finished training for epoch 823, loss: 0.001\n",
      "Finished training for epoch 824, loss: 0.001\n",
      "Finished training for epoch 825, loss: 0.001\n",
      "Finished training for epoch 826, loss: 0.001\n",
      "Finished training for epoch 827, loss: 0.002\n",
      "Finished training for epoch 828, loss: 0.004\n",
      "Finished training for epoch 829, loss: 0.013\n",
      "Finished training for epoch 830, loss: 0.001\n",
      "Finished training for epoch 831, loss: 0.002\n",
      "Finished training for epoch 832, loss: 0.002\n",
      "Finished training for epoch 833, loss: 0.003\n",
      "Finished training for epoch 834, loss: 0.004\n",
      "Finished training for epoch 835, loss: 0.004\n",
      "Finished training for epoch 836, loss: 0.004\n",
      "Finished training for epoch 837, loss: 0.024\n",
      "Finished training for epoch 838, loss: 0.006\n",
      "Finished training for epoch 839, loss: 0.006\n",
      "Finished training for epoch 840, loss: 0.004\n",
      "Finished training for epoch 841, loss: 0.002\n",
      "Finished training for epoch 842, loss: 0.001\n",
      "Finished training for epoch 843, loss: 0.001\n",
      "Finished training for epoch 844, loss: 0.001\n",
      "Finished training for epoch 845, loss: 0.001\n",
      "Finished training for epoch 846, loss: 0.001\n",
      "Finished training for epoch 847, loss: 0.001\n",
      "Finished training for epoch 848, loss: 0.001\n",
      "Finished training for epoch 849, loss: 0.001\n",
      "Finished training for epoch 850, loss: 0.001\n",
      "Finished training for epoch 851, loss: 0.001\n",
      "Finished training for epoch 852, loss: 0.001\n",
      "Finished training for epoch 853, loss: 0.001\n",
      "Finished training for epoch 854, loss: 0.002\n",
      "Finished training for epoch 855, loss: 0.002\n",
      "Finished training for epoch 856, loss: 0.001\n",
      "Finished training for epoch 857, loss: 0.001\n",
      "Finished training for epoch 858, loss: 0.002\n",
      "Finished training for epoch 859, loss: 0.001\n",
      "Finished training for epoch 860, loss: 0.001\n",
      "Finished training for epoch 861, loss: 0.001\n",
      "Finished training for epoch 862, loss: 0.013\n",
      "Finished training for epoch 863, loss: 0.006\n",
      "Finished training for epoch 864, loss: 0.038\n",
      "Finished training for epoch 865, loss: 0.046\n",
      "Finished training for epoch 866, loss: 0.009\n",
      "Finished training for epoch 867, loss: 0.019\n",
      "Finished training for epoch 868, loss: 0.004\n",
      "Finished training for epoch 869, loss: 0.004\n",
      "Finished training for epoch 870, loss: 0.003\n",
      "Finished training for epoch 871, loss: 0.002\n",
      "Finished training for epoch 872, loss: 0.002\n",
      "Finished training for epoch 873, loss: 0.002\n",
      "Finished training for epoch 874, loss: 0.002\n",
      "Finished training for epoch 875, loss: 0.002\n",
      "Finished training for epoch 876, loss: 0.002\n",
      "Finished training for epoch 877, loss: 0.002\n",
      "Finished training for epoch 878, loss: 0.001\n",
      "Finished training for epoch 879, loss: 0.002\n",
      "Finished training for epoch 880, loss: 0.003\n",
      "Finished training for epoch 881, loss: 0.003\n",
      "Finished training for epoch 882, loss: 0.001\n",
      "Finished training for epoch 883, loss: 0.001\n",
      "Finished training for epoch 884, loss: 0.002\n",
      "Finished training for epoch 885, loss: 0.003\n",
      "Finished training for epoch 886, loss: 0.012\n",
      "Finished training for epoch 887, loss: 0.006\n",
      "Finished training for epoch 888, loss: 0.002\n",
      "Finished training for epoch 889, loss: 0.002\n",
      "Finished training for epoch 890, loss: 0.002\n",
      "Finished training for epoch 891, loss: 0.002\n",
      "Finished training for epoch 892, loss: 0.002\n",
      "Finished training for epoch 893, loss: 0.002\n",
      "Finished training for epoch 894, loss: 0.001\n",
      "Finished training for epoch 895, loss: 0.001\n",
      "Finished training for epoch 896, loss: 0.001\n",
      "Finished training for epoch 897, loss: 0.009\n",
      "Finished training for epoch 898, loss: 0.006\n",
      "Finished training for epoch 899, loss: 0.005\n",
      "Finished training for epoch 900, loss: 0.002\n",
      "Finished training for epoch 901, loss: 0.002\n",
      "Finished training for epoch 902, loss: 0.003\n",
      "Finished training for epoch 903, loss: 0.014\n",
      "Finished training for epoch 904, loss: 0.018\n",
      "Finished training for epoch 905, loss: 0.007\n",
      "Finished training for epoch 906, loss: 0.003\n",
      "Finished training for epoch 907, loss: 0.002\n",
      "Finished training for epoch 908, loss: 0.001\n",
      "Finished training for epoch 909, loss: 0.001\n",
      "Finished training for epoch 910, loss: 0.002\n",
      "Finished training for epoch 911, loss: 0.002\n",
      "Finished training for epoch 912, loss: 0.001\n",
      "Finished training for epoch 913, loss: 0.001\n",
      "Finished training for epoch 914, loss: 0.001\n",
      "Finished training for epoch 915, loss: 0.002\n",
      "Finished training for epoch 916, loss: 0.002\n",
      "Finished training for epoch 917, loss: 0.001\n",
      "Finished training for epoch 918, loss: 0.001\n",
      "Finished training for epoch 919, loss: 0.001\n",
      "Finished training for epoch 920, loss: 0.001\n",
      "Finished training for epoch 921, loss: 0.001\n",
      "Finished training for epoch 922, loss: 0.005\n",
      "Finished training for epoch 923, loss: 0.001\n",
      "Finished training for epoch 924, loss: 0.001\n",
      "Finished training for epoch 925, loss: 0.003\n",
      "Finished training for epoch 926, loss: 0.011\n",
      "Finished training for epoch 927, loss: 0.003\n",
      "Finished training for epoch 928, loss: 0.002\n",
      "Finished training for epoch 929, loss: 0.002\n",
      "Finished training for epoch 930, loss: 0.001\n",
      "Finished training for epoch 931, loss: 0.002\n",
      "Finished training for epoch 932, loss: 0.002\n",
      "Finished training for epoch 933, loss: 0.001\n",
      "Finished training for epoch 934, loss: 0.001\n",
      "Finished training for epoch 935, loss: 0.001\n",
      "Finished training for epoch 936, loss: 0.002\n",
      "Finished training for epoch 937, loss: 0.001\n",
      "Finished training for epoch 938, loss: 0.003\n",
      "Finished training for epoch 939, loss: 0.002\n",
      "Finished training for epoch 940, loss: 0.003\n",
      "Finished training for epoch 941, loss: 0.002\n",
      "Finished training for epoch 942, loss: 0.001\n",
      "Finished training for epoch 943, loss: 0.003\n",
      "Finished training for epoch 944, loss: 0.001\n",
      "Finished training for epoch 945, loss: 0.002\n",
      "Finished training for epoch 946, loss: 0.008\n",
      "Finished training for epoch 947, loss: 0.003\n",
      "Finished training for epoch 948, loss: 0.007\n",
      "Finished training for epoch 949, loss: 0.006\n",
      "Finished training for epoch 950, loss: 0.016\n",
      "Finished training for epoch 951, loss: 0.016\n",
      "Finished training for epoch 952, loss: 0.010\n",
      "Finished training for epoch 953, loss: 0.017\n",
      "Finished training for epoch 954, loss: 0.035\n",
      "Finished training for epoch 955, loss: 0.007\n",
      "Finished training for epoch 956, loss: 0.002\n",
      "Finished training for epoch 957, loss: 0.002\n",
      "Finished training for epoch 958, loss: 0.002\n",
      "Finished training for epoch 959, loss: 0.002\n",
      "Finished training for epoch 960, loss: 0.002\n",
      "Finished training for epoch 961, loss: 0.001\n",
      "Finished training for epoch 962, loss: 0.002\n",
      "Finished training for epoch 963, loss: 0.002\n",
      "Finished training for epoch 964, loss: 0.002\n",
      "Finished training for epoch 965, loss: 0.002\n",
      "Finished training for epoch 966, loss: 0.002\n",
      "Finished training for epoch 967, loss: 0.001\n",
      "Finished training for epoch 968, loss: 0.001\n",
      "Finished training for epoch 969, loss: 0.001\n",
      "Finished training for epoch 970, loss: 0.001\n",
      "Finished training for epoch 971, loss: 0.001\n",
      "Finished training for epoch 972, loss: 0.001\n",
      "Finished training for epoch 973, loss: 0.002\n",
      "Finished training for epoch 974, loss: 0.001\n",
      "Finished training for epoch 975, loss: 0.001\n",
      "Finished training for epoch 976, loss: 0.001\n",
      "Finished training for epoch 977, loss: 0.001\n",
      "Finished training for epoch 978, loss: 0.005\n",
      "Finished training for epoch 979, loss: 0.002\n",
      "Finished training for epoch 980, loss: 0.001\n",
      "Finished training for epoch 981, loss: 0.002\n",
      "Finished training for epoch 982, loss: 0.001\n",
      "Finished training for epoch 983, loss: 0.001\n",
      "Finished training for epoch 984, loss: 0.001\n",
      "Finished training for epoch 985, loss: 0.001\n",
      "Finished training for epoch 986, loss: 0.002\n",
      "Finished training for epoch 987, loss: 0.001\n",
      "Finished training for epoch 988, loss: 0.001\n",
      "Finished training for epoch 989, loss: 0.001\n",
      "Finished training for epoch 990, loss: 0.007\n",
      "Finished training for epoch 991, loss: 0.010\n",
      "Finished training for epoch 992, loss: 0.006\n",
      "Finished training for epoch 993, loss: 0.004\n",
      "Finished training for epoch 994, loss: 0.007\n",
      "Finished training for epoch 995, loss: 0.002\n",
      "Finished training for epoch 996, loss: 0.001\n",
      "Finished training for epoch 997, loss: 0.001\n",
      "Finished training for epoch 998, loss: 0.001\n",
      "Finished training for epoch 999, loss: 0.001\n",
      "Finished training for epoch 1000, loss: 0.002\n"
     ]
    }
   ],
   "source": [
    "net_1 = Net()\n",
    "net_1 = train_model_bce(net_1, dataset_train, 32, 1000, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_uniform_test = SystemDataset(\"dataset_arbi2d.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9953500032424927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9954)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(net_1, dataset_uniform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We test the model by near-boundary points generated previously via bisection routine.\n",
    "dataset_near_test = SystemDataset(\"dataset_arbi2d_near.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5551000237464905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5551)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(net_1, dataset_near_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the training set is small, we could see that the classifier does not give good performance if tested by points that are close to the boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training: data enhancement with near-boundaty points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing df_1: 100%|██████████| 40/40 [06:40<00:00, 10.02s/it]\n"
     ]
    }
   ],
   "source": [
    "df_data = dataset_train.data\n",
    "\n",
    "df_data_1 = df_data[df_data['attracted'] == 1].sample(40)\n",
    "df_data_n1 = df_data[df_data['attracted'] == -1].sample(40)\n",
    "\n",
    "dataset_near = []\n",
    "for i in tqdm(range(len(df_data_1)), desc=\"Processing df_1\"):\n",
    "    for j in range(len(df_data_n1)):\n",
    "        a = (df_data_1.iloc[i]['x0'], df_data_1.iloc[i]['y0'])\n",
    "        b = (df_data_n1.iloc[j]['x0'], df_data_n1.iloc[j]['y0'])\n",
    "        a, b = bisection(a, b)\n",
    "        dataset_near.append([a[0], a[1], 1])\n",
    "        dataset_near.append([b[0], b[1], -1])\n",
    "\n",
    "df_near = pd.DataFrame(dataset_near, columns=['x0', 'y0', 'attracted'])\n",
    "df_near.to_csv('dataset_arbi2d_enhanced_1600.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Verify the generated near-boundary points\n",
    "df_near = pd.read_csv('dataset_arbi2d_enhanced_400.csv')\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(df_near['x0'], df_near['y0'], c=df_near['attracted'], cmap='coolwarm', s=1)\n",
    "plt.xlabel('$x_0$')\n",
    "plt.ylabel('$y_0$')\n",
    "plt.title('Sampled near-boundary datapoints')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model again with enhanced dataset\n",
    "dataset_uniform_train = SystemDataset(\"dataset_arbi2d_1000.csv\")\n",
    "dataset_near_train = SystemDataset(\"dataset_arbi2d_enhanced_400.csv\")\n",
    "dataset_merged_train = torch.utils.data.ConcatDataset([dataset_uniform_train, dataset_near_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training for epoch 1, loss: 0.655\n",
      "Finished training for epoch 2, loss: 0.547\n",
      "Finished training for epoch 3, loss: 0.480\n",
      "Finished training for epoch 4, loss: 0.433\n",
      "Finished training for epoch 5, loss: 0.401\n",
      "Finished training for epoch 6, loss: 0.383\n",
      "Finished training for epoch 7, loss: 0.371\n",
      "Finished training for epoch 8, loss: 0.371\n",
      "Finished training for epoch 9, loss: 0.354\n",
      "Finished training for epoch 10, loss: 0.353\n",
      "Finished training for epoch 11, loss: 0.353\n",
      "Finished training for epoch 12, loss: 0.367\n",
      "Finished training for epoch 13, loss: 0.344\n",
      "Finished training for epoch 14, loss: 0.342\n",
      "Finished training for epoch 15, loss: 0.340\n",
      "Finished training for epoch 16, loss: 0.339\n",
      "Finished training for epoch 17, loss: 0.345\n",
      "Finished training for epoch 18, loss: 0.343\n",
      "Finished training for epoch 19, loss: 0.337\n",
      "Finished training for epoch 20, loss: 0.345\n",
      "Finished training for epoch 21, loss: 0.337\n",
      "Finished training for epoch 22, loss: 0.334\n",
      "Finished training for epoch 23, loss: 0.330\n",
      "Finished training for epoch 24, loss: 0.345\n",
      "Finished training for epoch 25, loss: 0.335\n",
      "Finished training for epoch 26, loss: 0.332\n",
      "Finished training for epoch 27, loss: 0.340\n",
      "Finished training for epoch 28, loss: 0.333\n",
      "Finished training for epoch 29, loss: 0.327\n",
      "Finished training for epoch 30, loss: 0.334\n",
      "Finished training for epoch 31, loss: 0.332\n",
      "Finished training for epoch 32, loss: 0.329\n",
      "Finished training for epoch 33, loss: 0.329\n",
      "Finished training for epoch 34, loss: 0.328\n",
      "Finished training for epoch 35, loss: 0.328\n",
      "Finished training for epoch 36, loss: 0.325\n",
      "Finished training for epoch 37, loss: 0.327\n",
      "Finished training for epoch 38, loss: 0.323\n",
      "Finished training for epoch 39, loss: 0.324\n",
      "Finished training for epoch 40, loss: 0.330\n",
      "Finished training for epoch 41, loss: 0.331\n",
      "Finished training for epoch 42, loss: 0.326\n",
      "Finished training for epoch 43, loss: 0.339\n",
      "Finished training for epoch 44, loss: 0.326\n",
      "Finished training for epoch 45, loss: 0.322\n",
      "Finished training for epoch 46, loss: 0.332\n",
      "Finished training for epoch 47, loss: 0.325\n",
      "Finished training for epoch 48, loss: 0.324\n",
      "Finished training for epoch 49, loss: 0.317\n",
      "Finished training for epoch 50, loss: 0.327\n",
      "Finished training for epoch 51, loss: 0.324\n",
      "Finished training for epoch 52, loss: 0.322\n",
      "Finished training for epoch 53, loss: 0.337\n",
      "Finished training for epoch 54, loss: 0.326\n",
      "Finished training for epoch 55, loss: 0.314\n",
      "Finished training for epoch 56, loss: 0.318\n",
      "Finished training for epoch 57, loss: 0.320\n",
      "Finished training for epoch 58, loss: 0.331\n",
      "Finished training for epoch 59, loss: 0.328\n",
      "Finished training for epoch 60, loss: 0.317\n",
      "Finished training for epoch 61, loss: 0.324\n",
      "Finished training for epoch 62, loss: 0.319\n",
      "Finished training for epoch 63, loss: 0.323\n",
      "Finished training for epoch 64, loss: 0.319\n",
      "Finished training for epoch 65, loss: 0.328\n",
      "Finished training for epoch 66, loss: 0.331\n",
      "Finished training for epoch 67, loss: 0.321\n",
      "Finished training for epoch 68, loss: 0.321\n",
      "Finished training for epoch 69, loss: 0.322\n",
      "Finished training for epoch 70, loss: 0.317\n",
      "Finished training for epoch 71, loss: 0.314\n",
      "Finished training for epoch 72, loss: 0.331\n",
      "Finished training for epoch 73, loss: 0.324\n",
      "Finished training for epoch 74, loss: 0.313\n",
      "Finished training for epoch 75, loss: 0.314\n",
      "Finished training for epoch 76, loss: 0.320\n",
      "Finished training for epoch 77, loss: 0.310\n",
      "Finished training for epoch 78, loss: 0.314\n",
      "Finished training for epoch 79, loss: 0.311\n",
      "Finished training for epoch 80, loss: 0.327\n",
      "Finished training for epoch 81, loss: 0.308\n",
      "Finished training for epoch 82, loss: 0.314\n",
      "Finished training for epoch 83, loss: 0.308\n",
      "Finished training for epoch 84, loss: 0.312\n",
      "Finished training for epoch 85, loss: 0.312\n",
      "Finished training for epoch 86, loss: 0.317\n",
      "Finished training for epoch 87, loss: 0.312\n",
      "Finished training for epoch 88, loss: 0.323\n",
      "Finished training for epoch 89, loss: 0.314\n",
      "Finished training for epoch 90, loss: 0.315\n",
      "Finished training for epoch 91, loss: 0.333\n",
      "Finished training for epoch 92, loss: 0.322\n",
      "Finished training for epoch 93, loss: 0.316\n",
      "Finished training for epoch 94, loss: 0.331\n",
      "Finished training for epoch 95, loss: 0.311\n",
      "Finished training for epoch 96, loss: 0.311\n",
      "Finished training for epoch 97, loss: 0.314\n",
      "Finished training for epoch 98, loss: 0.316\n",
      "Finished training for epoch 99, loss: 0.316\n",
      "Finished training for epoch 100, loss: 0.319\n",
      "Finished training for epoch 101, loss: 0.318\n",
      "Finished training for epoch 102, loss: 0.314\n",
      "Finished training for epoch 103, loss: 0.307\n",
      "Finished training for epoch 104, loss: 0.306\n",
      "Finished training for epoch 105, loss: 0.321\n",
      "Finished training for epoch 106, loss: 0.320\n",
      "Finished training for epoch 107, loss: 0.315\n",
      "Finished training for epoch 108, loss: 0.308\n",
      "Finished training for epoch 109, loss: 0.312\n",
      "Finished training for epoch 110, loss: 0.326\n",
      "Finished training for epoch 111, loss: 0.318\n",
      "Finished training for epoch 112, loss: 0.321\n",
      "Finished training for epoch 113, loss: 0.317\n",
      "Finished training for epoch 114, loss: 0.327\n",
      "Finished training for epoch 115, loss: 0.330\n",
      "Finished training for epoch 116, loss: 0.309\n",
      "Finished training for epoch 117, loss: 0.309\n",
      "Finished training for epoch 118, loss: 0.311\n",
      "Finished training for epoch 119, loss: 0.313\n",
      "Finished training for epoch 120, loss: 0.314\n",
      "Finished training for epoch 121, loss: 0.312\n",
      "Finished training for epoch 122, loss: 0.309\n",
      "Finished training for epoch 123, loss: 0.310\n",
      "Finished training for epoch 124, loss: 0.303\n",
      "Finished training for epoch 125, loss: 0.304\n",
      "Finished training for epoch 126, loss: 0.305\n",
      "Finished training for epoch 127, loss: 0.314\n",
      "Finished training for epoch 128, loss: 0.312\n",
      "Finished training for epoch 129, loss: 0.313\n",
      "Finished training for epoch 130, loss: 0.314\n",
      "Finished training for epoch 131, loss: 0.309\n",
      "Finished training for epoch 132, loss: 0.322\n",
      "Finished training for epoch 133, loss: 0.306\n",
      "Finished training for epoch 134, loss: 0.307\n",
      "Finished training for epoch 135, loss: 0.306\n",
      "Finished training for epoch 136, loss: 0.309\n",
      "Finished training for epoch 137, loss: 0.308\n",
      "Finished training for epoch 138, loss: 0.303\n",
      "Finished training for epoch 139, loss: 0.312\n",
      "Finished training for epoch 140, loss: 0.319\n",
      "Finished training for epoch 141, loss: 0.305\n",
      "Finished training for epoch 142, loss: 0.313\n",
      "Finished training for epoch 143, loss: 0.326\n",
      "Finished training for epoch 144, loss: 0.307\n",
      "Finished training for epoch 145, loss: 0.308\n",
      "Finished training for epoch 146, loss: 0.313\n",
      "Finished training for epoch 147, loss: 0.307\n",
      "Finished training for epoch 148, loss: 0.307\n",
      "Finished training for epoch 149, loss: 0.329\n",
      "Finished training for epoch 150, loss: 0.310\n",
      "Finished training for epoch 151, loss: 0.305\n",
      "Finished training for epoch 152, loss: 0.301\n",
      "Finished training for epoch 153, loss: 0.301\n",
      "Finished training for epoch 154, loss: 0.304\n",
      "Finished training for epoch 155, loss: 0.307\n",
      "Finished training for epoch 156, loss: 0.303\n",
      "Finished training for epoch 157, loss: 0.308\n",
      "Finished training for epoch 158, loss: 0.313\n",
      "Finished training for epoch 159, loss: 0.303\n",
      "Finished training for epoch 160, loss: 0.302\n",
      "Finished training for epoch 161, loss: 0.301\n",
      "Finished training for epoch 162, loss: 0.315\n",
      "Finished training for epoch 163, loss: 0.303\n",
      "Finished training for epoch 164, loss: 0.304\n",
      "Finished training for epoch 165, loss: 0.302\n",
      "Finished training for epoch 166, loss: 0.302\n",
      "Finished training for epoch 167, loss: 0.307\n",
      "Finished training for epoch 168, loss: 0.297\n",
      "Finished training for epoch 169, loss: 0.299\n",
      "Finished training for epoch 170, loss: 0.305\n",
      "Finished training for epoch 171, loss: 0.305\n",
      "Finished training for epoch 172, loss: 0.309\n",
      "Finished training for epoch 173, loss: 0.310\n",
      "Finished training for epoch 174, loss: 0.312\n",
      "Finished training for epoch 175, loss: 0.317\n",
      "Finished training for epoch 176, loss: 0.300\n",
      "Finished training for epoch 177, loss: 0.305\n",
      "Finished training for epoch 178, loss: 0.299\n",
      "Finished training for epoch 179, loss: 0.307\n",
      "Finished training for epoch 180, loss: 0.325\n",
      "Finished training for epoch 181, loss: 0.305\n",
      "Finished training for epoch 182, loss: 0.303\n",
      "Finished training for epoch 183, loss: 0.300\n",
      "Finished training for epoch 184, loss: 0.311\n",
      "Finished training for epoch 185, loss: 0.320\n",
      "Finished training for epoch 186, loss: 0.302\n",
      "Finished training for epoch 187, loss: 0.313\n",
      "Finished training for epoch 188, loss: 0.310\n",
      "Finished training for epoch 189, loss: 0.294\n",
      "Finished training for epoch 190, loss: 0.293\n",
      "Finished training for epoch 191, loss: 0.298\n",
      "Finished training for epoch 192, loss: 0.317\n",
      "Finished training for epoch 193, loss: 0.296\n",
      "Finished training for epoch 194, loss: 0.298\n",
      "Finished training for epoch 195, loss: 0.303\n",
      "Finished training for epoch 196, loss: 0.303\n",
      "Finished training for epoch 197, loss: 0.307\n",
      "Finished training for epoch 198, loss: 0.326\n",
      "Finished training for epoch 199, loss: 0.310\n",
      "Finished training for epoch 200, loss: 0.311\n",
      "Finished training for epoch 201, loss: 0.309\n",
      "Finished training for epoch 202, loss: 0.303\n",
      "Finished training for epoch 203, loss: 0.312\n",
      "Finished training for epoch 204, loss: 0.298\n",
      "Finished training for epoch 205, loss: 0.297\n",
      "Finished training for epoch 206, loss: 0.294\n",
      "Finished training for epoch 207, loss: 0.291\n",
      "Finished training for epoch 208, loss: 0.304\n",
      "Finished training for epoch 209, loss: 0.304\n",
      "Finished training for epoch 210, loss: 0.307\n",
      "Finished training for epoch 211, loss: 0.298\n",
      "Finished training for epoch 212, loss: 0.312\n",
      "Finished training for epoch 213, loss: 0.301\n",
      "Finished training for epoch 214, loss: 0.297\n",
      "Finished training for epoch 215, loss: 0.297\n",
      "Finished training for epoch 216, loss: 0.304\n",
      "Finished training for epoch 217, loss: 0.299\n",
      "Finished training for epoch 218, loss: 0.308\n",
      "Finished training for epoch 219, loss: 0.299\n",
      "Finished training for epoch 220, loss: 0.303\n",
      "Finished training for epoch 221, loss: 0.299\n",
      "Finished training for epoch 222, loss: 0.301\n",
      "Finished training for epoch 223, loss: 0.291\n",
      "Finished training for epoch 224, loss: 0.297\n",
      "Finished training for epoch 225, loss: 0.296\n",
      "Finished training for epoch 226, loss: 0.294\n",
      "Finished training for epoch 227, loss: 0.297\n",
      "Finished training for epoch 228, loss: 0.295\n",
      "Finished training for epoch 229, loss: 0.298\n",
      "Finished training for epoch 230, loss: 0.324\n",
      "Finished training for epoch 231, loss: 0.293\n",
      "Finished training for epoch 232, loss: 0.303\n",
      "Finished training for epoch 233, loss: 0.291\n",
      "Finished training for epoch 234, loss: 0.311\n",
      "Finished training for epoch 235, loss: 0.308\n",
      "Finished training for epoch 236, loss: 0.294\n",
      "Finished training for epoch 237, loss: 0.309\n",
      "Finished training for epoch 238, loss: 0.290\n",
      "Finished training for epoch 239, loss: 0.292\n",
      "Finished training for epoch 240, loss: 0.293\n",
      "Finished training for epoch 241, loss: 0.296\n",
      "Finished training for epoch 242, loss: 0.302\n",
      "Finished training for epoch 243, loss: 0.296\n",
      "Finished training for epoch 244, loss: 0.299\n",
      "Finished training for epoch 245, loss: 0.288\n",
      "Finished training for epoch 246, loss: 0.294\n",
      "Finished training for epoch 247, loss: 0.289\n",
      "Finished training for epoch 248, loss: 0.287\n",
      "Finished training for epoch 249, loss: 0.296\n",
      "Finished training for epoch 250, loss: 0.290\n",
      "Finished training for epoch 251, loss: 0.293\n",
      "Finished training for epoch 252, loss: 0.299\n",
      "Finished training for epoch 253, loss: 0.290\n",
      "Finished training for epoch 254, loss: 0.298\n",
      "Finished training for epoch 255, loss: 0.295\n",
      "Finished training for epoch 256, loss: 0.290\n",
      "Finished training for epoch 257, loss: 0.290\n",
      "Finished training for epoch 258, loss: 0.293\n",
      "Finished training for epoch 259, loss: 0.281\n",
      "Finished training for epoch 260, loss: 0.289\n",
      "Finished training for epoch 261, loss: 0.290\n",
      "Finished training for epoch 262, loss: 0.296\n",
      "Finished training for epoch 263, loss: 0.283\n",
      "Finished training for epoch 264, loss: 0.318\n",
      "Finished training for epoch 265, loss: 0.289\n",
      "Finished training for epoch 266, loss: 0.288\n",
      "Finished training for epoch 267, loss: 0.311\n",
      "Finished training for epoch 268, loss: 0.307\n",
      "Finished training for epoch 269, loss: 0.315\n",
      "Finished training for epoch 270, loss: 0.287\n",
      "Finished training for epoch 271, loss: 0.293\n",
      "Finished training for epoch 272, loss: 0.283\n",
      "Finished training for epoch 273, loss: 0.287\n",
      "Finished training for epoch 274, loss: 0.291\n",
      "Finished training for epoch 275, loss: 0.285\n",
      "Finished training for epoch 276, loss: 0.289\n",
      "Finished training for epoch 277, loss: 0.293\n",
      "Finished training for epoch 278, loss: 0.287\n",
      "Finished training for epoch 279, loss: 0.288\n",
      "Finished training for epoch 280, loss: 0.297\n",
      "Finished training for epoch 281, loss: 0.287\n",
      "Finished training for epoch 282, loss: 0.313\n",
      "Finished training for epoch 283, loss: 0.317\n",
      "Finished training for epoch 284, loss: 0.297\n",
      "Finished training for epoch 285, loss: 0.284\n",
      "Finished training for epoch 286, loss: 0.289\n",
      "Finished training for epoch 287, loss: 0.287\n",
      "Finished training for epoch 288, loss: 0.289\n",
      "Finished training for epoch 289, loss: 0.286\n",
      "Finished training for epoch 290, loss: 0.293\n",
      "Finished training for epoch 291, loss: 0.284\n",
      "Finished training for epoch 292, loss: 0.294\n",
      "Finished training for epoch 293, loss: 0.286\n",
      "Finished training for epoch 294, loss: 0.287\n",
      "Finished training for epoch 295, loss: 0.290\n",
      "Finished training for epoch 296, loss: 0.284\n",
      "Finished training for epoch 297, loss: 0.288\n",
      "Finished training for epoch 298, loss: 0.288\n",
      "Finished training for epoch 299, loss: 0.279\n",
      "Finished training for epoch 300, loss: 0.286\n",
      "Finished training for epoch 301, loss: 0.285\n",
      "Finished training for epoch 302, loss: 0.290\n",
      "Finished training for epoch 303, loss: 0.285\n",
      "Finished training for epoch 304, loss: 0.294\n",
      "Finished training for epoch 305, loss: 0.284\n",
      "Finished training for epoch 306, loss: 0.292\n",
      "Finished training for epoch 307, loss: 0.281\n",
      "Finished training for epoch 308, loss: 0.299\n",
      "Finished training for epoch 309, loss: 0.312\n",
      "Finished training for epoch 310, loss: 0.286\n",
      "Finished training for epoch 311, loss: 0.276\n",
      "Finished training for epoch 312, loss: 0.289\n",
      "Finished training for epoch 313, loss: 0.310\n",
      "Finished training for epoch 314, loss: 0.292\n",
      "Finished training for epoch 315, loss: 0.282\n",
      "Finished training for epoch 316, loss: 0.298\n",
      "Finished training for epoch 317, loss: 0.298\n",
      "Finished training for epoch 318, loss: 0.297\n",
      "Finished training for epoch 319, loss: 0.293\n",
      "Finished training for epoch 320, loss: 0.313\n",
      "Finished training for epoch 321, loss: 0.276\n",
      "Finished training for epoch 322, loss: 0.298\n",
      "Finished training for epoch 323, loss: 0.289\n",
      "Finished training for epoch 324, loss: 0.284\n",
      "Finished training for epoch 325, loss: 0.289\n",
      "Finished training for epoch 326, loss: 0.288\n",
      "Finished training for epoch 327, loss: 0.280\n",
      "Finished training for epoch 328, loss: 0.280\n",
      "Finished training for epoch 329, loss: 0.282\n",
      "Finished training for epoch 330, loss: 0.296\n",
      "Finished training for epoch 331, loss: 0.294\n",
      "Finished training for epoch 332, loss: 0.279\n",
      "Finished training for epoch 333, loss: 0.291\n",
      "Finished training for epoch 334, loss: 0.293\n",
      "Finished training for epoch 335, loss: 0.277\n",
      "Finished training for epoch 336, loss: 0.286\n",
      "Finished training for epoch 337, loss: 0.282\n",
      "Finished training for epoch 338, loss: 0.274\n",
      "Finished training for epoch 339, loss: 0.291\n",
      "Finished training for epoch 340, loss: 0.296\n",
      "Finished training for epoch 341, loss: 0.284\n",
      "Finished training for epoch 342, loss: 0.284\n",
      "Finished training for epoch 343, loss: 0.280\n",
      "Finished training for epoch 344, loss: 0.280\n",
      "Finished training for epoch 345, loss: 0.277\n",
      "Finished training for epoch 346, loss: 0.296\n",
      "Finished training for epoch 347, loss: 0.291\n",
      "Finished training for epoch 348, loss: 0.289\n",
      "Finished training for epoch 349, loss: 0.279\n",
      "Finished training for epoch 350, loss: 0.280\n",
      "Finished training for epoch 351, loss: 0.288\n",
      "Finished training for epoch 352, loss: 0.275\n",
      "Finished training for epoch 353, loss: 0.285\n",
      "Finished training for epoch 354, loss: 0.280\n",
      "Finished training for epoch 355, loss: 0.282\n",
      "Finished training for epoch 356, loss: 0.270\n",
      "Finished training for epoch 357, loss: 0.283\n",
      "Finished training for epoch 358, loss: 0.278\n",
      "Finished training for epoch 359, loss: 0.277\n",
      "Finished training for epoch 360, loss: 0.276\n",
      "Finished training for epoch 361, loss: 0.273\n",
      "Finished training for epoch 362, loss: 0.274\n",
      "Finished training for epoch 363, loss: 0.283\n",
      "Finished training for epoch 364, loss: 0.276\n",
      "Finished training for epoch 365, loss: 0.292\n",
      "Finished training for epoch 366, loss: 0.276\n",
      "Finished training for epoch 367, loss: 0.278\n",
      "Finished training for epoch 368, loss: 0.278\n",
      "Finished training for epoch 369, loss: 0.277\n",
      "Finished training for epoch 370, loss: 0.280\n",
      "Finished training for epoch 371, loss: 0.285\n",
      "Finished training for epoch 372, loss: 0.310\n",
      "Finished training for epoch 373, loss: 0.290\n",
      "Finished training for epoch 374, loss: 0.280\n",
      "Finished training for epoch 375, loss: 0.275\n",
      "Finished training for epoch 376, loss: 0.266\n",
      "Finished training for epoch 377, loss: 0.300\n",
      "Finished training for epoch 378, loss: 0.282\n",
      "Finished training for epoch 379, loss: 0.268\n",
      "Finished training for epoch 380, loss: 0.302\n",
      "Finished training for epoch 381, loss: 0.271\n",
      "Finished training for epoch 382, loss: 0.319\n",
      "Finished training for epoch 383, loss: 0.298\n",
      "Finished training for epoch 384, loss: 0.271\n",
      "Finished training for epoch 385, loss: 0.280\n",
      "Finished training for epoch 386, loss: 0.281\n",
      "Finished training for epoch 387, loss: 0.282\n",
      "Finished training for epoch 388, loss: 0.287\n",
      "Finished training for epoch 389, loss: 0.282\n",
      "Finished training for epoch 390, loss: 0.279\n",
      "Finished training for epoch 391, loss: 0.265\n",
      "Finished training for epoch 392, loss: 0.290\n",
      "Finished training for epoch 393, loss: 0.286\n",
      "Finished training for epoch 394, loss: 0.277\n",
      "Finished training for epoch 395, loss: 0.269\n",
      "Finished training for epoch 396, loss: 0.281\n",
      "Finished training for epoch 397, loss: 0.278\n",
      "Finished training for epoch 398, loss: 0.268\n",
      "Finished training for epoch 399, loss: 0.273\n",
      "Finished training for epoch 400, loss: 0.269\n",
      "Finished training for epoch 401, loss: 0.261\n",
      "Finished training for epoch 402, loss: 0.262\n",
      "Finished training for epoch 403, loss: 0.273\n",
      "Finished training for epoch 404, loss: 0.280\n",
      "Finished training for epoch 405, loss: 0.264\n",
      "Finished training for epoch 406, loss: 0.267\n",
      "Finished training for epoch 407, loss: 0.280\n",
      "Finished training for epoch 408, loss: 0.275\n",
      "Finished training for epoch 409, loss: 0.257\n",
      "Finished training for epoch 410, loss: 0.273\n",
      "Finished training for epoch 411, loss: 0.281\n",
      "Finished training for epoch 412, loss: 0.276\n",
      "Finished training for epoch 413, loss: 0.286\n",
      "Finished training for epoch 414, loss: 0.271\n",
      "Finished training for epoch 415, loss: 0.277\n",
      "Finished training for epoch 416, loss: 0.276\n",
      "Finished training for epoch 417, loss: 0.275\n",
      "Finished training for epoch 418, loss: 0.269\n",
      "Finished training for epoch 419, loss: 0.276\n",
      "Finished training for epoch 420, loss: 0.289\n",
      "Finished training for epoch 421, loss: 0.273\n",
      "Finished training for epoch 422, loss: 0.264\n",
      "Finished training for epoch 423, loss: 0.269\n",
      "Finished training for epoch 424, loss: 0.281\n",
      "Finished training for epoch 425, loss: 0.276\n",
      "Finished training for epoch 426, loss: 0.269\n",
      "Finished training for epoch 427, loss: 0.278\n",
      "Finished training for epoch 428, loss: 0.282\n",
      "Finished training for epoch 429, loss: 0.266\n",
      "Finished training for epoch 430, loss: 0.289\n",
      "Finished training for epoch 431, loss: 0.265\n",
      "Finished training for epoch 432, loss: 0.273\n",
      "Finished training for epoch 433, loss: 0.276\n",
      "Finished training for epoch 434, loss: 0.267\n",
      "Finished training for epoch 435, loss: 0.265\n",
      "Finished training for epoch 436, loss: 0.258\n",
      "Finished training for epoch 437, loss: 0.252\n",
      "Finished training for epoch 438, loss: 0.284\n",
      "Finished training for epoch 439, loss: 0.268\n",
      "Finished training for epoch 440, loss: 0.265\n",
      "Finished training for epoch 441, loss: 0.266\n",
      "Finished training for epoch 442, loss: 0.274\n",
      "Finished training for epoch 443, loss: 0.256\n",
      "Finished training for epoch 444, loss: 0.252\n",
      "Finished training for epoch 445, loss: 0.262\n",
      "Finished training for epoch 446, loss: 0.252\n",
      "Finished training for epoch 447, loss: 0.282\n",
      "Finished training for epoch 448, loss: 0.274\n",
      "Finished training for epoch 449, loss: 0.270\n",
      "Finished training for epoch 450, loss: 0.263\n",
      "Finished training for epoch 451, loss: 0.268\n",
      "Finished training for epoch 452, loss: 0.262\n",
      "Finished training for epoch 453, loss: 0.273\n",
      "Finished training for epoch 454, loss: 0.262\n",
      "Finished training for epoch 455, loss: 0.255\n",
      "Finished training for epoch 456, loss: 0.265\n",
      "Finished training for epoch 457, loss: 0.281\n",
      "Finished training for epoch 458, loss: 0.279\n",
      "Finished training for epoch 459, loss: 0.279\n",
      "Finished training for epoch 460, loss: 0.258\n",
      "Finished training for epoch 461, loss: 0.249\n",
      "Finished training for epoch 462, loss: 0.259\n",
      "Finished training for epoch 463, loss: 0.266\n",
      "Finished training for epoch 464, loss: 0.280\n",
      "Finished training for epoch 465, loss: 0.253\n",
      "Finished training for epoch 466, loss: 0.280\n",
      "Finished training for epoch 467, loss: 0.294\n",
      "Finished training for epoch 468, loss: 0.272\n",
      "Finished training for epoch 469, loss: 0.268\n",
      "Finished training for epoch 470, loss: 0.274\n",
      "Finished training for epoch 471, loss: 0.260\n",
      "Finished training for epoch 472, loss: 0.274\n",
      "Finished training for epoch 473, loss: 0.277\n",
      "Finished training for epoch 474, loss: 0.258\n",
      "Finished training for epoch 475, loss: 0.253\n",
      "Finished training for epoch 476, loss: 0.251\n",
      "Finished training for epoch 477, loss: 0.253\n",
      "Finished training for epoch 478, loss: 0.252\n",
      "Finished training for epoch 479, loss: 0.272\n",
      "Finished training for epoch 480, loss: 0.247\n",
      "Finished training for epoch 481, loss: 0.269\n",
      "Finished training for epoch 482, loss: 0.265\n",
      "Finished training for epoch 483, loss: 0.249\n",
      "Finished training for epoch 484, loss: 0.271\n",
      "Finished training for epoch 485, loss: 0.259\n",
      "Finished training for epoch 486, loss: 0.259\n",
      "Finished training for epoch 487, loss: 0.258\n",
      "Finished training for epoch 488, loss: 0.260\n",
      "Finished training for epoch 489, loss: 0.279\n",
      "Finished training for epoch 490, loss: 0.244\n",
      "Finished training for epoch 491, loss: 0.274\n",
      "Finished training for epoch 492, loss: 0.256\n",
      "Finished training for epoch 493, loss: 0.244\n",
      "Finished training for epoch 494, loss: 0.247\n",
      "Finished training for epoch 495, loss: 0.243\n",
      "Finished training for epoch 496, loss: 0.249\n",
      "Finished training for epoch 497, loss: 0.260\n",
      "Finished training for epoch 498, loss: 0.269\n",
      "Finished training for epoch 499, loss: 0.257\n",
      "Finished training for epoch 500, loss: 0.262\n",
      "Finished training for epoch 501, loss: 0.266\n",
      "Finished training for epoch 502, loss: 0.278\n",
      "Finished training for epoch 503, loss: 0.278\n",
      "Finished training for epoch 504, loss: 0.256\n",
      "Finished training for epoch 505, loss: 0.242\n",
      "Finished training for epoch 506, loss: 0.255\n",
      "Finished training for epoch 507, loss: 0.294\n",
      "Finished training for epoch 508, loss: 0.250\n",
      "Finished training for epoch 509, loss: 0.279\n",
      "Finished training for epoch 510, loss: 0.240\n",
      "Finished training for epoch 511, loss: 0.277\n",
      "Finished training for epoch 512, loss: 0.255\n",
      "Finished training for epoch 513, loss: 0.239\n",
      "Finished training for epoch 514, loss: 0.256\n",
      "Finished training for epoch 515, loss: 0.263\n",
      "Finished training for epoch 516, loss: 0.269\n",
      "Finished training for epoch 517, loss: 0.259\n",
      "Finished training for epoch 518, loss: 0.247\n",
      "Finished training for epoch 519, loss: 0.243\n",
      "Finished training for epoch 520, loss: 0.263\n",
      "Finished training for epoch 521, loss: 0.250\n",
      "Finished training for epoch 522, loss: 0.283\n",
      "Finished training for epoch 523, loss: 0.253\n",
      "Finished training for epoch 524, loss: 0.243\n",
      "Finished training for epoch 525, loss: 0.273\n",
      "Finished training for epoch 526, loss: 0.265\n",
      "Finished training for epoch 527, loss: 0.240\n",
      "Finished training for epoch 528, loss: 0.261\n",
      "Finished training for epoch 529, loss: 0.258\n",
      "Finished training for epoch 530, loss: 0.263\n",
      "Finished training for epoch 531, loss: 0.266\n",
      "Finished training for epoch 532, loss: 0.239\n",
      "Finished training for epoch 533, loss: 0.255\n",
      "Finished training for epoch 534, loss: 0.252\n",
      "Finished training for epoch 535, loss: 0.240\n",
      "Finished training for epoch 536, loss: 0.261\n",
      "Finished training for epoch 537, loss: 0.247\n",
      "Finished training for epoch 538, loss: 0.262\n",
      "Finished training for epoch 539, loss: 0.247\n",
      "Finished training for epoch 540, loss: 0.243\n",
      "Finished training for epoch 541, loss: 0.267\n",
      "Finished training for epoch 542, loss: 0.250\n",
      "Finished training for epoch 543, loss: 0.247\n",
      "Finished training for epoch 544, loss: 0.272\n",
      "Finished training for epoch 545, loss: 0.250\n",
      "Finished training for epoch 546, loss: 0.250\n",
      "Finished training for epoch 547, loss: 0.267\n",
      "Finished training for epoch 548, loss: 0.246\n",
      "Finished training for epoch 549, loss: 0.234\n",
      "Finished training for epoch 550, loss: 0.267\n",
      "Finished training for epoch 551, loss: 0.263\n",
      "Finished training for epoch 552, loss: 0.250\n",
      "Finished training for epoch 553, loss: 0.303\n",
      "Finished training for epoch 554, loss: 0.256\n",
      "Finished training for epoch 555, loss: 0.244\n",
      "Finished training for epoch 556, loss: 0.247\n",
      "Finished training for epoch 557, loss: 0.265\n",
      "Finished training for epoch 558, loss: 0.235\n",
      "Finished training for epoch 559, loss: 0.232\n",
      "Finished training for epoch 560, loss: 0.239\n",
      "Finished training for epoch 561, loss: 0.241\n",
      "Finished training for epoch 562, loss: 0.264\n",
      "Finished training for epoch 563, loss: 0.289\n",
      "Finished training for epoch 564, loss: 0.257\n",
      "Finished training for epoch 565, loss: 0.231\n",
      "Finished training for epoch 566, loss: 0.249\n",
      "Finished training for epoch 567, loss: 0.244\n",
      "Finished training for epoch 568, loss: 0.259\n",
      "Finished training for epoch 569, loss: 0.245\n",
      "Finished training for epoch 570, loss: 0.288\n",
      "Finished training for epoch 571, loss: 0.269\n",
      "Finished training for epoch 572, loss: 0.241\n",
      "Finished training for epoch 573, loss: 0.239\n",
      "Finished training for epoch 574, loss: 0.252\n",
      "Finished training for epoch 575, loss: 0.238\n",
      "Finished training for epoch 576, loss: 0.249\n",
      "Finished training for epoch 577, loss: 0.236\n",
      "Finished training for epoch 578, loss: 0.246\n",
      "Finished training for epoch 579, loss: 0.277\n",
      "Finished training for epoch 580, loss: 0.224\n",
      "Finished training for epoch 581, loss: 0.260\n",
      "Finished training for epoch 582, loss: 0.236\n",
      "Finished training for epoch 583, loss: 0.234\n",
      "Finished training for epoch 584, loss: 0.270\n",
      "Finished training for epoch 585, loss: 0.240\n",
      "Finished training for epoch 586, loss: 0.222\n",
      "Finished training for epoch 587, loss: 0.263\n",
      "Finished training for epoch 588, loss: 0.268\n",
      "Finished training for epoch 589, loss: 0.223\n",
      "Finished training for epoch 590, loss: 0.230\n",
      "Finished training for epoch 591, loss: 0.280\n",
      "Finished training for epoch 592, loss: 0.259\n",
      "Finished training for epoch 593, loss: 0.228\n",
      "Finished training for epoch 594, loss: 0.229\n",
      "Finished training for epoch 595, loss: 0.219\n",
      "Finished training for epoch 596, loss: 0.258\n",
      "Finished training for epoch 597, loss: 0.246\n",
      "Finished training for epoch 598, loss: 0.248\n",
      "Finished training for epoch 599, loss: 0.248\n",
      "Finished training for epoch 600, loss: 0.230\n",
      "Finished training for epoch 601, loss: 0.250\n",
      "Finished training for epoch 602, loss: 0.215\n",
      "Finished training for epoch 603, loss: 0.238\n",
      "Finished training for epoch 604, loss: 0.241\n",
      "Finished training for epoch 605, loss: 0.225\n",
      "Finished training for epoch 606, loss: 0.242\n",
      "Finished training for epoch 607, loss: 0.227\n",
      "Finished training for epoch 608, loss: 0.219\n",
      "Finished training for epoch 609, loss: 0.240\n",
      "Finished training for epoch 610, loss: 0.230\n",
      "Finished training for epoch 611, loss: 0.227\n",
      "Finished training for epoch 612, loss: 0.237\n",
      "Finished training for epoch 613, loss: 0.220\n",
      "Finished training for epoch 614, loss: 0.265\n",
      "Finished training for epoch 615, loss: 0.230\n",
      "Finished training for epoch 616, loss: 0.226\n",
      "Finished training for epoch 617, loss: 0.237\n",
      "Finished training for epoch 618, loss: 0.235\n",
      "Finished training for epoch 619, loss: 0.230\n",
      "Finished training for epoch 620, loss: 0.265\n",
      "Finished training for epoch 621, loss: 0.215\n",
      "Finished training for epoch 622, loss: 0.249\n",
      "Finished training for epoch 623, loss: 0.231\n",
      "Finished training for epoch 624, loss: 0.215\n",
      "Finished training for epoch 625, loss: 0.248\n",
      "Finished training for epoch 626, loss: 0.225\n",
      "Finished training for epoch 627, loss: 0.248\n",
      "Finished training for epoch 628, loss: 0.250\n",
      "Finished training for epoch 629, loss: 0.251\n",
      "Finished training for epoch 630, loss: 0.243\n",
      "Finished training for epoch 631, loss: 0.211\n",
      "Finished training for epoch 632, loss: 0.235\n",
      "Finished training for epoch 633, loss: 0.264\n",
      "Finished training for epoch 634, loss: 0.240\n",
      "Finished training for epoch 635, loss: 0.231\n",
      "Finished training for epoch 636, loss: 0.239\n",
      "Finished training for epoch 637, loss: 0.218\n",
      "Finished training for epoch 638, loss: 0.229\n",
      "Finished training for epoch 639, loss: 0.249\n",
      "Finished training for epoch 640, loss: 0.240\n",
      "Finished training for epoch 641, loss: 0.229\n",
      "Finished training for epoch 642, loss: 0.243\n",
      "Finished training for epoch 643, loss: 0.249\n",
      "Finished training for epoch 644, loss: 0.241\n",
      "Finished training for epoch 645, loss: 0.227\n",
      "Finished training for epoch 646, loss: 0.237\n",
      "Finished training for epoch 647, loss: 0.218\n",
      "Finished training for epoch 648, loss: 0.227\n",
      "Finished training for epoch 649, loss: 0.214\n",
      "Finished training for epoch 650, loss: 0.239\n",
      "Finished training for epoch 651, loss: 0.226\n",
      "Finished training for epoch 652, loss: 0.209\n",
      "Finished training for epoch 653, loss: 0.233\n",
      "Finished training for epoch 654, loss: 0.206\n",
      "Finished training for epoch 655, loss: 0.252\n",
      "Finished training for epoch 656, loss: 0.204\n",
      "Finished training for epoch 657, loss: 0.218\n",
      "Finished training for epoch 658, loss: 0.233\n",
      "Finished training for epoch 659, loss: 0.214\n",
      "Finished training for epoch 660, loss: 0.283\n",
      "Finished training for epoch 661, loss: 0.245\n",
      "Finished training for epoch 662, loss: 0.250\n",
      "Finished training for epoch 663, loss: 0.257\n",
      "Finished training for epoch 664, loss: 0.241\n",
      "Finished training for epoch 665, loss: 0.245\n",
      "Finished training for epoch 666, loss: 0.211\n",
      "Finished training for epoch 667, loss: 0.216\n",
      "Finished training for epoch 668, loss: 0.235\n",
      "Finished training for epoch 669, loss: 0.275\n",
      "Finished training for epoch 670, loss: 0.249\n",
      "Finished training for epoch 671, loss: 0.306\n",
      "Finished training for epoch 672, loss: 0.301\n",
      "Finished training for epoch 673, loss: 0.215\n",
      "Finished training for epoch 674, loss: 0.219\n",
      "Finished training for epoch 675, loss: 0.221\n",
      "Finished training for epoch 676, loss: 0.232\n",
      "Finished training for epoch 677, loss: 0.230\n",
      "Finished training for epoch 678, loss: 0.238\n",
      "Finished training for epoch 679, loss: 0.221\n",
      "Finished training for epoch 680, loss: 0.211\n",
      "Finished training for epoch 681, loss: 0.211\n",
      "Finished training for epoch 682, loss: 0.226\n",
      "Finished training for epoch 683, loss: 0.226\n",
      "Finished training for epoch 684, loss: 0.210\n",
      "Finished training for epoch 685, loss: 0.212\n",
      "Finished training for epoch 686, loss: 0.283\n",
      "Finished training for epoch 687, loss: 0.229\n",
      "Finished training for epoch 688, loss: 0.229\n",
      "Finished training for epoch 689, loss: 0.225\n",
      "Finished training for epoch 690, loss: 0.246\n",
      "Finished training for epoch 691, loss: 0.216\n",
      "Finished training for epoch 692, loss: 0.249\n",
      "Finished training for epoch 693, loss: 0.221\n",
      "Finished training for epoch 694, loss: 0.258\n",
      "Finished training for epoch 695, loss: 0.231\n",
      "Finished training for epoch 696, loss: 0.210\n",
      "Finished training for epoch 697, loss: 0.203\n",
      "Finished training for epoch 698, loss: 0.233\n",
      "Finished training for epoch 699, loss: 0.206\n",
      "Finished training for epoch 700, loss: 0.232\n",
      "Finished training for epoch 701, loss: 0.201\n",
      "Finished training for epoch 702, loss: 0.226\n",
      "Finished training for epoch 703, loss: 0.228\n",
      "Finished training for epoch 704, loss: 0.209\n",
      "Finished training for epoch 705, loss: 0.245\n",
      "Finished training for epoch 706, loss: 0.217\n",
      "Finished training for epoch 707, loss: 0.212\n",
      "Finished training for epoch 708, loss: 0.213\n",
      "Finished training for epoch 709, loss: 0.237\n",
      "Finished training for epoch 710, loss: 0.221\n",
      "Finished training for epoch 711, loss: 0.226\n",
      "Finished training for epoch 712, loss: 0.205\n",
      "Finished training for epoch 713, loss: 0.218\n",
      "Finished training for epoch 714, loss: 0.195\n",
      "Finished training for epoch 715, loss: 0.202\n",
      "Finished training for epoch 716, loss: 0.235\n",
      "Finished training for epoch 717, loss: 0.206\n",
      "Finished training for epoch 718, loss: 0.219\n",
      "Finished training for epoch 719, loss: 0.231\n",
      "Finished training for epoch 720, loss: 0.200\n",
      "Finished training for epoch 721, loss: 0.202\n",
      "Finished training for epoch 722, loss: 0.203\n",
      "Finished training for epoch 723, loss: 0.226\n",
      "Finished training for epoch 724, loss: 0.222\n",
      "Finished training for epoch 725, loss: 0.277\n",
      "Finished training for epoch 726, loss: 0.221\n",
      "Finished training for epoch 727, loss: 0.261\n",
      "Finished training for epoch 728, loss: 0.219\n",
      "Finished training for epoch 729, loss: 0.219\n",
      "Finished training for epoch 730, loss: 0.241\n",
      "Finished training for epoch 731, loss: 0.233\n",
      "Finished training for epoch 732, loss: 0.205\n",
      "Finished training for epoch 733, loss: 0.231\n",
      "Finished training for epoch 734, loss: 0.201\n",
      "Finished training for epoch 735, loss: 0.196\n",
      "Finished training for epoch 736, loss: 0.217\n",
      "Finished training for epoch 737, loss: 0.192\n",
      "Finished training for epoch 738, loss: 0.218\n",
      "Finished training for epoch 739, loss: 0.214\n",
      "Finished training for epoch 740, loss: 0.230\n",
      "Finished training for epoch 741, loss: 0.221\n",
      "Finished training for epoch 742, loss: 0.234\n",
      "Finished training for epoch 743, loss: 0.209\n",
      "Finished training for epoch 744, loss: 0.213\n",
      "Finished training for epoch 745, loss: 0.209\n",
      "Finished training for epoch 746, loss: 0.239\n",
      "Finished training for epoch 747, loss: 0.224\n",
      "Finished training for epoch 748, loss: 0.199\n",
      "Finished training for epoch 749, loss: 0.257\n",
      "Finished training for epoch 750, loss: 0.300\n",
      "Finished training for epoch 751, loss: 0.210\n",
      "Finished training for epoch 752, loss: 0.205\n",
      "Finished training for epoch 753, loss: 0.205\n",
      "Finished training for epoch 754, loss: 0.212\n",
      "Finished training for epoch 755, loss: 0.229\n",
      "Finished training for epoch 756, loss: 0.202\n",
      "Finished training for epoch 757, loss: 0.193\n",
      "Finished training for epoch 758, loss: 0.202\n",
      "Finished training for epoch 759, loss: 0.270\n",
      "Finished training for epoch 760, loss: 0.237\n",
      "Finished training for epoch 761, loss: 0.241\n",
      "Finished training for epoch 762, loss: 0.205\n",
      "Finished training for epoch 763, loss: 0.200\n",
      "Finished training for epoch 764, loss: 0.205\n",
      "Finished training for epoch 765, loss: 0.203\n",
      "Finished training for epoch 766, loss: 0.220\n",
      "Finished training for epoch 767, loss: 0.199\n",
      "Finished training for epoch 768, loss: 0.230\n",
      "Finished training for epoch 769, loss: 0.207\n",
      "Finished training for epoch 770, loss: 0.257\n",
      "Finished training for epoch 771, loss: 0.214\n",
      "Finished training for epoch 772, loss: 0.217\n",
      "Finished training for epoch 773, loss: 0.196\n",
      "Finished training for epoch 774, loss: 0.219\n",
      "Finished training for epoch 775, loss: 0.202\n",
      "Finished training for epoch 776, loss: 0.249\n",
      "Finished training for epoch 777, loss: 0.210\n",
      "Finished training for epoch 778, loss: 0.190\n",
      "Finished training for epoch 779, loss: 0.195\n",
      "Finished training for epoch 780, loss: 0.235\n",
      "Finished training for epoch 781, loss: 0.250\n",
      "Finished training for epoch 782, loss: 0.194\n",
      "Finished training for epoch 783, loss: 0.194\n",
      "Finished training for epoch 784, loss: 0.188\n",
      "Finished training for epoch 785, loss: 0.204\n",
      "Finished training for epoch 786, loss: 0.209\n",
      "Finished training for epoch 787, loss: 0.230\n",
      "Finished training for epoch 788, loss: 0.271\n",
      "Finished training for epoch 789, loss: 0.202\n",
      "Finished training for epoch 790, loss: 0.195\n",
      "Finished training for epoch 791, loss: 0.201\n",
      "Finished training for epoch 792, loss: 0.205\n",
      "Finished training for epoch 793, loss: 0.194\n",
      "Finished training for epoch 794, loss: 0.211\n",
      "Finished training for epoch 795, loss: 0.192\n",
      "Finished training for epoch 796, loss: 0.211\n",
      "Finished training for epoch 797, loss: 0.189\n",
      "Finished training for epoch 798, loss: 0.208\n",
      "Finished training for epoch 799, loss: 0.205\n",
      "Finished training for epoch 800, loss: 0.195\n",
      "Finished training for epoch 801, loss: 0.201\n",
      "Finished training for epoch 802, loss: 0.198\n",
      "Finished training for epoch 803, loss: 0.227\n",
      "Finished training for epoch 804, loss: 0.213\n",
      "Finished training for epoch 805, loss: 0.219\n",
      "Finished training for epoch 806, loss: 0.215\n",
      "Finished training for epoch 807, loss: 0.191\n",
      "Finished training for epoch 808, loss: 0.219\n",
      "Finished training for epoch 809, loss: 0.212\n",
      "Finished training for epoch 810, loss: 0.206\n",
      "Finished training for epoch 811, loss: 0.209\n",
      "Finished training for epoch 812, loss: 0.198\n",
      "Finished training for epoch 813, loss: 0.199\n",
      "Finished training for epoch 814, loss: 0.203\n",
      "Finished training for epoch 815, loss: 0.193\n",
      "Finished training for epoch 816, loss: 0.212\n",
      "Finished training for epoch 817, loss: 0.198\n",
      "Finished training for epoch 818, loss: 0.189\n",
      "Finished training for epoch 819, loss: 0.181\n",
      "Finished training for epoch 820, loss: 0.186\n",
      "Finished training for epoch 821, loss: 0.202\n",
      "Finished training for epoch 822, loss: 0.182\n",
      "Finished training for epoch 823, loss: 0.219\n",
      "Finished training for epoch 824, loss: 0.237\n",
      "Finished training for epoch 825, loss: 0.179\n",
      "Finished training for epoch 826, loss: 0.181\n",
      "Finished training for epoch 827, loss: 0.215\n",
      "Finished training for epoch 828, loss: 0.198\n",
      "Finished training for epoch 829, loss: 0.222\n",
      "Finished training for epoch 830, loss: 0.201\n",
      "Finished training for epoch 831, loss: 0.242\n",
      "Finished training for epoch 832, loss: 0.212\n",
      "Finished training for epoch 833, loss: 0.193\n",
      "Finished training for epoch 834, loss: 0.221\n",
      "Finished training for epoch 835, loss: 0.199\n",
      "Finished training for epoch 836, loss: 0.177\n",
      "Finished training for epoch 837, loss: 0.201\n",
      "Finished training for epoch 838, loss: 0.190\n",
      "Finished training for epoch 839, loss: 0.219\n",
      "Finished training for epoch 840, loss: 0.234\n",
      "Finished training for epoch 841, loss: 0.186\n",
      "Finished training for epoch 842, loss: 0.199\n",
      "Finished training for epoch 843, loss: 0.194\n",
      "Finished training for epoch 844, loss: 0.219\n",
      "Finished training for epoch 845, loss: 0.200\n",
      "Finished training for epoch 846, loss: 0.172\n",
      "Finished training for epoch 847, loss: 0.201\n",
      "Finished training for epoch 848, loss: 0.172\n",
      "Finished training for epoch 849, loss: 0.184\n",
      "Finished training for epoch 850, loss: 0.173\n",
      "Finished training for epoch 851, loss: 0.194\n",
      "Finished training for epoch 852, loss: 0.214\n",
      "Finished training for epoch 853, loss: 0.206\n",
      "Finished training for epoch 854, loss: 0.244\n",
      "Finished training for epoch 855, loss: 0.239\n",
      "Finished training for epoch 856, loss: 0.185\n",
      "Finished training for epoch 857, loss: 0.191\n",
      "Finished training for epoch 858, loss: 0.192\n",
      "Finished training for epoch 859, loss: 0.215\n",
      "Finished training for epoch 860, loss: 0.192\n",
      "Finished training for epoch 861, loss: 0.180\n",
      "Finished training for epoch 862, loss: 0.192\n",
      "Finished training for epoch 863, loss: 0.193\n",
      "Finished training for epoch 864, loss: 0.175\n",
      "Finished training for epoch 865, loss: 0.217\n",
      "Finished training for epoch 866, loss: 0.187\n",
      "Finished training for epoch 867, loss: 0.215\n",
      "Finished training for epoch 868, loss: 0.236\n",
      "Finished training for epoch 869, loss: 0.199\n",
      "Finished training for epoch 870, loss: 0.209\n",
      "Finished training for epoch 871, loss: 0.292\n",
      "Finished training for epoch 872, loss: 0.199\n",
      "Finished training for epoch 873, loss: 0.202\n",
      "Finished training for epoch 874, loss: 0.198\n",
      "Finished training for epoch 875, loss: 0.188\n",
      "Finished training for epoch 876, loss: 0.177\n",
      "Finished training for epoch 877, loss: 0.178\n",
      "Finished training for epoch 878, loss: 0.216\n",
      "Finished training for epoch 879, loss: 0.180\n",
      "Finished training for epoch 880, loss: 0.188\n",
      "Finished training for epoch 881, loss: 0.185\n",
      "Finished training for epoch 882, loss: 0.205\n",
      "Finished training for epoch 883, loss: 0.176\n",
      "Finished training for epoch 884, loss: 0.211\n",
      "Finished training for epoch 885, loss: 0.178\n",
      "Finished training for epoch 886, loss: 0.181\n",
      "Finished training for epoch 887, loss: 0.187\n",
      "Finished training for epoch 888, loss: 0.202\n",
      "Finished training for epoch 889, loss: 0.199\n",
      "Finished training for epoch 890, loss: 0.199\n",
      "Finished training for epoch 891, loss: 0.211\n",
      "Finished training for epoch 892, loss: 0.225\n",
      "Finished training for epoch 893, loss: 0.184\n",
      "Finished training for epoch 894, loss: 0.192\n",
      "Finished training for epoch 895, loss: 0.169\n",
      "Finished training for epoch 896, loss: 0.164\n",
      "Finished training for epoch 897, loss: 0.248\n",
      "Finished training for epoch 898, loss: 0.181\n",
      "Finished training for epoch 899, loss: 0.166\n",
      "Finished training for epoch 900, loss: 0.185\n",
      "Finished training for epoch 901, loss: 0.270\n",
      "Finished training for epoch 902, loss: 0.163\n",
      "Finished training for epoch 903, loss: 0.197\n",
      "Finished training for epoch 904, loss: 0.217\n",
      "Finished training for epoch 905, loss: 0.178\n",
      "Finished training for epoch 906, loss: 0.175\n",
      "Finished training for epoch 907, loss: 0.192\n",
      "Finished training for epoch 908, loss: 0.192\n",
      "Finished training for epoch 909, loss: 0.181\n",
      "Finished training for epoch 910, loss: 0.189\n",
      "Finished training for epoch 911, loss: 0.182\n",
      "Finished training for epoch 912, loss: 0.183\n",
      "Finished training for epoch 913, loss: 0.205\n",
      "Finished training for epoch 914, loss: 0.229\n",
      "Finished training for epoch 915, loss: 0.306\n",
      "Finished training for epoch 916, loss: 0.197\n",
      "Finished training for epoch 917, loss: 0.191\n",
      "Finished training for epoch 918, loss: 0.213\n",
      "Finished training for epoch 919, loss: 0.201\n",
      "Finished training for epoch 920, loss: 0.198\n",
      "Finished training for epoch 921, loss: 0.217\n",
      "Finished training for epoch 922, loss: 0.189\n",
      "Finished training for epoch 923, loss: 0.179\n",
      "Finished training for epoch 924, loss: 0.198\n",
      "Finished training for epoch 925, loss: 0.174\n",
      "Finished training for epoch 926, loss: 0.259\n",
      "Finished training for epoch 927, loss: 0.204\n",
      "Finished training for epoch 928, loss: 0.194\n",
      "Finished training for epoch 929, loss: 0.214\n",
      "Finished training for epoch 930, loss: 0.161\n",
      "Finished training for epoch 931, loss: 0.185\n",
      "Finished training for epoch 932, loss: 0.172\n",
      "Finished training for epoch 933, loss: 0.244\n",
      "Finished training for epoch 934, loss: 0.234\n",
      "Finished training for epoch 935, loss: 0.193\n",
      "Finished training for epoch 936, loss: 0.175\n",
      "Finished training for epoch 937, loss: 0.181\n",
      "Finished training for epoch 938, loss: 0.212\n",
      "Finished training for epoch 939, loss: 0.188\n",
      "Finished training for epoch 940, loss: 0.195\n",
      "Finished training for epoch 941, loss: 0.170\n",
      "Finished training for epoch 942, loss: 0.204\n",
      "Finished training for epoch 943, loss: 0.183\n",
      "Finished training for epoch 944, loss: 0.173\n",
      "Finished training for epoch 945, loss: 0.191\n",
      "Finished training for epoch 946, loss: 0.185\n",
      "Finished training for epoch 947, loss: 0.186\n",
      "Finished training for epoch 948, loss: 0.191\n",
      "Finished training for epoch 949, loss: 0.184\n",
      "Finished training for epoch 950, loss: 0.252\n",
      "Finished training for epoch 951, loss: 0.163\n",
      "Finished training for epoch 952, loss: 0.183\n",
      "Finished training for epoch 953, loss: 0.204\n",
      "Finished training for epoch 954, loss: 0.207\n",
      "Finished training for epoch 955, loss: 0.187\n",
      "Finished training for epoch 956, loss: 0.168\n",
      "Finished training for epoch 957, loss: 0.184\n",
      "Finished training for epoch 958, loss: 0.177\n",
      "Finished training for epoch 959, loss: 0.185\n",
      "Finished training for epoch 960, loss: 0.175\n",
      "Finished training for epoch 961, loss: 0.178\n",
      "Finished training for epoch 962, loss: 0.197\n",
      "Finished training for epoch 963, loss: 0.160\n",
      "Finished training for epoch 964, loss: 0.242\n",
      "Finished training for epoch 965, loss: 0.218\n",
      "Finished training for epoch 966, loss: 0.173\n",
      "Finished training for epoch 967, loss: 0.216\n",
      "Finished training for epoch 968, loss: 0.172\n",
      "Finished training for epoch 969, loss: 0.170\n",
      "Finished training for epoch 970, loss: 0.184\n",
      "Finished training for epoch 971, loss: 0.247\n",
      "Finished training for epoch 972, loss: 0.164\n",
      "Finished training for epoch 973, loss: 0.162\n",
      "Finished training for epoch 974, loss: 0.174\n",
      "Finished training for epoch 975, loss: 0.165\n",
      "Finished training for epoch 976, loss: 0.180\n",
      "Finished training for epoch 977, loss: 0.198\n",
      "Finished training for epoch 978, loss: 0.263\n",
      "Finished training for epoch 979, loss: 0.164\n",
      "Finished training for epoch 980, loss: 0.176\n",
      "Finished training for epoch 981, loss: 0.203\n",
      "Finished training for epoch 982, loss: 0.180\n",
      "Finished training for epoch 983, loss: 0.177\n",
      "Finished training for epoch 984, loss: 0.160\n",
      "Finished training for epoch 985, loss: 0.201\n",
      "Finished training for epoch 986, loss: 0.158\n",
      "Finished training for epoch 987, loss: 0.170\n",
      "Finished training for epoch 988, loss: 0.246\n",
      "Finished training for epoch 989, loss: 0.202\n",
      "Finished training for epoch 990, loss: 0.243\n",
      "Finished training for epoch 991, loss: 0.189\n",
      "Finished training for epoch 992, loss: 0.160\n",
      "Finished training for epoch 993, loss: 0.191\n",
      "Finished training for epoch 994, loss: 0.176\n",
      "Finished training for epoch 995, loss: 0.193\n",
      "Finished training for epoch 996, loss: 0.174\n",
      "Finished training for epoch 997, loss: 0.167\n",
      "Finished training for epoch 998, loss: 0.183\n",
      "Finished training for epoch 999, loss: 0.194\n",
      "Finished training for epoch 1000, loss: 0.234\n"
     ]
    }
   ],
   "source": [
    "net_2 = Net()\n",
    "net_2 = train_model_bce(net_2, dataset_merged_train, 32, 1000, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9990299940109253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9990)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(net_2, dataset_uniform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8331500291824341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8332)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(net_2, dataset_near_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could see that with enhanced training set, we still retain good accuracy on universally-drawn test data, but achived improved accuracy on near-boundary test data as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CustomLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We impose normality condition on near-boundary training points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SystemDatasetModified(Dataset):\n",
    "    def __init__(self, csv_file, indicator):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.data = self.data.apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "        self.data['indicator'] = indicator\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.data.iloc[idx, 0:2].values.astype('float32')).float()\n",
    "        y = torch.tensor(self.data.iloc[idx, 2], dtype=torch.float32)\n",
    "        indicator = torch.tensor(self.data.iloc[idx, 3], dtype=torch.float32)\n",
    "        return x, y, indicator\n",
    "\n",
    "    def append_data(self, new_data):\n",
    "        # Identify columns that are either completely empty or contain all NA values\n",
    "        cols_to_exclude = new_data.columns[new_data.isna().all()]\n",
    "\n",
    "        # Exclude these columns from new_data\n",
    "        new_data_filtered = new_data.drop(columns=cols_to_exclude)\n",
    "\n",
    "        # Concatenate dataframes, now excluding the empty or all-NA columns\n",
    "        self.data = pd.concat([self.data, new_data_filtered], ignore_index=True)\n",
    "    \n",
    "dataset_uniform_train_modified = SystemDatasetModified(\"dataset_arbi2d_1000.csv\", 0)\n",
    "dataset_near_train_modified = SystemDatasetModified(\"dataset_arbi2d_enhanced_400.csv\", 1)\n",
    "dataset_merged_train_modified = torch.utils.data.ConcatDataset([dataset_uniform_train_modified, dataset_near_train_modified])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, magnitude):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.magnitude = magnitude\n",
    "\n",
    "    def forward(self, predictions, labels, inputs, b, indicators):\n",
    "        predictions_flat = predictions.view(-1)\n",
    "        labels_flat = labels.float().view(-1)\n",
    "        \n",
    "        l = nn.BCELoss()(predictions_flat, labels_flat)\n",
    "\n",
    "        for i, indicator in enumerate(indicators):\n",
    "            if indicator == 1:\n",
    "                grad_input = inputs[i].unsqueeze(0).clone().detach().requires_grad_(True)\n",
    "                grad_prediction = predictions_flat[i].unsqueeze(0)  \n",
    "                grads = torch.autograd.grad(grad_prediction.sum(), grad_input, create_graph=True, allow_unused=True)[0]\n",
    "                \n",
    "                if grads is not None:\n",
    "                    norm_grads = grads / grads.norm(dim=1, keepdim=True)\n",
    "                    norm_b = b[i].unsqueeze(0) / b[i].norm(dim=0, keepdim=True)\n",
    "                    inner_product = (norm_grads * norm_b).sum(dim=1)**2\n",
    "                    l += self.magnitude * inner_product.sum()\n",
    "        \n",
    "        return l\n",
    "\n",
    "def train_model_custom(net, dataset_train, batchsize, epochs, lr, magnitude):\n",
    "    criterion = CustomLoss(magnitude)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batchsize, shuffle=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        mini_batch_count = 0\n",
    "        for features, labels, indicators in dataloader_train: \n",
    "            labels = ((labels + 1) / 2).float()\n",
    "            labels = labels.view(-1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(features).view(-1)\n",
    "            loss = criterion(outputs, labels, features, system(0, features.T), indicators)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            mini_batch_count += 1\n",
    "        \n",
    "        print(f'Finished training for epoch {epoch + 1}, loss: {running_loss / mini_batch_count:.3f}')\n",
    "    \n",
    "    return net\n",
    "\n",
    "def test_model_modified(net, dataset_test):\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=True)\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    probability_list = []\n",
    "    predictions_list = []\n",
    "    acc = Accuracy(task = 'binary')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels, _ in dataloader_test:\n",
    "            labels = ((labels + 1) / 2).float()\n",
    "            probability = net(features)\n",
    "            outputs = (probability > 0.5).float()\n",
    "            outputs = outputs.squeeze()\n",
    "\n",
    "            acc.update(outputs, labels)\n",
    "\n",
    "            # Move features, labels, and outputs to CPU and convert them to numpy arrays\n",
    "            features_list.append(features.numpy())\n",
    "            labels_list.append(labels.numpy())\n",
    "            probability_list.append(probability.numpy())\n",
    "            predictions_list.append(outputs.numpy())\n",
    "    accuracy = acc.compute()\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "\n",
    "    # Concatenate all batches\n",
    "    features = np.concatenate(features_list, axis=0)\n",
    "    labels = np.concatenate(labels_list, axis=0)\n",
    "    probability = np.concatenate(probability_list, axis=0)\n",
    "    predictions = np.concatenate(predictions_list, axis=0)\n",
    "\n",
    "    # Create a 2D scatter plot\n",
    "    #fig = plt.figure()\n",
    "    #ax = fig.add_subplot(111)\n",
    "\n",
    "    # Plot the features colored by the predictions\n",
    "    #scatter = ax.scatter(features[:, 0], features[:, 1], c=probability, cmap='coolwarm')\n",
    "\n",
    "    # Add a color bar\n",
    "    #plt.colorbar(scatter)\n",
    "\n",
    "    #plt.show()\n",
    "\n",
    "    #plt.hist(probability, bins=20)\n",
    "    #plt.show()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training for epoch 1, loss: 0.648\n",
      "Finished training for epoch 2, loss: 0.518\n",
      "Finished training for epoch 3, loss: 0.456\n",
      "Finished training for epoch 4, loss: 0.406\n",
      "Finished training for epoch 5, loss: 0.388\n",
      "Finished training for epoch 6, loss: 0.370\n",
      "Finished training for epoch 7, loss: 0.362\n",
      "Finished training for epoch 8, loss: 0.359\n",
      "Finished training for epoch 9, loss: 0.353\n",
      "Finished training for epoch 10, loss: 0.346\n",
      "Finished training for epoch 11, loss: 0.349\n",
      "Finished training for epoch 12, loss: 0.340\n",
      "Finished training for epoch 13, loss: 0.341\n",
      "Finished training for epoch 14, loss: 0.336\n",
      "Finished training for epoch 15, loss: 0.331\n",
      "Finished training for epoch 16, loss: 0.333\n",
      "Finished training for epoch 17, loss: 0.330\n",
      "Finished training for epoch 18, loss: 0.332\n",
      "Finished training for epoch 19, loss: 0.336\n",
      "Finished training for epoch 20, loss: 0.331\n",
      "Finished training for epoch 21, loss: 0.328\n",
      "Finished training for epoch 22, loss: 0.328\n",
      "Finished training for epoch 23, loss: 0.321\n",
      "Finished training for epoch 24, loss: 0.343\n",
      "Finished training for epoch 25, loss: 0.325\n",
      "Finished training for epoch 26, loss: 0.325\n",
      "Finished training for epoch 27, loss: 0.325\n",
      "Finished training for epoch 28, loss: 0.331\n",
      "Finished training for epoch 29, loss: 0.323\n",
      "Finished training for epoch 30, loss: 0.321\n",
      "Finished training for epoch 31, loss: 0.322\n",
      "Finished training for epoch 32, loss: 0.314\n",
      "Finished training for epoch 33, loss: 0.326\n",
      "Finished training for epoch 34, loss: 0.325\n",
      "Finished training for epoch 35, loss: 0.315\n",
      "Finished training for epoch 36, loss: 0.319\n",
      "Finished training for epoch 37, loss: 0.320\n",
      "Finished training for epoch 38, loss: 0.319\n",
      "Finished training for epoch 39, loss: 0.321\n",
      "Finished training for epoch 40, loss: 0.318\n",
      "Finished training for epoch 41, loss: 0.318\n",
      "Finished training for epoch 42, loss: 0.327\n",
      "Finished training for epoch 43, loss: 0.332\n",
      "Finished training for epoch 44, loss: 0.322\n",
      "Finished training for epoch 45, loss: 0.313\n",
      "Finished training for epoch 46, loss: 0.318\n",
      "Finished training for epoch 47, loss: 0.316\n",
      "Finished training for epoch 48, loss: 0.316\n",
      "Finished training for epoch 49, loss: 0.313\n",
      "Finished training for epoch 50, loss: 0.325\n",
      "Finished training for epoch 51, loss: 0.313\n",
      "Finished training for epoch 52, loss: 0.316\n",
      "Finished training for epoch 53, loss: 0.320\n",
      "Finished training for epoch 54, loss: 0.313\n",
      "Finished training for epoch 55, loss: 0.317\n",
      "Finished training for epoch 56, loss: 0.310\n",
      "Finished training for epoch 57, loss: 0.322\n",
      "Finished training for epoch 58, loss: 0.315\n",
      "Finished training for epoch 59, loss: 0.313\n",
      "Finished training for epoch 60, loss: 0.312\n",
      "Finished training for epoch 61, loss: 0.315\n",
      "Finished training for epoch 62, loss: 0.309\n",
      "Finished training for epoch 63, loss: 0.310\n",
      "Finished training for epoch 64, loss: 0.310\n",
      "Finished training for epoch 65, loss: 0.322\n",
      "Finished training for epoch 66, loss: 0.305\n",
      "Finished training for epoch 67, loss: 0.313\n",
      "Finished training for epoch 68, loss: 0.310\n",
      "Finished training for epoch 69, loss: 0.311\n",
      "Finished training for epoch 70, loss: 0.309\n",
      "Finished training for epoch 71, loss: 0.314\n",
      "Finished training for epoch 72, loss: 0.320\n",
      "Finished training for epoch 73, loss: 0.313\n",
      "Finished training for epoch 74, loss: 0.304\n",
      "Finished training for epoch 75, loss: 0.308\n",
      "Finished training for epoch 76, loss: 0.313\n",
      "Finished training for epoch 77, loss: 0.308\n",
      "Finished training for epoch 78, loss: 0.303\n",
      "Finished training for epoch 79, loss: 0.313\n",
      "Finished training for epoch 80, loss: 0.307\n",
      "Finished training for epoch 81, loss: 0.302\n",
      "Finished training for epoch 82, loss: 0.313\n",
      "Finished training for epoch 83, loss: 0.317\n",
      "Finished training for epoch 84, loss: 0.311\n",
      "Finished training for epoch 85, loss: 0.310\n",
      "Finished training for epoch 86, loss: 0.308\n",
      "Finished training for epoch 87, loss: 0.310\n",
      "Finished training for epoch 88, loss: 0.306\n",
      "Finished training for epoch 89, loss: 0.305\n",
      "Finished training for epoch 90, loss: 0.311\n",
      "Finished training for epoch 91, loss: 0.302\n",
      "Finished training for epoch 92, loss: 0.313\n",
      "Finished training for epoch 93, loss: 0.304\n",
      "Finished training for epoch 94, loss: 0.300\n",
      "Finished training for epoch 95, loss: 0.317\n",
      "Finished training for epoch 96, loss: 0.307\n",
      "Finished training for epoch 97, loss: 0.308\n",
      "Finished training for epoch 98, loss: 0.316\n",
      "Finished training for epoch 99, loss: 0.310\n",
      "Finished training for epoch 100, loss: 0.314\n",
      "Finished training for epoch 101, loss: 0.303\n",
      "Finished training for epoch 102, loss: 0.302\n",
      "Finished training for epoch 103, loss: 0.304\n",
      "Finished training for epoch 104, loss: 0.306\n",
      "Finished training for epoch 105, loss: 0.310\n",
      "Finished training for epoch 106, loss: 0.306\n",
      "Finished training for epoch 107, loss: 0.304\n",
      "Finished training for epoch 108, loss: 0.294\n",
      "Finished training for epoch 109, loss: 0.303\n",
      "Finished training for epoch 110, loss: 0.304\n",
      "Finished training for epoch 111, loss: 0.304\n",
      "Finished training for epoch 112, loss: 0.311\n",
      "Finished training for epoch 113, loss: 0.317\n",
      "Finished training for epoch 114, loss: 0.308\n",
      "Finished training for epoch 115, loss: 0.305\n",
      "Finished training for epoch 116, loss: 0.296\n",
      "Finished training for epoch 117, loss: 0.304\n",
      "Finished training for epoch 118, loss: 0.312\n",
      "Finished training for epoch 119, loss: 0.300\n",
      "Finished training for epoch 120, loss: 0.304\n",
      "Finished training for epoch 121, loss: 0.300\n",
      "Finished training for epoch 122, loss: 0.296\n",
      "Finished training for epoch 123, loss: 0.301\n",
      "Finished training for epoch 124, loss: 0.301\n",
      "Finished training for epoch 125, loss: 0.304\n",
      "Finished training for epoch 126, loss: 0.310\n",
      "Finished training for epoch 127, loss: 0.302\n",
      "Finished training for epoch 128, loss: 0.296\n",
      "Finished training for epoch 129, loss: 0.301\n",
      "Finished training for epoch 130, loss: 0.301\n",
      "Finished training for epoch 131, loss: 0.315\n",
      "Finished training for epoch 132, loss: 0.311\n",
      "Finished training for epoch 133, loss: 0.301\n",
      "Finished training for epoch 134, loss: 0.301\n",
      "Finished training for epoch 135, loss: 0.297\n",
      "Finished training for epoch 136, loss: 0.290\n",
      "Finished training for epoch 137, loss: 0.299\n",
      "Finished training for epoch 138, loss: 0.299\n",
      "Finished training for epoch 139, loss: 0.299\n",
      "Finished training for epoch 140, loss: 0.296\n",
      "Finished training for epoch 141, loss: 0.299\n",
      "Finished training for epoch 142, loss: 0.307\n",
      "Finished training for epoch 143, loss: 0.307\n",
      "Finished training for epoch 144, loss: 0.301\n",
      "Finished training for epoch 145, loss: 0.299\n",
      "Finished training for epoch 146, loss: 0.296\n",
      "Finished training for epoch 147, loss: 0.293\n",
      "Finished training for epoch 148, loss: 0.296\n",
      "Finished training for epoch 149, loss: 0.295\n",
      "Finished training for epoch 150, loss: 0.295\n",
      "Finished training for epoch 151, loss: 0.291\n",
      "Finished training for epoch 152, loss: 0.292\n",
      "Finished training for epoch 153, loss: 0.294\n",
      "Finished training for epoch 154, loss: 0.290\n",
      "Finished training for epoch 155, loss: 0.296\n",
      "Finished training for epoch 156, loss: 0.295\n",
      "Finished training for epoch 157, loss: 0.296\n",
      "Finished training for epoch 158, loss: 0.295\n",
      "Finished training for epoch 159, loss: 0.291\n",
      "Finished training for epoch 160, loss: 0.302\n",
      "Finished training for epoch 161, loss: 0.299\n",
      "Finished training for epoch 162, loss: 0.293\n",
      "Finished training for epoch 163, loss: 0.287\n",
      "Finished training for epoch 164, loss: 0.297\n",
      "Finished training for epoch 165, loss: 0.290\n",
      "Finished training for epoch 166, loss: 0.283\n",
      "Finished training for epoch 167, loss: 0.308\n",
      "Finished training for epoch 168, loss: 0.294\n",
      "Finished training for epoch 169, loss: 0.290\n",
      "Finished training for epoch 170, loss: 0.290\n",
      "Finished training for epoch 171, loss: 0.299\n",
      "Finished training for epoch 172, loss: 0.297\n",
      "Finished training for epoch 173, loss: 0.295\n",
      "Finished training for epoch 174, loss: 0.297\n",
      "Finished training for epoch 175, loss: 0.290\n",
      "Finished training for epoch 176, loss: 0.296\n",
      "Finished training for epoch 177, loss: 0.285\n",
      "Finished training for epoch 178, loss: 0.305\n",
      "Finished training for epoch 179, loss: 0.288\n",
      "Finished training for epoch 180, loss: 0.293\n",
      "Finished training for epoch 181, loss: 0.288\n",
      "Finished training for epoch 182, loss: 0.294\n",
      "Finished training for epoch 183, loss: 0.305\n",
      "Finished training for epoch 184, loss: 0.307\n",
      "Finished training for epoch 185, loss: 0.294\n",
      "Finished training for epoch 186, loss: 0.289\n",
      "Finished training for epoch 187, loss: 0.287\n",
      "Finished training for epoch 188, loss: 0.313\n",
      "Finished training for epoch 189, loss: 0.291\n",
      "Finished training for epoch 190, loss: 0.289\n",
      "Finished training for epoch 191, loss: 0.308\n",
      "Finished training for epoch 192, loss: 0.289\n",
      "Finished training for epoch 193, loss: 0.286\n",
      "Finished training for epoch 194, loss: 0.295\n",
      "Finished training for epoch 195, loss: 0.296\n",
      "Finished training for epoch 196, loss: 0.291\n",
      "Finished training for epoch 197, loss: 0.289\n",
      "Finished training for epoch 198, loss: 0.292\n",
      "Finished training for epoch 199, loss: 0.294\n",
      "Finished training for epoch 200, loss: 0.283\n",
      "Finished training for epoch 201, loss: 0.293\n",
      "Finished training for epoch 202, loss: 0.283\n",
      "Finished training for epoch 203, loss: 0.285\n",
      "Finished training for epoch 204, loss: 0.298\n",
      "Finished training for epoch 205, loss: 0.282\n",
      "Finished training for epoch 206, loss: 0.285\n",
      "Finished training for epoch 207, loss: 0.287\n",
      "Finished training for epoch 208, loss: 0.288\n",
      "Finished training for epoch 209, loss: 0.284\n",
      "Finished training for epoch 210, loss: 0.277\n",
      "Finished training for epoch 211, loss: 0.295\n",
      "Finished training for epoch 212, loss: 0.291\n",
      "Finished training for epoch 213, loss: 0.288\n",
      "Finished training for epoch 214, loss: 0.288\n",
      "Finished training for epoch 215, loss: 0.286\n",
      "Finished training for epoch 216, loss: 0.281\n",
      "Finished training for epoch 217, loss: 0.285\n",
      "Finished training for epoch 218, loss: 0.280\n",
      "Finished training for epoch 219, loss: 0.286\n",
      "Finished training for epoch 220, loss: 0.288\n",
      "Finished training for epoch 221, loss: 0.296\n",
      "Finished training for epoch 222, loss: 0.297\n",
      "Finished training for epoch 223, loss: 0.278\n",
      "Finished training for epoch 224, loss: 0.287\n",
      "Finished training for epoch 225, loss: 0.276\n",
      "Finished training for epoch 226, loss: 0.285\n",
      "Finished training for epoch 227, loss: 0.281\n",
      "Finished training for epoch 228, loss: 0.297\n",
      "Finished training for epoch 229, loss: 0.281\n",
      "Finished training for epoch 230, loss: 0.273\n",
      "Finished training for epoch 231, loss: 0.276\n",
      "Finished training for epoch 232, loss: 0.285\n",
      "Finished training for epoch 233, loss: 0.292\n",
      "Finished training for epoch 234, loss: 0.291\n",
      "Finished training for epoch 235, loss: 0.269\n",
      "Finished training for epoch 236, loss: 0.291\n",
      "Finished training for epoch 237, loss: 0.285\n",
      "Finished training for epoch 238, loss: 0.284\n",
      "Finished training for epoch 239, loss: 0.275\n",
      "Finished training for epoch 240, loss: 0.291\n",
      "Finished training for epoch 241, loss: 0.276\n",
      "Finished training for epoch 242, loss: 0.289\n",
      "Finished training for epoch 243, loss: 0.289\n",
      "Finished training for epoch 244, loss: 0.279\n",
      "Finished training for epoch 245, loss: 0.272\n",
      "Finished training for epoch 246, loss: 0.274\n",
      "Finished training for epoch 247, loss: 0.277\n",
      "Finished training for epoch 248, loss: 0.277\n",
      "Finished training for epoch 249, loss: 0.300\n",
      "Finished training for epoch 250, loss: 0.299\n",
      "Finished training for epoch 251, loss: 0.286\n",
      "Finished training for epoch 252, loss: 0.273\n",
      "Finished training for epoch 253, loss: 0.294\n",
      "Finished training for epoch 254, loss: 0.292\n",
      "Finished training for epoch 255, loss: 0.293\n",
      "Finished training for epoch 256, loss: 0.276\n",
      "Finished training for epoch 257, loss: 0.275\n",
      "Finished training for epoch 258, loss: 0.269\n",
      "Finished training for epoch 259, loss: 0.288\n",
      "Finished training for epoch 260, loss: 0.282\n",
      "Finished training for epoch 261, loss: 0.288\n",
      "Finished training for epoch 262, loss: 0.274\n",
      "Finished training for epoch 263, loss: 0.270\n",
      "Finished training for epoch 264, loss: 0.287\n",
      "Finished training for epoch 265, loss: 0.274\n",
      "Finished training for epoch 266, loss: 0.270\n",
      "Finished training for epoch 267, loss: 0.273\n",
      "Finished training for epoch 268, loss: 0.272\n",
      "Finished training for epoch 269, loss: 0.281\n",
      "Finished training for epoch 270, loss: 0.284\n",
      "Finished training for epoch 271, loss: 0.269\n",
      "Finished training for epoch 272, loss: 0.286\n",
      "Finished training for epoch 273, loss: 0.274\n",
      "Finished training for epoch 274, loss: 0.270\n",
      "Finished training for epoch 275, loss: 0.268\n",
      "Finished training for epoch 276, loss: 0.281\n",
      "Finished training for epoch 277, loss: 0.272\n",
      "Finished training for epoch 278, loss: 0.269\n",
      "Finished training for epoch 279, loss: 0.274\n",
      "Finished training for epoch 280, loss: 0.290\n",
      "Finished training for epoch 281, loss: 0.272\n",
      "Finished training for epoch 282, loss: 0.265\n",
      "Finished training for epoch 283, loss: 0.292\n",
      "Finished training for epoch 284, loss: 0.278\n",
      "Finished training for epoch 285, loss: 0.276\n",
      "Finished training for epoch 286, loss: 0.270\n",
      "Finished training for epoch 287, loss: 0.284\n",
      "Finished training for epoch 288, loss: 0.278\n",
      "Finished training for epoch 289, loss: 0.273\n",
      "Finished training for epoch 290, loss: 0.269\n",
      "Finished training for epoch 291, loss: 0.270\n",
      "Finished training for epoch 292, loss: 0.262\n",
      "Finished training for epoch 293, loss: 0.265\n",
      "Finished training for epoch 294, loss: 0.268\n",
      "Finished training for epoch 295, loss: 0.271\n",
      "Finished training for epoch 296, loss: 0.270\n",
      "Finished training for epoch 297, loss: 0.260\n",
      "Finished training for epoch 298, loss: 0.267\n",
      "Finished training for epoch 299, loss: 0.273\n",
      "Finished training for epoch 300, loss: 0.271\n",
      "Finished training for epoch 301, loss: 0.271\n",
      "Finished training for epoch 302, loss: 0.258\n",
      "Finished training for epoch 303, loss: 0.261\n",
      "Finished training for epoch 304, loss: 0.275\n",
      "Finished training for epoch 305, loss: 0.299\n",
      "Finished training for epoch 306, loss: 0.267\n",
      "Finished training for epoch 307, loss: 0.264\n",
      "Finished training for epoch 308, loss: 0.259\n",
      "Finished training for epoch 309, loss: 0.256\n",
      "Finished training for epoch 310, loss: 0.253\n",
      "Finished training for epoch 311, loss: 0.261\n",
      "Finished training for epoch 312, loss: 0.270\n",
      "Finished training for epoch 313, loss: 0.260\n",
      "Finished training for epoch 314, loss: 0.262\n",
      "Finished training for epoch 315, loss: 0.285\n",
      "Finished training for epoch 316, loss: 0.248\n",
      "Finished training for epoch 317, loss: 0.267\n",
      "Finished training for epoch 318, loss: 0.245\n",
      "Finished training for epoch 319, loss: 0.262\n",
      "Finished training for epoch 320, loss: 0.260\n",
      "Finished training for epoch 321, loss: 0.257\n",
      "Finished training for epoch 322, loss: 0.267\n",
      "Finished training for epoch 323, loss: 0.269\n",
      "Finished training for epoch 324, loss: 0.267\n",
      "Finished training for epoch 325, loss: 0.272\n",
      "Finished training for epoch 326, loss: 0.259\n",
      "Finished training for epoch 327, loss: 0.264\n",
      "Finished training for epoch 328, loss: 0.267\n",
      "Finished training for epoch 329, loss: 0.255\n",
      "Finished training for epoch 330, loss: 0.273\n",
      "Finished training for epoch 331, loss: 0.273\n",
      "Finished training for epoch 332, loss: 0.245\n",
      "Finished training for epoch 333, loss: 0.261\n",
      "Finished training for epoch 334, loss: 0.276\n",
      "Finished training for epoch 335, loss: 0.258\n",
      "Finished training for epoch 336, loss: 0.248\n",
      "Finished training for epoch 337, loss: 0.244\n",
      "Finished training for epoch 338, loss: 0.275\n",
      "Finished training for epoch 339, loss: 0.294\n",
      "Finished training for epoch 340, loss: 0.267\n",
      "Finished training for epoch 341, loss: 0.244\n",
      "Finished training for epoch 342, loss: 0.240\n",
      "Finished training for epoch 343, loss: 0.244\n",
      "Finished training for epoch 344, loss: 0.286\n",
      "Finished training for epoch 345, loss: 0.252\n",
      "Finished training for epoch 346, loss: 0.261\n",
      "Finished training for epoch 347, loss: 0.252\n",
      "Finished training for epoch 348, loss: 0.241\n",
      "Finished training for epoch 349, loss: 0.253\n",
      "Finished training for epoch 350, loss: 0.295\n",
      "Finished training for epoch 351, loss: 0.246\n",
      "Finished training for epoch 352, loss: 0.259\n",
      "Finished training for epoch 353, loss: 0.242\n",
      "Finished training for epoch 354, loss: 0.235\n",
      "Finished training for epoch 355, loss: 0.253\n",
      "Finished training for epoch 356, loss: 0.247\n",
      "Finished training for epoch 357, loss: 0.257\n",
      "Finished training for epoch 358, loss: 0.262\n",
      "Finished training for epoch 359, loss: 0.239\n",
      "Finished training for epoch 360, loss: 0.253\n",
      "Finished training for epoch 361, loss: 0.253\n",
      "Finished training for epoch 362, loss: 0.234\n",
      "Finished training for epoch 363, loss: 0.232\n",
      "Finished training for epoch 364, loss: 0.252\n",
      "Finished training for epoch 365, loss: 0.246\n",
      "Finished training for epoch 366, loss: 0.242\n",
      "Finished training for epoch 367, loss: 0.251\n",
      "Finished training for epoch 368, loss: 0.255\n",
      "Finished training for epoch 369, loss: 0.238\n",
      "Finished training for epoch 370, loss: 0.230\n",
      "Finished training for epoch 371, loss: 0.235\n",
      "Finished training for epoch 372, loss: 0.233\n",
      "Finished training for epoch 373, loss: 0.297\n",
      "Finished training for epoch 374, loss: 0.231\n",
      "Finished training for epoch 375, loss: 0.260\n",
      "Finished training for epoch 376, loss: 0.264\n",
      "Finished training for epoch 377, loss: 0.251\n",
      "Finished training for epoch 378, loss: 0.226\n",
      "Finished training for epoch 379, loss: 0.231\n",
      "Finished training for epoch 380, loss: 0.240\n",
      "Finished training for epoch 381, loss: 0.236\n",
      "Finished training for epoch 382, loss: 0.234\n",
      "Finished training for epoch 383, loss: 0.241\n",
      "Finished training for epoch 384, loss: 0.239\n",
      "Finished training for epoch 385, loss: 0.225\n",
      "Finished training for epoch 386, loss: 0.228\n",
      "Finished training for epoch 387, loss: 0.230\n",
      "Finished training for epoch 388, loss: 0.258\n",
      "Finished training for epoch 389, loss: 0.247\n",
      "Finished training for epoch 390, loss: 0.222\n",
      "Finished training for epoch 391, loss: 0.225\n",
      "Finished training for epoch 392, loss: 0.227\n",
      "Finished training for epoch 393, loss: 0.244\n",
      "Finished training for epoch 394, loss: 0.271\n",
      "Finished training for epoch 395, loss: 0.239\n",
      "Finished training for epoch 396, loss: 0.227\n",
      "Finished training for epoch 397, loss: 0.231\n",
      "Finished training for epoch 398, loss: 0.239\n",
      "Finished training for epoch 399, loss: 0.242\n",
      "Finished training for epoch 400, loss: 0.233\n",
      "Finished training for epoch 401, loss: 0.229\n",
      "Finished training for epoch 402, loss: 0.242\n",
      "Finished training for epoch 403, loss: 0.242\n",
      "Finished training for epoch 404, loss: 0.252\n",
      "Finished training for epoch 405, loss: 0.238\n",
      "Finished training for epoch 406, loss: 0.219\n",
      "Finished training for epoch 407, loss: 0.222\n",
      "Finished training for epoch 408, loss: 0.218\n",
      "Finished training for epoch 409, loss: 0.229\n",
      "Finished training for epoch 410, loss: 0.236\n",
      "Finished training for epoch 411, loss: 0.264\n",
      "Finished training for epoch 412, loss: 0.261\n",
      "Finished training for epoch 413, loss: 0.228\n",
      "Finished training for epoch 414, loss: 0.294\n",
      "Finished training for epoch 415, loss: 0.230\n",
      "Finished training for epoch 416, loss: 0.250\n",
      "Finished training for epoch 417, loss: 0.219\n",
      "Finished training for epoch 418, loss: 0.218\n",
      "Finished training for epoch 419, loss: 0.213\n",
      "Finished training for epoch 420, loss: 0.213\n",
      "Finished training for epoch 421, loss: 0.232\n",
      "Finished training for epoch 422, loss: 0.226\n",
      "Finished training for epoch 423, loss: 0.266\n",
      "Finished training for epoch 424, loss: 0.260\n",
      "Finished training for epoch 425, loss: 0.262\n",
      "Finished training for epoch 426, loss: 0.218\n",
      "Finished training for epoch 427, loss: 0.219\n",
      "Finished training for epoch 428, loss: 0.214\n",
      "Finished training for epoch 429, loss: 0.218\n",
      "Finished training for epoch 430, loss: 0.224\n",
      "Finished training for epoch 431, loss: 0.242\n",
      "Finished training for epoch 432, loss: 0.211\n",
      "Finished training for epoch 433, loss: 0.230\n",
      "Finished training for epoch 434, loss: 0.213\n",
      "Finished training for epoch 435, loss: 0.214\n",
      "Finished training for epoch 436, loss: 0.210\n",
      "Finished training for epoch 437, loss: 0.208\n",
      "Finished training for epoch 438, loss: 0.214\n",
      "Finished training for epoch 439, loss: 0.246\n",
      "Finished training for epoch 440, loss: 0.241\n",
      "Finished training for epoch 441, loss: 0.262\n",
      "Finished training for epoch 442, loss: 0.261\n",
      "Finished training for epoch 443, loss: 0.249\n",
      "Finished training for epoch 444, loss: 0.241\n",
      "Finished training for epoch 445, loss: 0.209\n",
      "Finished training for epoch 446, loss: 0.205\n",
      "Finished training for epoch 447, loss: 0.212\n",
      "Finished training for epoch 448, loss: 0.221\n",
      "Finished training for epoch 449, loss: 0.254\n",
      "Finished training for epoch 450, loss: 0.220\n",
      "Finished training for epoch 451, loss: 0.249\n",
      "Finished training for epoch 452, loss: 0.236\n",
      "Finished training for epoch 453, loss: 0.226\n",
      "Finished training for epoch 454, loss: 0.230\n",
      "Finished training for epoch 455, loss: 0.209\n",
      "Finished training for epoch 456, loss: 0.199\n",
      "Finished training for epoch 457, loss: 0.197\n",
      "Finished training for epoch 458, loss: 0.219\n",
      "Finished training for epoch 459, loss: 0.219\n",
      "Finished training for epoch 460, loss: 0.221\n",
      "Finished training for epoch 461, loss: 0.202\n",
      "Finished training for epoch 462, loss: 0.207\n",
      "Finished training for epoch 463, loss: 0.211\n",
      "Finished training for epoch 464, loss: 0.243\n",
      "Finished training for epoch 465, loss: 0.214\n",
      "Finished training for epoch 466, loss: 0.214\n",
      "Finished training for epoch 467, loss: 0.207\n",
      "Finished training for epoch 468, loss: 0.201\n",
      "Finished training for epoch 469, loss: 0.219\n",
      "Finished training for epoch 470, loss: 0.212\n",
      "Finished training for epoch 471, loss: 0.255\n",
      "Finished training for epoch 472, loss: 0.204\n",
      "Finished training for epoch 473, loss: 0.218\n",
      "Finished training for epoch 474, loss: 0.200\n",
      "Finished training for epoch 475, loss: 0.218\n",
      "Finished training for epoch 476, loss: 0.232\n",
      "Finished training for epoch 477, loss: 0.213\n",
      "Finished training for epoch 478, loss: 0.198\n",
      "Finished training for epoch 479, loss: 0.210\n",
      "Finished training for epoch 480, loss: 0.215\n",
      "Finished training for epoch 481, loss: 0.194\n",
      "Finished training for epoch 482, loss: 0.183\n",
      "Finished training for epoch 483, loss: 0.228\n",
      "Finished training for epoch 484, loss: 0.194\n",
      "Finished training for epoch 485, loss: 0.196\n",
      "Finished training for epoch 486, loss: 0.214\n",
      "Finished training for epoch 487, loss: 0.188\n",
      "Finished training for epoch 488, loss: 0.212\n",
      "Finished training for epoch 489, loss: 0.194\n",
      "Finished training for epoch 490, loss: 0.209\n",
      "Finished training for epoch 491, loss: 0.193\n",
      "Finished training for epoch 492, loss: 0.186\n",
      "Finished training for epoch 493, loss: 0.196\n",
      "Finished training for epoch 494, loss: 0.229\n",
      "Finished training for epoch 495, loss: 0.196\n",
      "Finished training for epoch 496, loss: 0.217\n",
      "Finished training for epoch 497, loss: 0.254\n",
      "Finished training for epoch 498, loss: 0.193\n",
      "Finished training for epoch 499, loss: 0.182\n",
      "Finished training for epoch 500, loss: 0.193\n",
      "Finished training for epoch 501, loss: 0.207\n",
      "Finished training for epoch 502, loss: 0.218\n",
      "Finished training for epoch 503, loss: 0.194\n",
      "Finished training for epoch 504, loss: 0.214\n",
      "Finished training for epoch 505, loss: 0.204\n",
      "Finished training for epoch 506, loss: 0.248\n",
      "Finished training for epoch 507, loss: 0.187\n",
      "Finished training for epoch 508, loss: 0.186\n",
      "Finished training for epoch 509, loss: 0.272\n",
      "Finished training for epoch 510, loss: 0.241\n",
      "Finished training for epoch 511, loss: 0.197\n",
      "Finished training for epoch 512, loss: 0.197\n",
      "Finished training for epoch 513, loss: 0.199\n",
      "Finished training for epoch 514, loss: 0.200\n",
      "Finished training for epoch 515, loss: 0.192\n",
      "Finished training for epoch 516, loss: 0.258\n",
      "Finished training for epoch 517, loss: 0.190\n",
      "Finished training for epoch 518, loss: 0.179\n",
      "Finished training for epoch 519, loss: 0.175\n",
      "Finished training for epoch 520, loss: 0.177\n",
      "Finished training for epoch 521, loss: 0.181\n",
      "Finished training for epoch 522, loss: 0.193\n",
      "Finished training for epoch 523, loss: 0.241\n",
      "Finished training for epoch 524, loss: 0.182\n",
      "Finished training for epoch 525, loss: 0.184\n",
      "Finished training for epoch 526, loss: 0.218\n",
      "Finished training for epoch 527, loss: 0.188\n",
      "Finished training for epoch 528, loss: 0.204\n",
      "Finished training for epoch 529, loss: 0.241\n",
      "Finished training for epoch 530, loss: 0.183\n",
      "Finished training for epoch 531, loss: 0.235\n",
      "Finished training for epoch 532, loss: 0.180\n",
      "Finished training for epoch 533, loss: 0.189\n",
      "Finished training for epoch 534, loss: 0.212\n",
      "Finished training for epoch 535, loss: 0.224\n",
      "Finished training for epoch 536, loss: 0.216\n",
      "Finished training for epoch 537, loss: 0.177\n",
      "Finished training for epoch 538, loss: 0.169\n",
      "Finished training for epoch 539, loss: 0.196\n",
      "Finished training for epoch 540, loss: 0.184\n",
      "Finished training for epoch 541, loss: 0.200\n",
      "Finished training for epoch 542, loss: 0.181\n",
      "Finished training for epoch 543, loss: 0.178\n",
      "Finished training for epoch 544, loss: 0.183\n",
      "Finished training for epoch 545, loss: 0.178\n",
      "Finished training for epoch 546, loss: 0.216\n",
      "Finished training for epoch 547, loss: 0.182\n",
      "Finished training for epoch 548, loss: 0.201\n",
      "Finished training for epoch 549, loss: 0.181\n",
      "Finished training for epoch 550, loss: 0.188\n",
      "Finished training for epoch 551, loss: 0.217\n",
      "Finished training for epoch 552, loss: 0.194\n",
      "Finished training for epoch 553, loss: 0.262\n",
      "Finished training for epoch 554, loss: 0.190\n",
      "Finished training for epoch 555, loss: 0.158\n",
      "Finished training for epoch 556, loss: 0.183\n",
      "Finished training for epoch 557, loss: 0.168\n",
      "Finished training for epoch 558, loss: 0.216\n",
      "Finished training for epoch 559, loss: 0.183\n",
      "Finished training for epoch 560, loss: 0.192\n",
      "Finished training for epoch 561, loss: 0.201\n",
      "Finished training for epoch 562, loss: 0.211\n",
      "Finished training for epoch 563, loss: 0.215\n",
      "Finished training for epoch 564, loss: 0.184\n",
      "Finished training for epoch 565, loss: 0.186\n",
      "Finished training for epoch 566, loss: 0.167\n",
      "Finished training for epoch 567, loss: 0.194\n",
      "Finished training for epoch 568, loss: 0.178\n",
      "Finished training for epoch 569, loss: 0.269\n",
      "Finished training for epoch 570, loss: 0.199\n",
      "Finished training for epoch 571, loss: 0.179\n",
      "Finished training for epoch 572, loss: 0.197\n",
      "Finished training for epoch 573, loss: 0.188\n",
      "Finished training for epoch 574, loss: 0.176\n",
      "Finished training for epoch 575, loss: 0.192\n",
      "Finished training for epoch 576, loss: 0.177\n",
      "Finished training for epoch 577, loss: 0.173\n",
      "Finished training for epoch 578, loss: 0.188\n",
      "Finished training for epoch 579, loss: 0.166\n",
      "Finished training for epoch 580, loss: 0.184\n",
      "Finished training for epoch 581, loss: 0.166\n",
      "Finished training for epoch 582, loss: 0.210\n",
      "Finished training for epoch 583, loss: 0.221\n",
      "Finished training for epoch 584, loss: 0.175\n",
      "Finished training for epoch 585, loss: 0.161\n",
      "Finished training for epoch 586, loss: 0.161\n",
      "Finished training for epoch 587, loss: 0.162\n",
      "Finished training for epoch 588, loss: 0.164\n",
      "Finished training for epoch 589, loss: 0.190\n",
      "Finished training for epoch 590, loss: 0.221\n",
      "Finished training for epoch 591, loss: 0.214\n",
      "Finished training for epoch 592, loss: 0.164\n",
      "Finished training for epoch 593, loss: 0.141\n",
      "Finished training for epoch 594, loss: 0.163\n",
      "Finished training for epoch 595, loss: 0.218\n",
      "Finished training for epoch 596, loss: 0.206\n",
      "Finished training for epoch 597, loss: 0.155\n",
      "Finished training for epoch 598, loss: 0.168\n",
      "Finished training for epoch 599, loss: 0.251\n",
      "Finished training for epoch 600, loss: 0.226\n",
      "Finished training for epoch 601, loss: 0.185\n",
      "Finished training for epoch 602, loss: 0.176\n",
      "Finished training for epoch 603, loss: 0.183\n",
      "Finished training for epoch 604, loss: 0.178\n",
      "Finished training for epoch 605, loss: 0.207\n",
      "Finished training for epoch 606, loss: 0.163\n",
      "Finished training for epoch 607, loss: 0.233\n",
      "Finished training for epoch 608, loss: 0.207\n",
      "Finished training for epoch 609, loss: 0.161\n",
      "Finished training for epoch 610, loss: 0.193\n",
      "Finished training for epoch 611, loss: 0.200\n",
      "Finished training for epoch 612, loss: 0.193\n",
      "Finished training for epoch 613, loss: 0.178\n",
      "Finished training for epoch 614, loss: 0.163\n",
      "Finished training for epoch 615, loss: 0.160\n",
      "Finished training for epoch 616, loss: 0.155\n",
      "Finished training for epoch 617, loss: 0.248\n",
      "Finished training for epoch 618, loss: 0.188\n",
      "Finished training for epoch 619, loss: 0.221\n",
      "Finished training for epoch 620, loss: 0.322\n",
      "Finished training for epoch 621, loss: 0.169\n",
      "Finished training for epoch 622, loss: 0.173\n",
      "Finished training for epoch 623, loss: 0.180\n",
      "Finished training for epoch 624, loss: 0.191\n",
      "Finished training for epoch 625, loss: 0.216\n",
      "Finished training for epoch 626, loss: 0.166\n",
      "Finished training for epoch 627, loss: 0.174\n",
      "Finished training for epoch 628, loss: 0.190\n",
      "Finished training for epoch 629, loss: 0.184\n",
      "Finished training for epoch 630, loss: 0.190\n",
      "Finished training for epoch 631, loss: 0.216\n",
      "Finished training for epoch 632, loss: 0.159\n",
      "Finished training for epoch 633, loss: 0.179\n",
      "Finished training for epoch 634, loss: 0.162\n",
      "Finished training for epoch 635, loss: 0.183\n",
      "Finished training for epoch 636, loss: 0.165\n",
      "Finished training for epoch 637, loss: 0.175\n",
      "Finished training for epoch 638, loss: 0.181\n",
      "Finished training for epoch 639, loss: 0.163\n",
      "Finished training for epoch 640, loss: 0.153\n",
      "Finished training for epoch 641, loss: 0.171\n",
      "Finished training for epoch 642, loss: 0.191\n",
      "Finished training for epoch 643, loss: 0.200\n",
      "Finished training for epoch 644, loss: 0.261\n",
      "Finished training for epoch 645, loss: 0.151\n",
      "Finished training for epoch 646, loss: 0.180\n",
      "Finished training for epoch 647, loss: 0.181\n",
      "Finished training for epoch 648, loss: 0.163\n",
      "Finished training for epoch 649, loss: 0.220\n",
      "Finished training for epoch 650, loss: 0.163\n",
      "Finished training for epoch 651, loss: 0.162\n",
      "Finished training for epoch 652, loss: 0.193\n",
      "Finished training for epoch 653, loss: 0.148\n",
      "Finished training for epoch 654, loss: 0.168\n",
      "Finished training for epoch 655, loss: 0.180\n",
      "Finished training for epoch 656, loss: 0.200\n",
      "Finished training for epoch 657, loss: 0.168\n",
      "Finished training for epoch 658, loss: 0.205\n",
      "Finished training for epoch 659, loss: 0.262\n",
      "Finished training for epoch 660, loss: 0.236\n",
      "Finished training for epoch 661, loss: 0.163\n",
      "Finished training for epoch 662, loss: 0.150\n",
      "Finished training for epoch 663, loss: 0.186\n",
      "Finished training for epoch 664, loss: 0.180\n",
      "Finished training for epoch 665, loss: 0.154\n",
      "Finished training for epoch 666, loss: 0.152\n",
      "Finished training for epoch 667, loss: 0.179\n",
      "Finished training for epoch 668, loss: 0.147\n",
      "Finished training for epoch 669, loss: 0.150\n",
      "Finished training for epoch 670, loss: 0.218\n",
      "Finished training for epoch 671, loss: 0.167\n",
      "Finished training for epoch 672, loss: 0.178\n",
      "Finished training for epoch 673, loss: 0.260\n",
      "Finished training for epoch 674, loss: 0.227\n",
      "Finished training for epoch 675, loss: 0.175\n",
      "Finished training for epoch 676, loss: 0.173\n",
      "Finished training for epoch 677, loss: 0.185\n",
      "Finished training for epoch 678, loss: 0.168\n",
      "Finished training for epoch 679, loss: 0.175\n",
      "Finished training for epoch 680, loss: 0.212\n",
      "Finished training for epoch 681, loss: 0.164\n",
      "Finished training for epoch 682, loss: 0.163\n",
      "Finished training for epoch 683, loss: 0.142\n",
      "Finished training for epoch 684, loss: 0.185\n",
      "Finished training for epoch 685, loss: 0.195\n",
      "Finished training for epoch 686, loss: 0.155\n",
      "Finished training for epoch 687, loss: 0.278\n",
      "Finished training for epoch 688, loss: 0.200\n",
      "Finished training for epoch 689, loss: 0.205\n",
      "Finished training for epoch 690, loss: 0.155\n",
      "Finished training for epoch 691, loss: 0.204\n",
      "Finished training for epoch 692, loss: 0.271\n",
      "Finished training for epoch 693, loss: 0.178\n",
      "Finished training for epoch 694, loss: 0.166\n",
      "Finished training for epoch 695, loss: 0.184\n",
      "Finished training for epoch 696, loss: 0.175\n",
      "Finished training for epoch 697, loss: 0.168\n",
      "Finished training for epoch 698, loss: 0.148\n",
      "Finished training for epoch 699, loss: 0.185\n",
      "Finished training for epoch 700, loss: 0.203\n",
      "Finished training for epoch 701, loss: 0.262\n",
      "Finished training for epoch 702, loss: 0.206\n",
      "Finished training for epoch 703, loss: 0.182\n",
      "Finished training for epoch 704, loss: 0.147\n",
      "Finished training for epoch 705, loss: 0.194\n",
      "Finished training for epoch 706, loss: 0.171\n",
      "Finished training for epoch 707, loss: 0.163\n",
      "Finished training for epoch 708, loss: 0.155\n",
      "Finished training for epoch 709, loss: 0.137\n",
      "Finished training for epoch 710, loss: 0.188\n",
      "Finished training for epoch 711, loss: 0.158\n",
      "Finished training for epoch 712, loss: 0.156\n",
      "Finished training for epoch 713, loss: 0.151\n",
      "Finished training for epoch 714, loss: 0.155\n",
      "Finished training for epoch 715, loss: 0.174\n",
      "Finished training for epoch 716, loss: 0.219\n",
      "Finished training for epoch 717, loss: 0.173\n",
      "Finished training for epoch 718, loss: 0.159\n",
      "Finished training for epoch 719, loss: 0.177\n",
      "Finished training for epoch 720, loss: 0.186\n",
      "Finished training for epoch 721, loss: 0.172\n",
      "Finished training for epoch 722, loss: 0.198\n",
      "Finished training for epoch 723, loss: 0.160\n",
      "Finished training for epoch 724, loss: 0.139\n",
      "Finished training for epoch 725, loss: 0.357\n",
      "Finished training for epoch 726, loss: 0.197\n",
      "Finished training for epoch 727, loss: 0.162\n",
      "Finished training for epoch 728, loss: 0.165\n",
      "Finished training for epoch 729, loss: 0.208\n",
      "Finished training for epoch 730, loss: 0.176\n",
      "Finished training for epoch 731, loss: 0.145\n",
      "Finished training for epoch 732, loss: 0.150\n",
      "Finished training for epoch 733, loss: 0.165\n",
      "Finished training for epoch 734, loss: 0.146\n",
      "Finished training for epoch 735, loss: 0.137\n",
      "Finished training for epoch 736, loss: 0.192\n",
      "Finished training for epoch 737, loss: 0.161\n",
      "Finished training for epoch 738, loss: 0.145\n",
      "Finished training for epoch 739, loss: 0.168\n",
      "Finished training for epoch 740, loss: 0.211\n",
      "Finished training for epoch 741, loss: 0.165\n",
      "Finished training for epoch 742, loss: 0.266\n",
      "Finished training for epoch 743, loss: 0.164\n",
      "Finished training for epoch 744, loss: 0.165\n",
      "Finished training for epoch 745, loss: 0.163\n",
      "Finished training for epoch 746, loss: 0.238\n",
      "Finished training for epoch 747, loss: 0.147\n",
      "Finished training for epoch 748, loss: 0.147\n",
      "Finished training for epoch 749, loss: 0.168\n",
      "Finished training for epoch 750, loss: 0.198\n",
      "Finished training for epoch 751, loss: 0.152\n",
      "Finished training for epoch 752, loss: 0.139\n",
      "Finished training for epoch 753, loss: 0.213\n",
      "Finished training for epoch 754, loss: 0.129\n",
      "Finished training for epoch 755, loss: 0.144\n",
      "Finished training for epoch 756, loss: 0.267\n",
      "Finished training for epoch 757, loss: 0.181\n",
      "Finished training for epoch 758, loss: 0.158\n",
      "Finished training for epoch 759, loss: 0.164\n",
      "Finished training for epoch 760, loss: 0.262\n",
      "Finished training for epoch 761, loss: 0.179\n",
      "Finished training for epoch 762, loss: 0.191\n",
      "Finished training for epoch 763, loss: 0.166\n",
      "Finished training for epoch 764, loss: 0.153\n",
      "Finished training for epoch 765, loss: 0.181\n",
      "Finished training for epoch 766, loss: 0.151\n",
      "Finished training for epoch 767, loss: 0.152\n",
      "Finished training for epoch 768, loss: 0.170\n",
      "Finished training for epoch 769, loss: 0.207\n",
      "Finished training for epoch 770, loss: 0.338\n",
      "Finished training for epoch 771, loss: 0.163\n",
      "Finished training for epoch 772, loss: 0.188\n",
      "Finished training for epoch 773, loss: 0.155\n",
      "Finished training for epoch 774, loss: 0.173\n",
      "Finished training for epoch 775, loss: 0.180\n",
      "Finished training for epoch 776, loss: 0.157\n",
      "Finished training for epoch 777, loss: 0.185\n",
      "Finished training for epoch 778, loss: 0.146\n",
      "Finished training for epoch 779, loss: 0.183\n",
      "Finished training for epoch 780, loss: 0.160\n",
      "Finished training for epoch 781, loss: 0.371\n",
      "Finished training for epoch 782, loss: 0.172\n",
      "Finished training for epoch 783, loss: 0.189\n",
      "Finished training for epoch 784, loss: 0.162\n",
      "Finished training for epoch 785, loss: 0.180\n",
      "Finished training for epoch 786, loss: 0.177\n",
      "Finished training for epoch 787, loss: 0.236\n",
      "Finished training for epoch 788, loss: 0.196\n",
      "Finished training for epoch 789, loss: 0.161\n",
      "Finished training for epoch 790, loss: 0.142\n",
      "Finished training for epoch 791, loss: 0.149\n",
      "Finished training for epoch 792, loss: 0.186\n",
      "Finished training for epoch 793, loss: 0.189\n",
      "Finished training for epoch 794, loss: 0.170\n",
      "Finished training for epoch 795, loss: 0.151\n",
      "Finished training for epoch 796, loss: 0.154\n",
      "Finished training for epoch 797, loss: 0.153\n",
      "Finished training for epoch 798, loss: 0.221\n",
      "Finished training for epoch 799, loss: 0.173\n",
      "Finished training for epoch 800, loss: 0.160\n",
      "Finished training for epoch 801, loss: 0.164\n",
      "Finished training for epoch 802, loss: 0.244\n",
      "Finished training for epoch 803, loss: 0.190\n",
      "Finished training for epoch 804, loss: 0.139\n",
      "Finished training for epoch 805, loss: 0.152\n",
      "Finished training for epoch 806, loss: 0.154\n",
      "Finished training for epoch 807, loss: 0.195\n",
      "Finished training for epoch 808, loss: 0.182\n",
      "Finished training for epoch 809, loss: 0.207\n",
      "Finished training for epoch 810, loss: 0.156\n",
      "Finished training for epoch 811, loss: 0.182\n",
      "Finished training for epoch 812, loss: 0.223\n",
      "Finished training for epoch 813, loss: 0.203\n",
      "Finished training for epoch 814, loss: 0.170\n",
      "Finished training for epoch 815, loss: 0.151\n",
      "Finished training for epoch 816, loss: 0.151\n",
      "Finished training for epoch 817, loss: 0.141\n",
      "Finished training for epoch 818, loss: 0.197\n",
      "Finished training for epoch 819, loss: 0.233\n",
      "Finished training for epoch 820, loss: 0.164\n",
      "Finished training for epoch 821, loss: 0.149\n",
      "Finished training for epoch 822, loss: 0.225\n",
      "Finished training for epoch 823, loss: 0.163\n",
      "Finished training for epoch 824, loss: 0.155\n",
      "Finished training for epoch 825, loss: 0.140\n",
      "Finished training for epoch 826, loss: 0.150\n",
      "Finished training for epoch 827, loss: 0.185\n",
      "Finished training for epoch 828, loss: 0.147\n",
      "Finished training for epoch 829, loss: 0.176\n",
      "Finished training for epoch 830, loss: 0.155\n",
      "Finished training for epoch 831, loss: 0.187\n",
      "Finished training for epoch 832, loss: 0.142\n",
      "Finished training for epoch 833, loss: 0.147\n",
      "Finished training for epoch 834, loss: 0.166\n",
      "Finished training for epoch 835, loss: 0.180\n",
      "Finished training for epoch 836, loss: 0.142\n",
      "Finished training for epoch 837, loss: 0.198\n",
      "Finished training for epoch 838, loss: 0.162\n",
      "Finished training for epoch 839, loss: 0.143\n",
      "Finished training for epoch 840, loss: 0.150\n",
      "Finished training for epoch 841, loss: 0.153\n",
      "Finished training for epoch 842, loss: 0.130\n",
      "Finished training for epoch 843, loss: 0.139\n",
      "Finished training for epoch 844, loss: 0.133\n",
      "Finished training for epoch 845, loss: 0.164\n",
      "Finished training for epoch 846, loss: 0.169\n",
      "Finished training for epoch 847, loss: 0.207\n",
      "Finished training for epoch 848, loss: 0.170\n",
      "Finished training for epoch 849, loss: 0.218\n",
      "Finished training for epoch 850, loss: 0.165\n",
      "Finished training for epoch 851, loss: 0.159\n",
      "Finished training for epoch 852, loss: 0.148\n",
      "Finished training for epoch 853, loss: 0.136\n",
      "Finished training for epoch 854, loss: 0.156\n",
      "Finished training for epoch 855, loss: 0.162\n",
      "Finished training for epoch 856, loss: 0.217\n",
      "Finished training for epoch 857, loss: 0.321\n",
      "Finished training for epoch 858, loss: 0.230\n",
      "Finished training for epoch 859, loss: 0.133\n",
      "Finished training for epoch 860, loss: 0.136\n",
      "Finished training for epoch 861, loss: 0.140\n",
      "Finished training for epoch 862, loss: 0.152\n",
      "Finished training for epoch 863, loss: 0.180\n",
      "Finished training for epoch 864, loss: 0.243\n",
      "Finished training for epoch 865, loss: 0.178\n",
      "Finished training for epoch 866, loss: 0.151\n",
      "Finished training for epoch 867, loss: 0.136\n",
      "Finished training for epoch 868, loss: 0.184\n",
      "Finished training for epoch 869, loss: 0.147\n",
      "Finished training for epoch 870, loss: 0.146\n",
      "Finished training for epoch 871, loss: 0.220\n",
      "Finished training for epoch 872, loss: 0.155\n",
      "Finished training for epoch 873, loss: 0.147\n",
      "Finished training for epoch 874, loss: 0.157\n",
      "Finished training for epoch 875, loss: 0.151\n",
      "Finished training for epoch 876, loss: 0.150\n",
      "Finished training for epoch 877, loss: 0.151\n",
      "Finished training for epoch 878, loss: 0.167\n",
      "Finished training for epoch 879, loss: 0.175\n",
      "Finished training for epoch 880, loss: 0.137\n",
      "Finished training for epoch 881, loss: 0.185\n",
      "Finished training for epoch 882, loss: 0.164\n",
      "Finished training for epoch 883, loss: 0.140\n",
      "Finished training for epoch 884, loss: 0.176\n",
      "Finished training for epoch 885, loss: 0.145\n",
      "Finished training for epoch 886, loss: 0.165\n",
      "Finished training for epoch 887, loss: 0.166\n",
      "Finished training for epoch 888, loss: 0.144\n",
      "Finished training for epoch 889, loss: 0.165\n",
      "Finished training for epoch 890, loss: 0.201\n",
      "Finished training for epoch 891, loss: 0.165\n",
      "Finished training for epoch 892, loss: 0.189\n",
      "Finished training for epoch 893, loss: 0.268\n",
      "Finished training for epoch 894, loss: 0.148\n",
      "Finished training for epoch 895, loss: 0.131\n",
      "Finished training for epoch 896, loss: 0.135\n",
      "Finished training for epoch 897, loss: 0.135\n",
      "Finished training for epoch 898, loss: 0.159\n",
      "Finished training for epoch 899, loss: 0.176\n",
      "Finished training for epoch 900, loss: 0.216\n",
      "Finished training for epoch 901, loss: 0.149\n",
      "Finished training for epoch 902, loss: 0.233\n",
      "Finished training for epoch 903, loss: 0.136\n",
      "Finished training for epoch 904, loss: 0.141\n",
      "Finished training for epoch 905, loss: 0.193\n",
      "Finished training for epoch 906, loss: 0.160\n",
      "Finished training for epoch 907, loss: 0.152\n",
      "Finished training for epoch 908, loss: 0.127\n",
      "Finished training for epoch 909, loss: 0.139\n",
      "Finished training for epoch 910, loss: 0.163\n",
      "Finished training for epoch 911, loss: 0.271\n",
      "Finished training for epoch 912, loss: 0.193\n",
      "Finished training for epoch 913, loss: 0.148\n",
      "Finished training for epoch 914, loss: 0.161\n",
      "Finished training for epoch 915, loss: 0.151\n",
      "Finished training for epoch 916, loss: 0.198\n",
      "Finished training for epoch 917, loss: 0.176\n",
      "Finished training for epoch 918, loss: 0.206\n",
      "Finished training for epoch 919, loss: 0.143\n",
      "Finished training for epoch 920, loss: 0.200\n",
      "Finished training for epoch 921, loss: 0.153\n",
      "Finished training for epoch 922, loss: 0.161\n",
      "Finished training for epoch 923, loss: 0.124\n",
      "Finished training for epoch 924, loss: 0.153\n",
      "Finished training for epoch 925, loss: 0.216\n",
      "Finished training for epoch 926, loss: 0.161\n",
      "Finished training for epoch 927, loss: 0.167\n",
      "Finished training for epoch 928, loss: 0.166\n",
      "Finished training for epoch 929, loss: 0.136\n",
      "Finished training for epoch 930, loss: 0.172\n",
      "Finished training for epoch 931, loss: 0.151\n",
      "Finished training for epoch 932, loss: 0.130\n",
      "Finished training for epoch 933, loss: 0.151\n",
      "Finished training for epoch 934, loss: 0.182\n",
      "Finished training for epoch 935, loss: 0.173\n",
      "Finished training for epoch 936, loss: 0.170\n",
      "Finished training for epoch 937, loss: 0.157\n",
      "Finished training for epoch 938, loss: 0.136\n",
      "Finished training for epoch 939, loss: 0.265\n",
      "Finished training for epoch 940, loss: 0.146\n",
      "Finished training for epoch 941, loss: 0.185\n",
      "Finished training for epoch 942, loss: 0.169\n",
      "Finished training for epoch 943, loss: 0.182\n",
      "Finished training for epoch 944, loss: 0.197\n",
      "Finished training for epoch 945, loss: 0.136\n",
      "Finished training for epoch 946, loss: 0.163\n",
      "Finished training for epoch 947, loss: 0.174\n",
      "Finished training for epoch 948, loss: 0.139\n",
      "Finished training for epoch 949, loss: 0.138\n",
      "Finished training for epoch 950, loss: 0.153\n",
      "Finished training for epoch 951, loss: 0.171\n",
      "Finished training for epoch 952, loss: 0.173\n",
      "Finished training for epoch 953, loss: 0.196\n",
      "Finished training for epoch 954, loss: 0.133\n",
      "Finished training for epoch 955, loss: 0.127\n",
      "Finished training for epoch 956, loss: 0.158\n",
      "Finished training for epoch 957, loss: 0.199\n",
      "Finished training for epoch 958, loss: 0.139\n",
      "Finished training for epoch 959, loss: 0.153\n",
      "Finished training for epoch 960, loss: 0.144\n",
      "Finished training for epoch 961, loss: 0.178\n",
      "Finished training for epoch 962, loss: 0.161\n",
      "Finished training for epoch 963, loss: 0.124\n",
      "Finished training for epoch 964, loss: 0.141\n",
      "Finished training for epoch 965, loss: 0.119\n",
      "Finished training for epoch 966, loss: 0.142\n",
      "Finished training for epoch 967, loss: 0.133\n",
      "Finished training for epoch 968, loss: 0.140\n",
      "Finished training for epoch 969, loss: 0.124\n",
      "Finished training for epoch 970, loss: 0.126\n",
      "Finished training for epoch 971, loss: 0.124\n",
      "Finished training for epoch 972, loss: 0.210\n",
      "Finished training for epoch 973, loss: 0.197\n",
      "Finished training for epoch 974, loss: 0.152\n",
      "Finished training for epoch 975, loss: 0.140\n",
      "Finished training for epoch 976, loss: 0.127\n",
      "Finished training for epoch 977, loss: 0.171\n",
      "Finished training for epoch 978, loss: 0.127\n",
      "Finished training for epoch 979, loss: 0.179\n",
      "Finished training for epoch 980, loss: 0.148\n",
      "Finished training for epoch 981, loss: 0.126\n",
      "Finished training for epoch 982, loss: 0.158\n",
      "Finished training for epoch 983, loss: 0.164\n",
      "Finished training for epoch 984, loss: 0.147\n",
      "Finished training for epoch 985, loss: 0.134\n",
      "Finished training for epoch 986, loss: 0.147\n",
      "Finished training for epoch 987, loss: 0.153\n",
      "Finished training for epoch 988, loss: 0.120\n",
      "Finished training for epoch 989, loss: 0.162\n",
      "Finished training for epoch 990, loss: 0.177\n",
      "Finished training for epoch 991, loss: 0.182\n",
      "Finished training for epoch 992, loss: 0.121\n",
      "Finished training for epoch 993, loss: 0.222\n",
      "Finished training for epoch 994, loss: 0.139\n",
      "Finished training for epoch 995, loss: 0.158\n",
      "Finished training for epoch 996, loss: 0.186\n",
      "Finished training for epoch 997, loss: 0.127\n",
      "Finished training for epoch 998, loss: 0.171\n",
      "Finished training for epoch 999, loss: 0.242\n",
      "Finished training for epoch 1000, loss: 0.208\n"
     ]
    }
   ],
   "source": [
    "net_3 = Net()\n",
    "net_3 = train_model_custom(net_3, dataset_merged_train_modified, 32, 1000, 0.001, 8579.598230609947)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_uniform_test_modified = SystemDatasetModified(\"dataset_arbi2d.csv\", 0)\n",
    "dataset_near_test_modified = SystemDatasetModified(\"dataset_arbi2d_near.csv\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9985899925231934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9986)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_modified(net_3, dataset_uniform_test_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7253999710083008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7254)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_modified(net_3, dataset_near_test_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Accuracy: 0.995710015296936\n",
      "Accuracy: 0.5703499913215637\n",
      "Accuracy: 0.9985899925231934\n",
      "Accuracy: 0.7597500085830688\n",
      "Accuracy: 0.998769998550415\n",
      "Accuracy: 0.7280499935150146\n",
      "Iteration 2\n",
      "Accuracy: 0.9957000017166138\n",
      "Accuracy: 0.6208000183105469\n",
      "Accuracy: 0.9971100091934204\n",
      "Accuracy: 0.6136000156402588\n",
      "Accuracy: 0.9978399872779846\n",
      "Accuracy: 0.6050500273704529\n",
      "Iteration 3\n",
      "Accuracy: 0.9942399859428406\n",
      "Accuracy: 0.5706999897956848\n",
      "Accuracy: 0.9975000023841858\n",
      "Accuracy: 0.5347999930381775\n",
      "Accuracy: 0.9986500144004822\n",
      "Accuracy: 0.6388499736785889\n",
      "Iteration 4\n",
      "Accuracy: 0.9933500289916992\n",
      "Accuracy: 0.6016499996185303\n",
      "Accuracy: 0.998199999332428\n",
      "Accuracy: 0.5878999829292297\n",
      "Accuracy: 0.9988099932670593\n",
      "Accuracy: 0.7616999745368958\n",
      "Iteration 5\n",
      "Accuracy: 0.9924600124359131\n",
      "Accuracy: 0.5188500285148621\n",
      "Accuracy: 0.9973400235176086\n",
      "Accuracy: 0.612500011920929\n",
      "Accuracy: 0.9980400204658508\n",
      "Accuracy: 0.696150004863739\n",
      "Iteration 6\n",
      "Accuracy: 0.992169976234436\n",
      "Accuracy: 0.5425999760627747\n",
      "Accuracy: 0.998449981212616\n",
      "Accuracy: 0.6878499984741211\n",
      "Accuracy: 0.9988200068473816\n",
      "Accuracy: 0.7803500294685364\n",
      "Iteration 7\n",
      "Accuracy: 0.995169997215271\n",
      "Accuracy: 0.6502500176429749\n",
      "Accuracy: 0.9973499774932861\n",
      "Accuracy: 0.6169499754905701\n",
      "Accuracy: 0.9978899955749512\n",
      "Accuracy: 0.6523000001907349\n",
      "Iteration 8\n",
      "Accuracy: 0.9935700297355652\n",
      "Accuracy: 0.5475999712944031\n",
      "Accuracy: 0.9975799918174744\n",
      "Accuracy: 0.6814500093460083\n",
      "Accuracy: 0.9994099736213684\n",
      "Accuracy: 0.8514500260353088\n",
      "Iteration 9\n",
      "Accuracy: 0.992680013179779\n",
      "Accuracy: 0.5393499732017517\n",
      "Accuracy: 0.9968100190162659\n",
      "Accuracy: 0.6464499831199646\n",
      "Accuracy: 0.9983100295066833\n",
      "Accuracy: 0.6870999932289124\n",
      "Iteration 10\n",
      "Accuracy: 0.9904299974441528\n",
      "Accuracy: 0.5254999995231628\n",
      "Accuracy: 0.9987499713897705\n",
      "Accuracy: 0.6949499845504761\n",
      "Accuracy: 0.999459981918335\n",
      "Accuracy: 0.8736500144004822\n",
      "Average accuracy for uniform test set with model 1: 0.9935480356216431\n",
      "Average accuracy for near test set with model 1: 0.5687649846076965\n",
      "Average accuracy for uniform test set with model 2: 0.9977680444717407\n",
      "Average accuracy for near test set with model 2: 0.643619954586029\n",
      "Average accuracy for uniform test set with model 3: 0.9986000061035156\n",
      "Average accuracy for near test set with model 3: 0.727465033531189\n"
     ]
    }
   ],
   "source": [
    "accuracy_uniform_1 = 0\n",
    "accuracy_near_1 = 0\n",
    "accuracy_uniform_2 = 0\n",
    "accuracy_near_2 = 0\n",
    "accuracy_uniform_3 = 0\n",
    "accuracy_near_3 = 0\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'Iteration {i + 1}')\n",
    "    \n",
    "    net_1 = Net()\n",
    "    dataset_train_1 = SystemDataset(\"dataset_arbi2d_1000.csv\")\n",
    "    net_1 = train_model_bce(net_1, dataset_train_1, 32, 100, 0.001)\n",
    "\n",
    "    net_2 = Net()\n",
    "    dataset_uniform_train = SystemDataset(\"dataset_arbi2d_1000.csv\")\n",
    "    dataset_near_train = SystemDataset(\"dataset_arbi2d_enhanced_1600.csv\")\n",
    "    dataset_merged_train = torch.utils.data.ConcatDataset([dataset_uniform_train, dataset_near_train])\n",
    "    net_2 = train_model_bce(net_2, dataset_merged_train, 32, 100, 0.001)\n",
    "\n",
    "    net_3 = Net()\n",
    "    dataset_uniform_train_modified = SystemDatasetModified(\"dataset_arbi2d_1000.csv\", 0)\n",
    "    dataset_near_train_modified = SystemDatasetModified(\"dataset_arbi2d_enhanced_1600.csv\", 1)\n",
    "    dataset_merged_train_modified = torch.utils.data.ConcatDataset([dataset_uniform_train_modified, dataset_near_train_modified])\n",
    "    net_3 = train_model_custom(net_3, dataset_merged_train_modified, 32, 100, 0.001, 8442.813220061595)\n",
    "\n",
    "    accuracy_uniform_1 += test_model(net_1, dataset_uniform_test)\n",
    "    accuracy_near_1 += test_model(net_1, dataset_near_test)\n",
    "    accuracy_uniform_2 += test_model(net_2, dataset_uniform_test)\n",
    "    accuracy_near_2 += test_model(net_2, dataset_near_test)\n",
    "    accuracy_uniform_3 += test_model_modified(net_3, dataset_uniform_test_modified)\n",
    "    accuracy_near_3 += test_model_modified(net_3, dataset_near_test_modified)\n",
    "\n",
    "print(f'Average accuracy for uniform test set with model 1: {accuracy_uniform_1 / 10}')\n",
    "print(f'Average accuracy for near test set with model 1: {accuracy_near_1 / 10}')\n",
    "print(f'Average accuracy for uniform test set with model 2: {accuracy_uniform_2 / 10}')\n",
    "print(f'Average accuracy for near test set with model 2: {accuracy_near_2 / 10}')\n",
    "print(f'Average accuracy for uniform test set with model 3: {accuracy_uniform_3 / 10}')\n",
    "print(f'Average accuracy for near test set with model 3: {accuracy_near_3 / 10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Accuracy: 0.9987999796867371\n",
      "Accuracy: 0.7473999857902527\n",
      "Iteration 2\n",
      "Accuracy: 0.9986000061035156\n",
      "Accuracy: 0.7853000164031982\n",
      "Iteration 3\n",
      "Accuracy: 0.9987599849700928\n",
      "Accuracy: 0.7303500175476074\n",
      "Iteration 4\n",
      "Accuracy: 0.9982900023460388\n",
      "Accuracy: 0.7143999934196472\n",
      "Iteration 5\n",
      "Accuracy: 0.9993299841880798\n",
      "Accuracy: 0.8738499879837036\n",
      "Iteration 6\n",
      "Accuracy: 0.9987000226974487\n",
      "Accuracy: 0.7813500165939331\n",
      "Iteration 7\n",
      "Accuracy: 0.9993900060653687\n",
      "Accuracy: 0.8648499846458435\n",
      "Iteration 8\n",
      "Accuracy: 0.999239981174469\n",
      "Accuracy: 0.845300018787384\n",
      "Iteration 9\n",
      "Accuracy: 0.9991000294685364\n",
      "Accuracy: 0.8141999840736389\n",
      "Iteration 10\n",
      "Accuracy: 0.9985499978065491\n",
      "Accuracy: 0.6807000041007996\n",
      "Iteration 11\n",
      "Accuracy: 0.9992600083351135\n",
      "Accuracy: 0.8646500110626221\n",
      "Iteration 12\n",
      "Accuracy: 0.9990900158882141\n",
      "Accuracy: 0.7172999978065491\n",
      "Iteration 13\n",
      "Accuracy: 0.9988800287246704\n",
      "Accuracy: 0.8895999789237976\n",
      "Iteration 14\n",
      "Accuracy: 0.9994099736213684\n",
      "Accuracy: 0.8838499784469604\n",
      "Iteration 15\n",
      "Accuracy: 0.9986400008201599\n",
      "Accuracy: 0.8086000084877014\n",
      "Iteration 16\n",
      "Accuracy: 0.9993600249290466\n",
      "Accuracy: 0.8550000190734863\n",
      "Iteration 17\n",
      "Accuracy: 0.9983400106430054\n",
      "Accuracy: 0.7494500279426575\n",
      "Iteration 18\n",
      "Accuracy: 0.9989699721336365\n",
      "Accuracy: 0.786899983882904\n",
      "Iteration 19\n",
      "Accuracy: 0.9991999864578247\n",
      "Accuracy: 0.8619499802589417\n",
      "Iteration 20\n",
      "Accuracy: 0.9993199706077576\n",
      "Accuracy: 0.8893499970436096\n",
      "Iteration 21\n",
      "Accuracy: 0.9987499713897705\n",
      "Accuracy: 0.7442499995231628\n",
      "Iteration 22\n",
      "Accuracy: 0.9988499879837036\n",
      "Accuracy: 0.8127999901771545\n",
      "Iteration 23\n",
      "Accuracy: 0.9995999932289124\n",
      "Accuracy: 0.8930000066757202\n",
      "Iteration 24\n",
      "Accuracy: 0.9980300068855286\n",
      "Accuracy: 0.6825500130653381\n",
      "Iteration 25\n",
      "Accuracy: 0.9988800287246704\n",
      "Accuracy: 0.8299499750137329\n",
      "Iteration 26\n",
      "Accuracy: 0.9991700053215027\n",
      "Accuracy: 0.8039000034332275\n",
      "Iteration 27\n",
      "Accuracy: 0.9989399909973145\n",
      "Accuracy: 0.8133500218391418\n",
      "Iteration 28\n",
      "Accuracy: 0.9990699887275696\n",
      "Accuracy: 0.8567500114440918\n",
      "Iteration 29\n",
      "Accuracy: 0.9988600015640259\n",
      "Accuracy: 0.6967499852180481\n",
      "Iteration 30\n",
      "Accuracy: 0.9985799789428711\n",
      "Accuracy: 0.8205999732017517\n",
      "Iteration 31\n",
      "Accuracy: 0.9989299774169922\n",
      "Accuracy: 0.8608499765396118\n",
      "Iteration 32\n",
      "Accuracy: 0.9993500113487244\n",
      "Accuracy: 0.8972499966621399\n",
      "Iteration 33\n",
      "Accuracy: 0.999210000038147\n",
      "Accuracy: 0.8794999718666077\n",
      "Iteration 34\n",
      "Accuracy: 0.9990900158882141\n",
      "Accuracy: 0.8219000101089478\n",
      "Iteration 35\n",
      "Accuracy: 0.9990800023078918\n",
      "Accuracy: 0.7561500072479248\n",
      "Iteration 36\n",
      "Accuracy: 0.9986100196838379\n",
      "Accuracy: 0.7897999882698059\n",
      "Iteration 37\n",
      "Accuracy: 0.9988700151443481\n",
      "Accuracy: 0.6820999979972839\n",
      "Iteration 38\n",
      "Accuracy: 0.9994000196456909\n",
      "Accuracy: 0.8730000257492065\n",
      "Iteration 39\n",
      "Accuracy: 0.9993100166320801\n",
      "Accuracy: 0.8503999710083008\n",
      "Iteration 40\n",
      "Accuracy: 0.9989100098609924\n",
      "Accuracy: 0.7301999926567078\n",
      "Iteration 41\n",
      "Accuracy: 0.9990400075912476\n",
      "Accuracy: 0.8162500262260437\n",
      "Iteration 42\n",
      "Accuracy: 0.999210000038147\n",
      "Accuracy: 0.7990000247955322\n",
      "Iteration 43\n",
      "Accuracy: 0.998989999294281\n",
      "Accuracy: 0.6823499798774719\n",
      "Iteration 44\n",
      "Accuracy: 0.9994099736213684\n",
      "Accuracy: 0.8313500285148621\n",
      "Iteration 45\n",
      "Accuracy: 0.9991700053215027\n",
      "Accuracy: 0.7728000283241272\n",
      "Iteration 46\n",
      "Accuracy: 0.9993600249290466\n",
      "Accuracy: 0.892300009727478\n",
      "Iteration 47\n",
      "Accuracy: 0.9989500045776367\n",
      "Accuracy: 0.8105000257492065\n",
      "Iteration 48\n",
      "Accuracy: 0.9987900257110596\n",
      "Accuracy: 0.7728999853134155\n",
      "Iteration 49\n",
      "Accuracy: 0.9994000196456909\n",
      "Accuracy: 0.895799994468689\n",
      "Iteration 50\n",
      "Accuracy: 0.9993600249290466\n",
      "Accuracy: 0.8640000224113464\n",
      "Average accuracy for uniform test set with model 2: 0.9990079402923584\n",
      "Average accuracy for near test set with model 2: 0.8075329661369324\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy_uniform_2 = 0\n",
    "accuracy_near_2 = 0\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    print(f'Iteration {i + 1}')\n",
    "    \n",
    "    net_2 = Net()\n",
    "    dataset_uniform_train = SystemDataset(\"dataset_arbi2d_1000.csv\")\n",
    "    dataset_near_train = SystemDataset(\"dataset_arbi2d_enhanced_400.csv\")\n",
    "    dataset_merged_train = torch.utils.data.ConcatDataset([dataset_uniform_train, dataset_near_train])\n",
    "    net_2 = train_model_bce(net_2, dataset_merged_train, 32, 1000, 0.001)\n",
    "\n",
    "    accuracy_uniform_2 += test_model(net_2, dataset_uniform_test)\n",
    "    accuracy_near_2 += test_model(net_2, dataset_near_test)\n",
    "\n",
    "print(f'Average accuracy for uniform test set with model 2: {accuracy_uniform_2 / 50}')\n",
    "print(f'Average accuracy for near test set with model 2: {accuracy_near_2 / 50}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Accuracy: 0.8434500098228455\n",
      "Accuracy: 0.8025000095367432\n",
      "Accuracy: 0.6996999979019165\n",
      "Accuracy: 0.8514000177383423\n",
      "Accuracy: 0.8884999752044678\n",
      "Accuracy: 0.9013000130653381\n",
      "Accuracy: 0.736549973487854\n",
      "Accuracy: 0.725350022315979\n",
      "Accuracy: 0.8250499963760376\n",
      "Accuracy: 0.8926500082015991\n",
      "Accuracy: 0.8576499819755554\n",
      "Accuracy: 0.8655499815940857\n",
      "Accuracy: 0.8514500260353088\n",
      "Accuracy: 0.7992500066757202\n",
      "Accuracy: 0.8424999713897705\n",
      "Accuracy: 0.8537999987602234\n",
      "Accuracy: 0.7361000180244446\n",
      "Accuracy: 0.7174999713897705\n",
      "Accuracy: 0.7762500047683716\n",
      "Accuracy: 0.8208500146865845\n",
      "Accuracy: 0.862500011920929\n",
      "Accuracy: 0.8146499991416931\n",
      "Accuracy: 0.8536499738693237\n",
      "Accuracy: 0.7886499762535095\n",
      "Accuracy: 0.797249972820282\n",
      "Accuracy: 0.7387999892234802\n",
      "Accuracy: 0.7070500254631042\n",
      "Accuracy: 0.8984000086784363\n",
      "Accuracy: 0.7512999773025513\n",
      "Accuracy: 0.8277999758720398\n",
      "Accuracy: 0.8080000281333923\n",
      "Accuracy: 0.7767500281333923\n",
      "Accuracy: 0.8344500064849854\n",
      "Accuracy: 0.840399980545044\n",
      "Accuracy: 0.6510000228881836\n",
      "Accuracy: 0.853600025177002\n",
      "Accuracy: 0.838949978351593\n",
      "Accuracy: 0.8299000263214111\n",
      "Accuracy: 0.7465999722480774\n",
      "Accuracy: 0.8178499937057495\n",
      "Accuracy: 0.6606500148773193\n",
      "Accuracy: 0.838949978351593\n",
      "Accuracy: 0.6632999777793884\n",
      "Accuracy: 0.7573000192642212\n",
      "Accuracy: 0.8109999895095825\n",
      "Accuracy: 0.8395500183105469\n",
      "Accuracy: 0.807200014591217\n",
      "Accuracy: 0.7802000045776367\n",
      "Accuracy: 0.6636499762535095\n",
      "Accuracy: 0.8409000039100647\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 6384.4257\n",
      "Function value obtained: -13.3292\n",
      "Current minimum: -13.3292\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Accuracy: 0.6852999925613403\n",
      "Accuracy: 0.7886000275611877\n",
      "Accuracy: 0.8489500284194946\n",
      "Accuracy: 0.9083499908447266\n",
      "Accuracy: 0.5360000133514404\n",
      "Accuracy: 0.7561500072479248\n",
      "Accuracy: 0.5824499726295471\n",
      "Accuracy: 0.8450999855995178\n",
      "Accuracy: 0.8586000204086304\n",
      "Accuracy: 0.890749990940094\n",
      "Accuracy: 0.6826000213623047\n",
      "Accuracy: 0.658050000667572\n",
      "Accuracy: 0.713450014591217\n",
      "Accuracy: 0.809249997138977\n",
      "Accuracy: 0.8150500059127808\n",
      "Accuracy: 0.7950500249862671\n",
      "Accuracy: 0.7414500117301941\n",
      "Accuracy: 0.836899995803833\n",
      "Accuracy: 0.9009000062942505\n",
      "Accuracy: 0.8095999956130981\n",
      "Accuracy: 0.8295999765396118\n",
      "Accuracy: 0.8272500038146973\n",
      "Accuracy: 0.8224999904632568\n",
      "Accuracy: 0.770550012588501\n",
      "Accuracy: 0.7844499945640564\n",
      "Accuracy: 0.7196000218391418\n",
      "Accuracy: 0.7734500169754028\n",
      "Accuracy: 0.8427000045776367\n",
      "Accuracy: 0.758400022983551\n",
      "Accuracy: 0.8102999925613403\n",
      "Accuracy: 0.85794997215271\n",
      "Accuracy: 0.6916999816894531\n",
      "Accuracy: 0.7820000052452087\n",
      "Accuracy: 0.8300999999046326\n",
      "Accuracy: 0.826200008392334\n",
      "Accuracy: 0.7997999787330627\n",
      "Accuracy: 0.7680000066757202\n",
      "Accuracy: 0.7965499758720398\n",
      "Accuracy: 0.608299970626831\n",
      "Accuracy: 0.7296000123023987\n",
      "Accuracy: 0.7871999740600586\n",
      "Accuracy: 0.8509500026702881\n",
      "Accuracy: 0.899649977684021\n",
      "Accuracy: 0.859250009059906\n",
      "Accuracy: 0.8730999827384949\n",
      "Accuracy: 0.7847499847412109\n",
      "Accuracy: 0.8123000264167786\n",
      "Accuracy: 0.7736999988555908\n",
      "Accuracy: 0.8280500173568726\n",
      "Accuracy: 0.8036999702453613\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 6380.9047\n",
      "Function value obtained: -13.1214\n",
      "Current minimum: -13.3292\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Accuracy: 0.8730000257492065\n",
      "Accuracy: 0.834850013256073\n",
      "Accuracy: 0.8458499908447266\n",
      "Accuracy: 0.8848999738693237\n",
      "Accuracy: 0.8118000030517578\n",
      "Accuracy: 0.7911999821662903\n",
      "Accuracy: 0.7257500290870667\n",
      "Accuracy: 0.8843500018119812\n",
      "Accuracy: 0.7817500233650208\n",
      "Accuracy: 0.8956999778747559\n",
      "Accuracy: 0.8740500211715698\n",
      "Accuracy: 0.8043500185012817\n",
      "Accuracy: 0.8627499938011169\n",
      "Accuracy: 0.8133500218391418\n",
      "Accuracy: 0.8328999876976013\n",
      "Accuracy: 0.848550021648407\n",
      "Accuracy: 0.7846999764442444\n",
      "Accuracy: 0.8105999827384949\n",
      "Accuracy: 0.7516999840736389\n",
      "Accuracy: 0.8888000249862671\n",
      "Accuracy: 0.7811499834060669\n",
      "Accuracy: 0.8648499846458435\n",
      "Accuracy: 0.7634000182151794\n",
      "Accuracy: 0.8504499793052673\n",
      "Accuracy: 0.7851999998092651\n",
      "Accuracy: 0.7986999750137329\n",
      "Accuracy: 0.8981000185012817\n",
      "Accuracy: 0.7936000227928162\n",
      "Accuracy: 0.6955999732017517\n",
      "Accuracy: 0.9103000164031982\n",
      "Accuracy: 0.7975999712944031\n",
      "Accuracy: 0.8885499835014343\n",
      "Accuracy: 0.7247999906539917\n",
      "Accuracy: 0.8284500241279602\n",
      "Accuracy: 0.8567500114440918\n",
      "Accuracy: 0.8719000220298767\n",
      "Accuracy: 0.8512499928474426\n",
      "Accuracy: 0.7652000188827515\n",
      "Accuracy: 0.8313500285148621\n",
      "Accuracy: 0.6959999799728394\n",
      "Accuracy: 0.7462999820709229\n",
      "Accuracy: 0.8255000114440918\n",
      "Accuracy: 0.7645999789237976\n",
      "Accuracy: 0.7649999856948853\n",
      "Accuracy: 0.7089999914169312\n",
      "Accuracy: 0.6525499820709229\n",
      "Accuracy: 0.8998500108718872\n",
      "Accuracy: 0.6969000101089478\n",
      "Accuracy: 0.8928999900817871\n",
      "Accuracy: 0.8156999945640564\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 6379.6128\n",
      "Function value obtained: -13.5408\n",
      "Current minimum: -13.5408\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Accuracy: 0.7071499824523926\n",
      "Accuracy: 0.7559000253677368\n",
      "Accuracy: 0.7501500248908997\n",
      "Accuracy: 0.6959999799728394\n",
      "Accuracy: 0.7907000184059143\n",
      "Accuracy: 0.774150013923645\n",
      "Accuracy: 0.8792499899864197\n",
      "Accuracy: 0.8508999943733215\n",
      "Accuracy: 0.7609999775886536\n",
      "Accuracy: 0.906000018119812\n",
      "Accuracy: 0.881850004196167\n",
      "Accuracy: 0.8731499910354614\n",
      "Accuracy: 0.8673999905586243\n",
      "Accuracy: 0.8416000008583069\n",
      "Accuracy: 0.8561000227928162\n",
      "Accuracy: 0.5723999738693237\n",
      "Accuracy: 0.8986999988555908\n",
      "Accuracy: 0.7565500140190125\n",
      "Accuracy: 0.7640500068664551\n",
      "Accuracy: 0.6156499981880188\n",
      "Accuracy: 0.8837000131607056\n",
      "Accuracy: 0.8274999856948853\n",
      "Accuracy: 0.7991999983787537\n",
      "Accuracy: 0.8690500259399414\n",
      "Accuracy: 0.6655499935150146\n",
      "Accuracy: 0.9162499904632568\n",
      "Accuracy: 0.6274999976158142\n",
      "Accuracy: 0.7340499758720398\n",
      "Accuracy: 0.7947499752044678\n",
      "Accuracy: 0.7596499919891357\n",
      "Accuracy: 0.8321499824523926\n",
      "Accuracy: 0.8528000116348267\n",
      "Accuracy: 0.8066999912261963\n",
      "Accuracy: 0.8665000200271606\n",
      "Accuracy: 0.8255500197410583\n",
      "Accuracy: 0.875\n",
      "Accuracy: 0.900950014591217\n",
      "Accuracy: 0.820900022983551\n",
      "Accuracy: 0.758650004863739\n",
      "Accuracy: 0.7885000109672546\n",
      "Accuracy: 0.8226000070571899\n",
      "Accuracy: 0.745199978351593\n",
      "Accuracy: 0.736299991607666\n",
      "Accuracy: 0.791700005531311\n",
      "Accuracy: 0.861549973487854\n",
      "Accuracy: 0.8236500024795532\n",
      "Accuracy: 0.7470499873161316\n",
      "Accuracy: 0.7489500045776367\n",
      "Accuracy: 0.8798999786376953\n",
      "Accuracy: 0.84375\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 6375.8569\n",
      "Function value obtained: -13.3347\n",
      "Current minimum: -13.5408\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Accuracy: 0.8351500034332275\n",
      "Accuracy: 0.7555999755859375\n",
      "Accuracy: 0.733299970626831\n",
      "Accuracy: 0.7894499897956848\n",
      "Accuracy: 0.7035499811172485\n",
      "Accuracy: 0.8566499948501587\n",
      "Accuracy: 0.9012500047683716\n",
      "Accuracy: 0.8171499967575073\n",
      "Accuracy: 0.8820000290870667\n",
      "Accuracy: 0.7877500057220459\n",
      "Accuracy: 0.7393500208854675\n",
      "Accuracy: 0.7822999954223633\n",
      "Accuracy: 0.8005499839782715\n",
      "Accuracy: 0.7081500291824341\n",
      "Accuracy: 0.8518000245094299\n",
      "Accuracy: 0.7933499813079834\n",
      "Accuracy: 0.7529000043869019\n",
      "Accuracy: 0.631850004196167\n",
      "Accuracy: 0.8705999851226807\n",
      "Accuracy: 0.9006999731063843\n",
      "Accuracy: 0.7849000096321106\n",
      "Accuracy: 0.8126000165939331\n",
      "Accuracy: 0.8666499853134155\n",
      "Accuracy: 0.8037999868392944\n",
      "Accuracy: 0.7751500010490417\n",
      "Accuracy: 0.8097500205039978\n",
      "Accuracy: 0.8706499934196472\n",
      "Accuracy: 0.7821000218391418\n",
      "Accuracy: 0.8858500123023987\n",
      "Accuracy: 0.692799985408783\n",
      "Accuracy: 0.852150022983551\n",
      "Accuracy: 0.9055500030517578\n",
      "Accuracy: 0.7944499850273132\n",
      "Accuracy: 0.8119000196456909\n",
      "Accuracy: 0.7304499745368958\n",
      "Accuracy: 0.9019500017166138\n",
      "Accuracy: 0.7996500134468079\n",
      "Accuracy: 0.8922500014305115\n",
      "Accuracy: 0.746649980545044\n",
      "Accuracy: 0.7939000129699707\n",
      "Accuracy: 0.7706500291824341\n",
      "Accuracy: 0.8511499762535095\n",
      "Accuracy: 0.7670999765396118\n",
      "Accuracy: 0.7940999865531921\n",
      "Accuracy: 0.748199999332428\n",
      "Accuracy: 0.8087000250816345\n",
      "Accuracy: 0.8396999835968018\n",
      "Accuracy: 0.7591500282287598\n",
      "Accuracy: 0.7946500182151794\n",
      "Accuracy: 0.7452499866485596\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 6285.8285\n",
      "Function value obtained: -13.3617\n",
      "Current minimum: -13.5408\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "Accuracy: 0.8114500045776367\n",
      "Accuracy: 0.8583999872207642\n",
      "Accuracy: 0.8353999853134155\n",
      "Accuracy: 0.8784499764442444\n",
      "Accuracy: 0.9077500104904175\n",
      "Accuracy: 0.798799991607666\n",
      "Accuracy: 0.8409500122070312\n",
      "Accuracy: 0.7327499985694885\n",
      "Accuracy: 0.7334499955177307\n",
      "Accuracy: 0.8655499815940857\n",
      "Accuracy: 0.7925999760627747\n",
      "Accuracy: 0.9100499749183655\n",
      "Accuracy: 0.6637499928474426\n",
      "Accuracy: 0.8065500259399414\n",
      "Accuracy: 0.7266499996185303\n",
      "Accuracy: 0.7351499795913696\n",
      "Accuracy: 0.8351500034332275\n",
      "Accuracy: 0.7592999935150146\n",
      "Accuracy: 0.8924499750137329\n",
      "Accuracy: 0.8174999952316284\n",
      "Accuracy: 0.8248000144958496\n",
      "Accuracy: 0.8496500253677368\n",
      "Accuracy: 0.6001999974250793\n",
      "Accuracy: 0.8722000122070312\n",
      "Accuracy: 0.8619999885559082\n",
      "Accuracy: 0.843500018119812\n",
      "Accuracy: 0.7924000024795532\n",
      "Accuracy: 0.7035999894142151\n",
      "Accuracy: 0.7491999864578247\n",
      "Accuracy: 0.7809500098228455\n",
      "Accuracy: 0.7373499870300293\n",
      "Accuracy: 0.8701000213623047\n",
      "Accuracy: 0.8295000195503235\n",
      "Accuracy: 0.8427500128746033\n",
      "Accuracy: 0.7315499782562256\n",
      "Accuracy: 0.8128499984741211\n",
      "Accuracy: 0.8222000002861023\n",
      "Accuracy: 0.9034000039100647\n",
      "Accuracy: 0.784850001335144\n",
      "Accuracy: 0.7627000212669373\n",
      "Accuracy: 0.8155500292778015\n",
      "Accuracy: 0.7631000280380249\n",
      "Accuracy: 0.8756999969482422\n",
      "Accuracy: 0.7028499841690063\n",
      "Accuracy: 0.7918999791145325\n",
      "Accuracy: 0.755649983882904\n",
      "Accuracy: 0.909850001335144\n",
      "Accuracy: 0.6726999878883362\n",
      "Accuracy: 0.8460000157356262\n",
      "Accuracy: 0.9016000032424927\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 6378.0153\n",
      "Function value obtained: -13.4042\n",
      "Current minimum: -13.5408\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "Accuracy: 0.7330499887466431\n",
      "Accuracy: 0.8452000021934509\n",
      "Accuracy: 0.88919997215271\n",
      "Accuracy: 0.8396000266075134\n",
      "Accuracy: 0.6945499777793884\n",
      "Accuracy: 0.8641499876976013\n",
      "Accuracy: 0.8731499910354614\n",
      "Accuracy: 0.7483000159263611\n",
      "Accuracy: 0.6570000052452087\n",
      "Accuracy: 0.723550021648407\n",
      "Accuracy: 0.7384999990463257\n",
      "Accuracy: 0.7333499789237976\n",
      "Accuracy: 0.8788999915122986\n",
      "Accuracy: 0.8411999940872192\n",
      "Accuracy: 0.8603500127792358\n",
      "Accuracy: 0.8743500113487244\n",
      "Accuracy: 0.7958999872207642\n",
      "Accuracy: 0.7648500204086304\n",
      "Accuracy: 0.8952000141143799\n",
      "Accuracy: 0.6923499703407288\n",
      "Accuracy: 0.8324499726295471\n",
      "Accuracy: 0.757099986076355\n",
      "Accuracy: 0.7821999788284302\n",
      "Accuracy: 0.8659999966621399\n",
      "Accuracy: 0.8353000283241272\n",
      "Accuracy: 0.790149986743927\n",
      "Accuracy: 0.7716000080108643\n",
      "Accuracy: 0.8791999816894531\n",
      "Accuracy: 0.8766999840736389\n",
      "Accuracy: 0.8014500141143799\n",
      "Accuracy: 0.6535500288009644\n",
      "Accuracy: 0.8202499747276306\n",
      "Accuracy: 0.8497499823570251\n",
      "Accuracy: 0.6898499727249146\n",
      "Accuracy: 0.7479000091552734\n",
      "Accuracy: 0.8227499723434448\n",
      "Accuracy: 0.8238499760627747\n",
      "Accuracy: 0.8133500218391418\n",
      "Accuracy: 0.729449987411499\n",
      "Accuracy: 0.8769999742507935\n",
      "Accuracy: 0.7944499850273132\n",
      "Accuracy: 0.852150022983551\n",
      "Accuracy: 0.8137000203132629\n",
      "Accuracy: 0.8685500025749207\n",
      "Accuracy: 0.8161500096321106\n",
      "Accuracy: 0.7849500179290771\n",
      "Accuracy: 0.8456000089645386\n",
      "Accuracy: 0.8101500272750854\n",
      "Accuracy: 0.8303499817848206\n",
      "Accuracy: 0.8822500109672546\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 6311.1096\n",
      "Function value obtained: -13.4203\n",
      "Current minimum: -13.5408\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "Accuracy: 0.8810999989509583\n",
      "Accuracy: 0.869700014591217\n",
      "Accuracy: 0.7307999730110168\n",
      "Accuracy: 0.6859999895095825\n",
      "Accuracy: 0.814300000667572\n",
      "Accuracy: 0.8596000075340271\n",
      "Accuracy: 0.8413500189781189\n",
      "Accuracy: 0.8500499725341797\n",
      "Accuracy: 0.8073499798774719\n",
      "Accuracy: 0.8816999793052673\n",
      "Accuracy: 0.7900000214576721\n",
      "Accuracy: 0.8039500117301941\n",
      "Accuracy: 0.791949987411499\n",
      "Accuracy: 0.8808000087738037\n",
      "Accuracy: 0.8609499931335449\n",
      "Accuracy: 0.8055999875068665\n",
      "Accuracy: 0.8166499733924866\n",
      "Accuracy: 0.8669000267982483\n",
      "Accuracy: 0.6890000104904175\n",
      "Accuracy: 0.6330500245094299\n",
      "Accuracy: 0.7470999956130981\n",
      "Accuracy: 0.8197000026702881\n",
      "Accuracy: 0.7293499708175659\n",
      "Accuracy: 0.8138499855995178\n",
      "Accuracy: 0.8302000164985657\n",
      "Accuracy: 0.8683500289916992\n",
      "Accuracy: 0.7466999888420105\n",
      "Accuracy: 0.8438500165939331\n",
      "Accuracy: 0.8596000075340271\n",
      "Accuracy: 0.859000027179718\n",
      "Accuracy: 0.8066999912261963\n",
      "Accuracy: 0.7979999780654907\n",
      "Accuracy: 0.6909999847412109\n",
      "Accuracy: 0.8247500061988831\n",
      "Accuracy: 0.8186500072479248\n",
      "Accuracy: 0.8881499767303467\n",
      "Accuracy: 0.8154500126838684\n",
      "Accuracy: 0.8849999904632568\n",
      "Accuracy: 0.8615999817848206\n",
      "Accuracy: 0.7767500281333923\n",
      "Accuracy: 0.8442000150680542\n",
      "Accuracy: 0.8166999816894531\n",
      "Accuracy: 0.852400004863739\n",
      "Accuracy: 0.7835500240325928\n",
      "Accuracy: 0.7815499901771545\n",
      "Accuracy: 0.8555999994277954\n",
      "Accuracy: 0.7896000146865845\n",
      "Accuracy: 0.7548499703407288\n",
      "Accuracy: 0.7928000092506409\n",
      "Accuracy: 0.852150022983551\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 6390.6107\n",
      "Function value obtained: -13.5227\n",
      "Current minimum: -13.5408\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "Accuracy: 0.8191499710083008\n",
      "Accuracy: 0.7768999934196472\n",
      "Accuracy: 0.7087000012397766\n",
      "Accuracy: 0.869700014591217\n",
      "Accuracy: 0.8234500288963318\n",
      "Accuracy: 0.8748000264167786\n",
      "Accuracy: 0.8753499984741211\n",
      "Accuracy: 0.8379499912261963\n",
      "Accuracy: 0.8077499866485596\n",
      "Accuracy: 0.8362500071525574\n",
      "Accuracy: 0.7920500040054321\n",
      "Accuracy: 0.7280499935150146\n",
      "Accuracy: 0.8644499778747559\n",
      "Accuracy: 0.7388499975204468\n",
      "Accuracy: 0.8537999987602234\n",
      "Accuracy: 0.8593999743461609\n",
      "Accuracy: 0.857450008392334\n",
      "Accuracy: 0.725600004196167\n",
      "Accuracy: 0.7970499992370605\n",
      "Accuracy: 0.7702999711036682\n",
      "Accuracy: 0.7804999947547913\n",
      "Accuracy: 0.7463499903678894\n",
      "Accuracy: 0.8594499826431274\n",
      "Accuracy: 0.8721500039100647\n",
      "Accuracy: 0.706250011920929\n",
      "Accuracy: 0.7727500200271606\n",
      "Accuracy: 0.6637499928474426\n",
      "Accuracy: 0.8748000264167786\n",
      "Accuracy: 0.765500009059906\n",
      "Accuracy: 0.8578500151634216\n",
      "Accuracy: 0.7745500206947327\n",
      "Accuracy: 0.8084999918937683\n",
      "Accuracy: 0.7912499904632568\n",
      "Accuracy: 0.7128499746322632\n",
      "Accuracy: 0.8288999795913696\n",
      "Accuracy: 0.7469000220298767\n",
      "Accuracy: 0.8110499978065491\n",
      "Accuracy: 0.8547499775886536\n",
      "Accuracy: 0.6882500052452087\n",
      "Accuracy: 0.8453999757766724\n",
      "Accuracy: 0.8940500020980835\n",
      "Accuracy: 0.8686500191688538\n",
      "Accuracy: 0.8456000089645386\n",
      "Accuracy: 0.9096999764442444\n",
      "Accuracy: 0.775950014591217\n",
      "Accuracy: 0.8220999836921692\n",
      "Accuracy: 0.8853499889373779\n",
      "Accuracy: 0.8373500108718872\n",
      "Accuracy: 0.7343000173568726\n",
      "Accuracy: 0.8059499859809875\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 6390.1559\n",
      "Function value obtained: -13.4526\n",
      "Current minimum: -13.5408\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "Accuracy: 0.839900016784668\n",
      "Accuracy: 0.854200005531311\n",
      "Accuracy: 0.8155500292778015\n",
      "Accuracy: 0.7167500257492065\n",
      "Accuracy: 0.8235499858856201\n",
      "Accuracy: 0.7739499807357788\n",
      "Accuracy: 0.7236999869346619\n",
      "Accuracy: 0.6809999942779541\n",
      "Accuracy: 0.8273500204086304\n",
      "Accuracy: 0.7552499771118164\n",
      "Accuracy: 0.6597499847412109\n",
      "Accuracy: 0.9093999862670898\n",
      "Accuracy: 0.8810999989509583\n",
      "Accuracy: 0.8271499872207642\n",
      "Accuracy: 0.8627499938011169\n",
      "Accuracy: 0.899649977684021\n",
      "Accuracy: 0.7704499959945679\n",
      "Accuracy: 0.7318999767303467\n",
      "Accuracy: 0.7688999772071838\n",
      "Accuracy: 0.7277500033378601\n",
      "Accuracy: 0.7699999809265137\n",
      "Accuracy: 0.8536499738693237\n",
      "Accuracy: 0.8315500020980835\n",
      "Accuracy: 0.8704500198364258\n",
      "Accuracy: 0.7828999757766724\n",
      "Accuracy: 0.6947500109672546\n",
      "Accuracy: 0.8476499915122986\n",
      "Accuracy: 0.854449987411499\n",
      "Accuracy: 0.6934999823570251\n",
      "Accuracy: 0.8853999972343445\n",
      "Accuracy: 0.8843500018119812\n",
      "Accuracy: 0.7985000014305115\n",
      "Accuracy: 0.8019499778747559\n",
      "Accuracy: 0.6754000186920166\n",
      "Accuracy: 0.8474000096321106\n",
      "Accuracy: 0.8834499716758728\n",
      "Accuracy: 0.7856000065803528\n",
      "Accuracy: 0.8067499995231628\n",
      "Accuracy: 0.8852999806404114\n",
      "Accuracy: 0.7164499759674072\n",
      "Accuracy: 0.7791500091552734\n",
      "Accuracy: 0.8226000070571899\n",
      "Accuracy: 0.7717499732971191\n",
      "Accuracy: 0.6952999830245972\n",
      "Accuracy: 0.8598999977111816\n",
      "Accuracy: 0.8483999967575073\n",
      "Accuracy: 0.7792999744415283\n",
      "Accuracy: 0.8135499954223633\n",
      "Accuracy: 0.8953499794006348\n",
      "Accuracy: 0.8171499967575073\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 6392.3224\n",
      "Function value obtained: -13.3673\n",
      "Current minimum: -13.5408\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Accuracy: 0.8321499824523926\n",
      "Accuracy: 0.8112499713897705\n",
      "Accuracy: 0.834850013256073\n",
      "Accuracy: 0.875249981880188\n",
      "Accuracy: 0.7290499806404114\n",
      "Accuracy: 0.859499990940094\n",
      "Accuracy: 0.7606499791145325\n",
      "Accuracy: 0.6993499994277954\n",
      "Accuracy: 0.8646500110626221\n",
      "Accuracy: 0.8683000206947327\n",
      "Accuracy: 0.7961500287055969\n",
      "Accuracy: 0.7512000203132629\n",
      "Accuracy: 0.8235999941825867\n",
      "Accuracy: 0.776199996471405\n",
      "Accuracy: 0.8259999752044678\n",
      "Accuracy: 0.8662499785423279\n",
      "Accuracy: 0.8080999851226807\n",
      "Accuracy: 0.8466500043869019\n",
      "Accuracy: 0.8130999803543091\n",
      "Accuracy: 0.8535000085830688\n",
      "Accuracy: 0.8750500082969666\n",
      "Accuracy: 0.8372499942779541\n",
      "Accuracy: 0.697950005531311\n",
      "Accuracy: 0.8425999879837036\n",
      "Accuracy: 0.8535000085830688\n",
      "Accuracy: 0.8108999729156494\n",
      "Accuracy: 0.824150025844574\n",
      "Accuracy: 0.7228000164031982\n",
      "Accuracy: 0.8834999799728394\n",
      "Accuracy: 0.7623000144958496\n",
      "Accuracy: 0.8180500268936157\n",
      "Accuracy: 0.6959999799728394\n",
      "Accuracy: 0.8173999786376953\n",
      "Accuracy: 0.6516000032424927\n",
      "Accuracy: 0.6945000290870667\n",
      "Accuracy: 0.8694499731063843\n",
      "Accuracy: 0.8466500043869019\n",
      "Accuracy: 0.8180999755859375\n",
      "Accuracy: 0.7233999967575073\n",
      "Accuracy: 0.8139500021934509\n",
      "Accuracy: 0.7584999799728394\n",
      "Accuracy: 0.8708999752998352\n",
      "Accuracy: 0.5856000185012817\n",
      "Accuracy: 0.8787999749183655\n",
      "Accuracy: 0.8483999967575073\n",
      "Accuracy: 0.8088499903678894\n",
      "Accuracy: 0.8128499984741211\n",
      "Accuracy: 0.8239499926567078\n",
      "Accuracy: 0.8868499994277954\n",
      "Accuracy: 0.729449987411499\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 6392.0287\n",
      "Function value obtained: -13.3863\n",
      "Current minimum: -13.5408\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Accuracy: 0.7785000205039978\n",
      "Accuracy: 0.7121999859809875\n",
      "Accuracy: 0.804099977016449\n",
      "Accuracy: 0.86080002784729\n",
      "Accuracy: 0.8591499924659729\n",
      "Accuracy: 0.6973999738693237\n",
      "Accuracy: 0.7557500004768372\n",
      "Accuracy: 0.8674499988555908\n",
      "Accuracy: 0.7839000225067139\n",
      "Accuracy: 0.8620499968528748\n",
      "Accuracy: 0.8406500220298767\n",
      "Accuracy: 0.8212500214576721\n",
      "Accuracy: 0.8183000087738037\n",
      "Accuracy: 0.8567000031471252\n",
      "Accuracy: 0.7685499787330627\n",
      "Accuracy: 0.8169000148773193\n",
      "Accuracy: 0.8205500245094299\n",
      "Accuracy: 0.8105499744415283\n",
      "Accuracy: 0.8088499903678894\n",
      "Accuracy: 0.8405500054359436\n",
      "Accuracy: 0.7990999817848206\n",
      "Accuracy: 0.8439499735832214\n",
      "Accuracy: 0.832099974155426\n",
      "Accuracy: 0.7892000079154968\n",
      "Accuracy: 0.8863000273704529\n",
      "Accuracy: 0.6714000105857849\n",
      "Accuracy: 0.7256500124931335\n",
      "Accuracy: 0.7889999747276306\n",
      "Accuracy: 0.7857499718666077\n",
      "Accuracy: 0.8186500072479248\n",
      "Accuracy: 0.7753000259399414\n",
      "Accuracy: 0.7241500020027161\n",
      "Accuracy: 0.8105499744415283\n",
      "Accuracy: 0.8255500197410583\n",
      "Accuracy: 0.8928999900817871\n",
      "Accuracy: 0.8338500261306763\n",
      "Accuracy: 0.7477499842643738\n",
      "Accuracy: 0.8385000228881836\n",
      "Accuracy: 0.798550009727478\n",
      "Accuracy: 0.8212500214576721\n",
      "Accuracy: 0.6251000165939331\n",
      "Accuracy: 0.8252000212669373\n",
      "Accuracy: 0.7037500143051147\n",
      "Accuracy: 0.893750011920929\n",
      "Accuracy: 0.7684999704360962\n",
      "Accuracy: 0.8810999989509583\n",
      "Accuracy: 0.669950008392334\n",
      "Accuracy: 0.8058500289916992\n",
      "Accuracy: 0.7724000215530396\n",
      "Accuracy: 0.8359000086784363\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 6391.7395\n",
      "Function value obtained: -13.3250\n",
      "Current minimum: -13.5408\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Accuracy: 0.8787000179290771\n",
      "Accuracy: 0.7363499999046326\n",
      "Accuracy: 0.8391000032424927\n",
      "Accuracy: 0.8995000123977661\n",
      "Accuracy: 0.8623999953269958\n",
      "Accuracy: 0.7562000155448914\n",
      "Accuracy: 0.7127500176429749\n",
      "Accuracy: 0.7155500054359436\n",
      "Accuracy: 0.8012999892234802\n",
      "Accuracy: 0.7578999996185303\n",
      "Accuracy: 0.7853000164031982\n",
      "Accuracy: 0.8456500172615051\n",
      "Accuracy: 0.6930500268936157\n",
      "Accuracy: 0.7663499712944031\n",
      "Accuracy: 0.8508999943733215\n",
      "Accuracy: 0.8637499809265137\n",
      "Accuracy: 0.7982000112533569\n",
      "Accuracy: 0.89205002784729\n",
      "Accuracy: 0.8772500157356262\n",
      "Accuracy: 0.7963500022888184\n",
      "Accuracy: 0.874750018119812\n",
      "Accuracy: 0.8262500166893005\n",
      "Accuracy: 0.7943999767303467\n",
      "Accuracy: 0.7638999819755554\n",
      "Accuracy: 0.6330500245094299\n",
      "Accuracy: 0.8879500031471252\n",
      "Accuracy: 0.7476999759674072\n",
      "Accuracy: 0.6798499822616577\n",
      "Accuracy: 0.7695500254631042\n",
      "Accuracy: 0.8018500208854675\n",
      "Accuracy: 0.8356000185012817\n",
      "Accuracy: 0.8809000253677368\n",
      "Accuracy: 0.5878499746322632\n",
      "Accuracy: 0.756850004196167\n",
      "Accuracy: 0.8488500118255615\n",
      "Accuracy: 0.8758500218391418\n",
      "Accuracy: 0.8226500153541565\n",
      "Accuracy: 0.8442000150680542\n",
      "Accuracy: 0.8582000136375427\n",
      "Accuracy: 0.7993000149726868\n",
      "Accuracy: 0.8186500072479248\n",
      "Accuracy: 0.829200029373169\n",
      "Accuracy: 0.6889500021934509\n",
      "Accuracy: 0.8705499768257141\n",
      "Accuracy: 0.7664999961853027\n",
      "Accuracy: 0.7384999990463257\n",
      "Accuracy: 0.7243000268936157\n",
      "Accuracy: 0.7082499861717224\n",
      "Accuracy: 0.8223000168800354\n",
      "Accuracy: 0.7156000137329102\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 6391.5189\n",
      "Function value obtained: -13.2336\n",
      "Current minimum: -13.5408\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Accuracy: 0.8691499829292297\n",
      "Accuracy: 0.7253000140190125\n",
      "Accuracy: 0.8314499855041504\n",
      "Accuracy: 0.857450008392334\n",
      "Accuracy: 0.8280500173568726\n",
      "Accuracy: 0.8626499772071838\n",
      "Accuracy: 0.791949987411499\n",
      "Accuracy: 0.8792499899864197\n",
      "Accuracy: 0.7685499787330627\n",
      "Accuracy: 0.8825500011444092\n",
      "Accuracy: 0.8094000220298767\n",
      "Accuracy: 0.8324499726295471\n",
      "Accuracy: 0.8001499772071838\n",
      "Accuracy: 0.7694500088691711\n",
      "Accuracy: 0.7905499935150146\n",
      "Accuracy: 0.7996500134468079\n",
      "Accuracy: 0.871999979019165\n",
      "Accuracy: 0.7998999953269958\n",
      "Accuracy: 0.7620499730110168\n",
      "Accuracy: 0.8725500106811523\n",
      "Accuracy: 0.8428999781608582\n",
      "Accuracy: 0.8451499938964844\n",
      "Accuracy: 0.8362500071525574\n",
      "Accuracy: 0.7200000286102295\n",
      "Accuracy: 0.8988999724388123\n",
      "Accuracy: 0.7289000153541565\n",
      "Accuracy: 0.7856500148773193\n",
      "Accuracy: 0.7870000004768372\n",
      "Accuracy: 0.7864500284194946\n",
      "Accuracy: 0.8745999932289124\n",
      "Accuracy: 0.6919000148773193\n",
      "Accuracy: 0.7934499979019165\n",
      "Accuracy: 0.777899980545044\n",
      "Accuracy: 0.7837499976158142\n",
      "Accuracy: 0.7986500263214111\n",
      "Accuracy: 0.7964500188827515\n",
      "Accuracy: 0.6983000040054321\n",
      "Accuracy: 0.8769000172615051\n",
      "Accuracy: 0.730650007724762\n",
      "Accuracy: 0.8108999729156494\n",
      "Accuracy: 0.6261000037193298\n",
      "Accuracy: 0.692300021648407\n",
      "Accuracy: 0.8963500261306763\n",
      "Accuracy: 0.857200026512146\n",
      "Accuracy: 0.7414000034332275\n",
      "Accuracy: 0.756600022315979\n",
      "Accuracy: 0.7158499956130981\n",
      "Accuracy: 0.6586999893188477\n",
      "Accuracy: 0.7518500089645386\n",
      "Accuracy: 0.699999988079071\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 6329.0236\n",
      "Function value obtained: -13.2218\n",
      "Current minimum: -13.5408\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Accuracy: 0.7601000070571899\n",
      "Accuracy: 0.7570000290870667\n",
      "Accuracy: 0.7674999833106995\n",
      "Accuracy: 0.8286499977111816\n",
      "Accuracy: 0.8065000176429749\n",
      "Accuracy: 0.8720499873161316\n",
      "Accuracy: 0.8975499868392944\n",
      "Accuracy: 0.7597000002861023\n",
      "Accuracy: 0.8453500270843506\n",
      "Accuracy: 0.8180500268936157\n",
      "Accuracy: 0.6984500288963318\n",
      "Accuracy: 0.8565000295639038\n",
      "Accuracy: 0.6262999773025513\n",
      "Accuracy: 0.6705499887466431\n",
      "Accuracy: 0.8403499722480774\n",
      "Accuracy: 0.7700999975204468\n",
      "Accuracy: 0.7008500099182129\n",
      "Accuracy: 0.8274000287055969\n",
      "Accuracy: 0.8336499929428101\n",
      "Accuracy: 0.7631499767303467\n",
      "Accuracy: 0.7317000031471252\n",
      "Accuracy: 0.8809999823570251\n",
      "Accuracy: 0.7330499887466431\n",
      "Accuracy: 0.8418999910354614\n",
      "Accuracy: 0.8076000213623047\n",
      "Accuracy: 0.817300021648407\n",
      "Accuracy: 0.8043500185012817\n",
      "Accuracy: 0.8371000289916992\n",
      "Accuracy: 0.7013499736785889\n",
      "Accuracy: 0.694599986076355\n",
      "Accuracy: 0.7919999957084656\n",
      "Accuracy: 0.8156999945640564\n",
      "Accuracy: 0.821399986743927\n",
      "Accuracy: 0.824400007724762\n",
      "Accuracy: 0.8799499869346619\n",
      "Accuracy: 0.7577499747276306\n",
      "Accuracy: 0.7626000046730042\n",
      "Accuracy: 0.8066499829292297\n",
      "Accuracy: 0.8148499727249146\n",
      "Accuracy: 0.6942499876022339\n",
      "Accuracy: 0.7296000123023987\n",
      "Accuracy: 0.8308500051498413\n",
      "Accuracy: 0.8601999878883362\n",
      "Accuracy: 0.7153000235557556\n",
      "Accuracy: 0.8954499959945679\n",
      "Accuracy: 0.7545499801635742\n",
      "Accuracy: 0.8435999751091003\n",
      "Accuracy: 0.7602999806404114\n",
      "Accuracy: 0.8299999833106995\n",
      "Accuracy: 0.85794997215271\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 6350.4667\n",
      "Function value obtained: -13.1990\n",
      "Current minimum: -13.5408\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Accuracy: 0.7897499799728394\n",
      "Accuracy: 0.7363499999046326\n",
      "Accuracy: 0.7585499882698059\n",
      "Accuracy: 0.8620499968528748\n",
      "Accuracy: 0.7666500210762024\n",
      "Accuracy: 0.8022500276565552\n",
      "Accuracy: 0.7164000272750854\n",
      "Accuracy: 0.8998500108718872\n",
      "Accuracy: 0.8491500020027161\n",
      "Accuracy: 0.8269000053405762\n",
      "Accuracy: 0.7958999872207642\n",
      "Accuracy: 0.8016999959945679\n",
      "Accuracy: 0.7096499800682068\n",
      "Accuracy: 0.7964500188827515\n",
      "Accuracy: 0.8093000054359436\n",
      "Accuracy: 0.9135000109672546\n",
      "Accuracy: 0.8073499798774719\n",
      "Accuracy: 0.71670001745224\n",
      "Accuracy: 0.8863499760627747\n",
      "Accuracy: 0.8023999929428101\n",
      "Accuracy: 0.7900500297546387\n",
      "Accuracy: 0.8906999826431274\n",
      "Accuracy: 0.847000002861023\n",
      "Accuracy: 0.8040000200271606\n",
      "Accuracy: 0.7421000003814697\n",
      "Accuracy: 0.7885000109672546\n",
      "Accuracy: 0.854449987411499\n",
      "Accuracy: 0.8285499811172485\n",
      "Accuracy: 0.7850000262260437\n",
      "Accuracy: 0.8855500221252441\n",
      "Accuracy: 0.8614500164985657\n",
      "Accuracy: 0.8497499823570251\n",
      "Accuracy: 0.5559999942779541\n",
      "Accuracy: 0.8585500121116638\n",
      "Accuracy: 0.8195000290870667\n",
      "Accuracy: 0.8844000101089478\n",
      "Accuracy: 0.9114000201225281\n",
      "Accuracy: 0.8542500138282776\n",
      "Accuracy: 0.6783999800682068\n",
      "Accuracy: 0.7943500280380249\n",
      "Accuracy: 0.8863499760627747\n",
      "Accuracy: 0.8755499720573425\n",
      "Accuracy: 0.8944500088691711\n",
      "Accuracy: 0.8381999731063843\n",
      "Accuracy: 0.5978999733924866\n",
      "Accuracy: 0.8359000086784363\n",
      "Accuracy: 0.8076000213623047\n",
      "Accuracy: 0.8198500275611877\n",
      "Accuracy: 0.6888499855995178\n",
      "Accuracy: 0.8354499936103821\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 6289.3419\n",
      "Function value obtained: -13.4704\n",
      "Current minimum: -13.5408\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Accuracy: 0.8131999969482422\n",
      "Accuracy: 0.8730999827384949\n",
      "Accuracy: 0.817300021648407\n",
      "Accuracy: 0.8824999928474426\n",
      "Accuracy: 0.8143500089645386\n",
      "Accuracy: 0.8723999857902527\n",
      "Accuracy: 0.8534500002861023\n",
      "Accuracy: 0.7627000212669373\n",
      "Accuracy: 0.8519999980926514\n",
      "Accuracy: 0.8797500133514404\n",
      "Accuracy: 0.8733999729156494\n",
      "Accuracy: 0.7845500111579895\n",
      "Accuracy: 0.8273000121116638\n",
      "Accuracy: 0.7656000256538391\n",
      "Accuracy: 0.8115000128746033\n",
      "Accuracy: 0.8625500202178955\n",
      "Accuracy: 0.7559499740600586\n",
      "Accuracy: 0.753849983215332\n",
      "Accuracy: 0.6986500024795532\n",
      "Accuracy: 0.7965999841690063\n",
      "Accuracy: 0.7593500018119812\n",
      "Accuracy: 0.7488999962806702\n",
      "Accuracy: 0.8528000116348267\n",
      "Accuracy: 0.8206499814987183\n",
      "Accuracy: 0.7827500104904175\n",
      "Accuracy: 0.8044499754905701\n",
      "Accuracy: 0.7509499788284302\n",
      "Accuracy: 0.8856499791145325\n",
      "Accuracy: 0.7986000180244446\n",
      "Accuracy: 0.900950014591217\n",
      "Accuracy: 0.8220999836921692\n",
      "Accuracy: 0.6608999967575073\n",
      "Accuracy: 0.8924000263214111\n",
      "Accuracy: 0.8217499852180481\n",
      "Accuracy: 0.7049000263214111\n",
      "Accuracy: 0.7501999735832214\n",
      "Accuracy: 0.8497999906539917\n",
      "Accuracy: 0.7823500037193298\n",
      "Accuracy: 0.8363999724388123\n",
      "Accuracy: 0.6270999908447266\n",
      "Accuracy: 0.8976500034332275\n",
      "Accuracy: 0.8072999715805054\n",
      "Accuracy: 0.7890499830245972\n",
      "Accuracy: 0.8968499898910522\n",
      "Accuracy: 0.8104000091552734\n",
      "Accuracy: 0.8501999974250793\n",
      "Accuracy: 0.7941499948501587\n",
      "Accuracy: 0.8008999824523926\n",
      "Accuracy: 0.829200029373169\n",
      "Accuracy: 0.8272500038146973\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 6306.4416\n",
      "Function value obtained: -13.5022\n",
      "Current minimum: -13.5408\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Accuracy: 0.8307499885559082\n",
      "Accuracy: 0.8446999788284302\n",
      "Accuracy: 0.8442000150680542\n",
      "Accuracy: 0.8449000120162964\n",
      "Accuracy: 0.8741499781608582\n",
      "Accuracy: 0.8654999732971191\n",
      "Accuracy: 0.8224999904632568\n",
      "Accuracy: 0.7066500186920166\n",
      "Accuracy: 0.6829000115394592\n",
      "Accuracy: 0.8320500254631042\n",
      "Accuracy: 0.8364499807357788\n",
      "Accuracy: 0.8183000087738037\n",
      "Accuracy: 0.7248499989509583\n",
      "Accuracy: 0.765500009059906\n",
      "Accuracy: 0.7880499958992004\n",
      "Accuracy: 0.880649983882904\n",
      "Accuracy: 0.8920999765396118\n",
      "Accuracy: 0.8291000127792358\n",
      "Accuracy: 0.7897999882698059\n",
      "Accuracy: 0.8172500133514404\n",
      "Accuracy: 0.8837500214576721\n",
      "Accuracy: 0.7503499984741211\n",
      "Accuracy: 0.7228999733924866\n",
      "Accuracy: 0.699150025844574\n",
      "Accuracy: 0.89205002784729\n",
      "Accuracy: 0.7269499897956848\n",
      "Accuracy: 0.7609999775886536\n",
      "Accuracy: 0.709850013256073\n",
      "Accuracy: 0.8471999764442444\n",
      "Accuracy: 0.7749999761581421\n",
      "Accuracy: 0.6499500274658203\n",
      "Accuracy: 0.61285001039505\n",
      "Accuracy: 0.6714500188827515\n",
      "Accuracy: 0.7712500095367432\n",
      "Accuracy: 0.8044999837875366\n",
      "Accuracy: 0.7433500289916992\n",
      "Accuracy: 0.7861999869346619\n",
      "Accuracy: 0.798550009727478\n",
      "Accuracy: 0.7575500011444092\n",
      "Accuracy: 0.8332499861717224\n",
      "Accuracy: 0.7968000173568726\n",
      "Accuracy: 0.7578499913215637\n",
      "Accuracy: 0.9197499752044678\n",
      "Accuracy: 0.7871000170707703\n",
      "Accuracy: 0.8615999817848206\n",
      "Accuracy: 0.828249990940094\n",
      "Accuracy: 0.8769500255584717\n",
      "Accuracy: 0.8831999897956848\n",
      "Accuracy: 0.6567000150680542\n",
      "Accuracy: 0.8119000196456909\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 6401.3226\n",
      "Function value obtained: -13.2225\n",
      "Current minimum: -13.5408\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Accuracy: 0.75\n",
      "Accuracy: 0.8500000238418579\n",
      "Accuracy: 0.7915499806404114\n",
      "Accuracy: 0.826200008392334\n",
      "Accuracy: 0.6568999886512756\n",
      "Accuracy: 0.7190499901771545\n",
      "Accuracy: 0.8486499786376953\n",
      "Accuracy: 0.7447500228881836\n",
      "Accuracy: 0.8172000050544739\n",
      "Accuracy: 0.8528500199317932\n",
      "Accuracy: 0.8207499980926514\n",
      "Accuracy: 0.8741499781608582\n",
      "Accuracy: 0.8680499792098999\n",
      "Accuracy: 0.8672999739646912\n",
      "Accuracy: 0.8622000217437744\n",
      "Accuracy: 0.7369499802589417\n",
      "Accuracy: 0.7771499752998352\n",
      "Accuracy: 0.8454499840736389\n",
      "Accuracy: 0.7903000116348267\n",
      "Accuracy: 0.839900016784668\n",
      "Accuracy: 0.8474500179290771\n",
      "Accuracy: 0.6814500093460083\n",
      "Accuracy: 0.8375999927520752\n",
      "Accuracy: 0.7233499884605408\n",
      "Accuracy: 0.7684999704360962\n",
      "Accuracy: 0.8607500195503235\n",
      "Accuracy: 0.8063499927520752\n",
      "Accuracy: 0.8083500266075134\n",
      "Accuracy: 0.8306999802589417\n",
      "Accuracy: 0.8084999918937683\n",
      "Accuracy: 0.7833499908447266\n",
      "Accuracy: 0.7808499932289124\n",
      "Accuracy: 0.760699987411499\n",
      "Accuracy: 0.8033499717712402\n",
      "Accuracy: 0.6965500116348267\n",
      "Accuracy: 0.8472499847412109\n",
      "Accuracy: 0.8278999924659729\n",
      "Accuracy: 0.8141499757766724\n",
      "Accuracy: 0.7390999794006348\n",
      "Accuracy: 0.8076000213623047\n",
      "Accuracy: 0.89410001039505\n",
      "Accuracy: 0.8002499938011169\n",
      "Accuracy: 0.8015000224113464\n",
      "Accuracy: 0.8482000231742859\n",
      "Accuracy: 0.8758500218391418\n",
      "Accuracy: 0.8464999794960022\n",
      "Accuracy: 0.7638999819755554\n",
      "Accuracy: 0.6738499999046326\n",
      "Accuracy: 0.8184499740600586\n",
      "Accuracy: 0.800000011920929\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 6330.6223\n",
      "Function value obtained: -13.3652\n",
      "Current minimum: -13.5408\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Accuracy: 0.8145999908447266\n",
      "Accuracy: 0.8134999871253967\n",
      "Accuracy: 0.8539000153541565\n",
      "Accuracy: 0.8218500018119812\n",
      "Accuracy: 0.8570500016212463\n",
      "Accuracy: 0.8483499884605408\n",
      "Accuracy: 0.896399974822998\n",
      "Accuracy: 0.823199987411499\n",
      "Accuracy: 0.8761500120162964\n",
      "Accuracy: 0.7206000089645386\n",
      "Accuracy: 0.791450023651123\n",
      "Accuracy: 0.5421000123023987\n",
      "Accuracy: 0.8693000078201294\n",
      "Accuracy: 0.8813999891281128\n",
      "Accuracy: 0.8658499717712402\n",
      "Accuracy: 0.8521000146865845\n",
      "Accuracy: 0.89205002784729\n",
      "Accuracy: 0.7698000073432922\n",
      "Accuracy: 0.8995500206947327\n",
      "Accuracy: 0.7495499849319458\n",
      "Accuracy: 0.8069499731063843\n",
      "Accuracy: 0.7448499798774719\n",
      "Accuracy: 0.7846500277519226\n",
      "Accuracy: 0.8409500122070312\n",
      "Accuracy: 0.8454499840736389\n",
      "Accuracy: 0.7831000089645386\n",
      "Accuracy: 0.8413500189781189\n",
      "Accuracy: 0.7942500114440918\n",
      "Accuracy: 0.6603500247001648\n",
      "Accuracy: 0.8845499753952026\n",
      "Accuracy: 0.8963000178337097\n",
      "Accuracy: 0.7504500150680542\n",
      "Accuracy: 0.6775000095367432\n",
      "Accuracy: 0.8174499869346619\n",
      "Accuracy: 0.7919999957084656\n",
      "Accuracy: 0.7724000215530396\n",
      "Accuracy: 0.7411500215530396\n",
      "Accuracy: 0.822700023651123\n",
      "Accuracy: 0.8191499710083008\n",
      "Accuracy: 0.8431500196456909\n",
      "Accuracy: 0.8277000188827515\n",
      "Accuracy: 0.7254499793052673\n",
      "Accuracy: 0.8648999929428101\n",
      "Accuracy: 0.833299994468689\n",
      "Accuracy: 0.8403000235557556\n",
      "Accuracy: 0.8601999878883362\n",
      "Accuracy: 0.8364499807357788\n",
      "Accuracy: 0.6360999941825867\n",
      "Accuracy: 0.7778000235557556\n",
      "Accuracy: 0.8054999709129333\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 6322.5736\n",
      "Function value obtained: -13.4551\n",
      "Current minimum: -13.5408\n",
      "Best magnitude: 8579.598230609947\n",
      "Best average accuracy: 13.540799995263418\n"
     ]
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "# Define the objective function for Bayesian Optimization\n",
    "def objective_function(magnitude):\n",
    "    accuracy_near_3 = 0\n",
    "    \n",
    "    for i in range(50):\n",
    "        net_3 = Net()\n",
    "        dataset_uniform_train_modified = SystemDatasetModified(\"dataset_arbi2d_1000.csv\", 0)\n",
    "        dataset_near_train_modified = SystemDatasetModified(\"dataset_arbi2d_enhanced_400.csv\", 1)\n",
    "        dataset_merged_train_modified = torch.utils.data.ConcatDataset([dataset_uniform_train_modified, dataset_near_train_modified])\n",
    "        net_3 = train_model_custom(net_3, dataset_merged_train_modified, 32, 1000, 0.001, magnitude)\n",
    "        \n",
    "        accuracy_near_3 += test_model_modified(net_3, dataset_near_test_modified).item()\n",
    "    \n",
    "    # Calculate average accuracy\n",
    "    average_accuracy_near_3 = accuracy_near_3 / 3\n",
    "    \n",
    "    # Return negative accuracy because gp_minimize seeks to minimize the function\n",
    "    return -average_accuracy_near_3\n",
    "\n",
    "# Define the range for 'magnitude'\n",
    "space = [Real(1, 10000, name='magnitude')]\n",
    "\n",
    "# Use named args for convenience\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    # Pass the entire params dictionary to the objective_function\n",
    "    return objective_function(**params)\n",
    "\n",
    "# Run Bayesian Optimization\n",
    "result = gp_minimize(objective, space, n_calls=20, n_jobs=-1, random_state=0, verbose=True)\n",
    "\n",
    "# Output the best result\n",
    "print(f\"Best magnitude: {result.x[0]}\")\n",
    "print(f\"Best average accuracy: {-result.fun}\")\n",
    "best_magnitude = result.x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m dataset_near_train_modified \u001b[38;5;241m=\u001b[39m SystemDatasetModified(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_arbi2d_enhanced_400.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m dataset_merged_train_modified \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mConcatDataset([dataset_uniform_train_modified, dataset_near_train_modified])\n\u001b[0;32m---> 11\u001b[0m net_3 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_custom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_merged_train_modified\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_magnitude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m accuracy_uniform_3 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m test_model_modified(net_3, dataset_uniform_test_modified)\n\u001b[1;32m     14\u001b[0m accuracy_near_3 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m test_model_modified(net_3, dataset_near_test_modified)\n",
      "Cell \u001b[0;32mIn[71], line 34\u001b[0m, in \u001b[0;36mtrain_model_custom\u001b[0;34m(net, dataset_train, batchsize, epochs, lr, magnitude)\u001b[0m\n\u001b[1;32m     32\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     33\u001b[0m mini_batch_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m features, labels, indicators \u001b[38;5;129;01min\u001b[39;00m dataloader_train: \n\u001b[1;32m     35\u001b[0m     labels \u001b[38;5;241m=\u001b[39m ((labels \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     36\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/Estimate-Basin-Boundary/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Documents/GitHub/Estimate-Basin-Boundary/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Documents/GitHub/Estimate-Basin-Boundary/myenv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/GitHub/Estimate-Basin-Boundary/myenv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/GitHub/Estimate-Basin-Boundary/myenv/lib/python3.10/site-packages/torch/utils/data/dataset.py:350\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     sample_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_sizes[dataset_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[64], line 12\u001b[0m, in \u001b[0;36mSystemDatasetModified.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 12\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     indicator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m3\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, y, indicator\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy_uniform_3 = 0\n",
    "accuracy_near_3 = 0\n",
    "\n",
    "for i in range(50):\n",
    "    print(f'Iteration {i + 1}')\n",
    "\n",
    "    net_3 = Net()\n",
    "    dataset_uniform_train_modified = SystemDatasetModified(\"dataset_arbi2d_1000.csv\", 0)\n",
    "    dataset_near_train_modified = SystemDatasetModified(\"dataset_arbi2d_enhanced_400.csv\", 1)\n",
    "    dataset_merged_train_modified = torch.utils.data.ConcatDataset([dataset_uniform_train_modified, dataset_near_train_modified])\n",
    "    net_3 = train_model_custom(net_3, dataset_merged_train_modified, 32, 1000, 0.001, best_magnitude)\n",
    "\n",
    "    accuracy_uniform_3 += test_model_modified(net_3, dataset_uniform_test_modified)\n",
    "    accuracy_near_3 += test_model_modified(net_3, dataset_near_test_modified)\n",
    "\n",
    "print(f'Average accuracy for uniform test set with model 3: {accuracy_uniform_3 / 50}')\n",
    "print(f'Average accuracy for near test set with model 3: {accuracy_near_3 / 50}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_close_points(instance, indicators, n=1, distance=0.0005):\n",
    "    close_points = []\n",
    "    for point, indicator in zip(instance, indicators):\n",
    "        for _ in range(n):\n",
    "            new_point = (point[0]+np.random.uniform(-distance, distance), point[1]+np.random.uniform(-distance, distance))\n",
    "            attracted = simulation(new_point[0], new_point[1])\n",
    "            close_points.append((new_point[0], new_point[1], attracted, indicator))\n",
    "    df = pd.DataFrame(close_points, columns=['x0', 'y0', 'attracted', 'indicator'])\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_uniform_train_modified = SystemDatasetModified(\"dataset_arbi2d_1000.csv\", 0)\n",
    "dataset_near_train_modified = SystemDatasetModified(\"dataset_arbi2d_enhanced_400.csv\", 1)\n",
    "dataset_merged_train_modified = torch.utils.data.ConcatDataset([dataset_uniform_train_modified, dataset_near_train_modified])\n",
    "\n",
    "def train_model_custom_augmented(net, dataset_uniform_train, dataset_near_train, batchsize, epochs, lr, magnitude, generate_close_points):\n",
    "    criterion = CustomLoss(magnitude)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        dataset_train = torch.utils.data.ConcatDataset([dataset_uniform_train, dataset_near_train])\n",
    "        dataloader_train = DataLoader(dataset_train, batch_size=batchsize, shuffle=True)\n",
    "        running_loss = 0.0\n",
    "        mini_batch_count = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        misclassified_features_lst = []\n",
    "        misclassified_indicators_lst = []\n",
    "        \n",
    "        for features, labels, indicators in dataloader_train: \n",
    "            labels = ((labels + 1) / 2).float()\n",
    "            labels = labels.view(-1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(features).view(-1)\n",
    "            loss = criterion(outputs, labels, features, system(0, features.T), indicators)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            mini_batch_count += 1\n",
    "            \n",
    "            # Identify misclassified instances\n",
    "            with torch.no_grad():\n",
    "                predicted_labels = (outputs > 0.5).float()\n",
    "                misclassified_mask = predicted_labels != labels\n",
    "                misclassified_features = features[misclassified_mask]\n",
    "                misclassified_indicators = indicators[misclassified_mask]\n",
    "                misclassified_features_lst.extend(misclassified_features.numpy())\n",
    "                misclassified_indicators_lst.extend(misclassified_indicators.numpy())\n",
    "                correct_predictions += (predicted_labels == labels).sum().item()\n",
    "                total_predictions += labels.size(0)\n",
    "\n",
    "        \n",
    "        # Generate and add new data points for misclassified instances\n",
    "        if (epoch + 1) % 1000 == 0:\n",
    "            new_data_points = generate_close_points(misclassified_features_lst, misclassified_indicators_lst)\n",
    "            dataset_near_train.append_data(new_data_points)\n",
    "        training_accuracy = correct_predictions / total_predictions\n",
    "        \n",
    "        print(f'Finished training for epoch {epoch + 1}, loss: {running_loss / mini_batch_count:.3f}, accuracy: {training_accuracy:.3f}, training set size: {len(dataset_train)}')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training for epoch 1, loss: 0.657, accuracy: 0.640, training set size: 1800\n",
      "Finished training for epoch 2, loss: 0.533, accuracy: 0.722, training set size: 1800\n",
      "Finished training for epoch 3, loss: 0.448, accuracy: 0.756, training set size: 1800\n",
      "Finished training for epoch 4, loss: 0.402, accuracy: 0.761, training set size: 1800\n",
      "Finished training for epoch 5, loss: 0.385, accuracy: 0.765, training set size: 1800\n",
      "Finished training for epoch 6, loss: 0.371, accuracy: 0.773, training set size: 1800\n",
      "Finished training for epoch 7, loss: 0.372, accuracy: 0.763, training set size: 1800\n",
      "Finished training for epoch 8, loss: 0.359, accuracy: 0.774, training set size: 1800\n",
      "Finished training for epoch 9, loss: 0.353, accuracy: 0.774, training set size: 1800\n",
      "Finished training for epoch 10, loss: 0.351, accuracy: 0.779, training set size: 1800\n",
      "Finished training for epoch 11, loss: 0.345, accuracy: 0.783, training set size: 1800\n",
      "Finished training for epoch 12, loss: 0.346, accuracy: 0.777, training set size: 1800\n",
      "Finished training for epoch 13, loss: 0.341, accuracy: 0.778, training set size: 1800\n",
      "Finished training for epoch 14, loss: 0.338, accuracy: 0.784, training set size: 1800\n",
      "Finished training for epoch 15, loss: 0.337, accuracy: 0.785, training set size: 1800\n",
      "Finished training for epoch 16, loss: 0.340, accuracy: 0.783, training set size: 1800\n",
      "Finished training for epoch 17, loss: 0.336, accuracy: 0.784, training set size: 1800\n",
      "Finished training for epoch 18, loss: 0.332, accuracy: 0.786, training set size: 1800\n",
      "Finished training for epoch 19, loss: 0.337, accuracy: 0.777, training set size: 1800\n",
      "Finished training for epoch 20, loss: 0.334, accuracy: 0.791, training set size: 1800\n",
      "Finished training for epoch 21, loss: 0.334, accuracy: 0.780, training set size: 1800\n",
      "Finished training for epoch 22, loss: 0.327, accuracy: 0.801, training set size: 1800\n",
      "Finished training for epoch 23, loss: 0.337, accuracy: 0.785, training set size: 1800\n",
      "Finished training for epoch 24, loss: 0.327, accuracy: 0.796, training set size: 1800\n",
      "Finished training for epoch 25, loss: 0.332, accuracy: 0.779, training set size: 1800\n",
      "Finished training for epoch 26, loss: 0.328, accuracy: 0.789, training set size: 1800\n",
      "Finished training for epoch 27, loss: 0.328, accuracy: 0.787, training set size: 1800\n",
      "Finished training for epoch 28, loss: 0.324, accuracy: 0.786, training set size: 1800\n",
      "Finished training for epoch 29, loss: 0.329, accuracy: 0.796, training set size: 1800\n",
      "Finished training for epoch 30, loss: 0.326, accuracy: 0.798, training set size: 1800\n",
      "Finished training for epoch 31, loss: 0.321, accuracy: 0.791, training set size: 1800\n",
      "Finished training for epoch 32, loss: 0.338, accuracy: 0.778, training set size: 1800\n",
      "Finished training for epoch 33, loss: 0.337, accuracy: 0.788, training set size: 1800\n",
      "Finished training for epoch 34, loss: 0.320, accuracy: 0.797, training set size: 1800\n",
      "Finished training for epoch 35, loss: 0.324, accuracy: 0.792, training set size: 1800\n",
      "Finished training for epoch 36, loss: 0.319, accuracy: 0.799, training set size: 1800\n",
      "Finished training for epoch 37, loss: 0.330, accuracy: 0.782, training set size: 1800\n",
      "Finished training for epoch 38, loss: 0.320, accuracy: 0.804, training set size: 1800\n",
      "Finished training for epoch 39, loss: 0.325, accuracy: 0.792, training set size: 1800\n",
      "Finished training for epoch 40, loss: 0.328, accuracy: 0.782, training set size: 1800\n",
      "Finished training for epoch 41, loss: 0.324, accuracy: 0.801, training set size: 1800\n",
      "Finished training for epoch 42, loss: 0.317, accuracy: 0.800, training set size: 1800\n",
      "Finished training for epoch 43, loss: 0.318, accuracy: 0.807, training set size: 1800\n",
      "Finished training for epoch 44, loss: 0.322, accuracy: 0.805, training set size: 1800\n",
      "Finished training for epoch 45, loss: 0.313, accuracy: 0.805, training set size: 1800\n",
      "Finished training for epoch 46, loss: 0.322, accuracy: 0.787, training set size: 1800\n",
      "Finished training for epoch 47, loss: 0.320, accuracy: 0.815, training set size: 1800\n",
      "Finished training for epoch 48, loss: 0.323, accuracy: 0.792, training set size: 1800\n",
      "Finished training for epoch 49, loss: 0.315, accuracy: 0.808, training set size: 1800\n",
      "Finished training for epoch 50, loss: 0.316, accuracy: 0.809, training set size: 1800\n",
      "Finished training for epoch 51, loss: 0.320, accuracy: 0.800, training set size: 1800\n",
      "Finished training for epoch 52, loss: 0.330, accuracy: 0.799, training set size: 1800\n",
      "Finished training for epoch 53, loss: 0.320, accuracy: 0.806, training set size: 1800\n",
      "Finished training for epoch 54, loss: 0.318, accuracy: 0.805, training set size: 1800\n",
      "Finished training for epoch 55, loss: 0.316, accuracy: 0.810, training set size: 1800\n",
      "Finished training for epoch 56, loss: 0.324, accuracy: 0.794, training set size: 1800\n",
      "Finished training for epoch 57, loss: 0.313, accuracy: 0.815, training set size: 1800\n",
      "Finished training for epoch 58, loss: 0.315, accuracy: 0.823, training set size: 1800\n",
      "Finished training for epoch 59, loss: 0.313, accuracy: 0.806, training set size: 1800\n",
      "Finished training for epoch 60, loss: 0.315, accuracy: 0.806, training set size: 1800\n",
      "Finished training for epoch 61, loss: 0.316, accuracy: 0.813, training set size: 1800\n",
      "Finished training for epoch 62, loss: 0.315, accuracy: 0.806, training set size: 1800\n",
      "Finished training for epoch 63, loss: 0.313, accuracy: 0.808, training set size: 1800\n",
      "Finished training for epoch 64, loss: 0.318, accuracy: 0.801, training set size: 1800\n",
      "Finished training for epoch 65, loss: 0.321, accuracy: 0.804, training set size: 1800\n",
      "Finished training for epoch 66, loss: 0.315, accuracy: 0.803, training set size: 1800\n",
      "Finished training for epoch 67, loss: 0.319, accuracy: 0.796, training set size: 1800\n",
      "Finished training for epoch 68, loss: 0.315, accuracy: 0.811, training set size: 1800\n",
      "Finished training for epoch 69, loss: 0.312, accuracy: 0.794, training set size: 1800\n",
      "Finished training for epoch 70, loss: 0.320, accuracy: 0.794, training set size: 1800\n",
      "Finished training for epoch 71, loss: 0.311, accuracy: 0.818, training set size: 1800\n",
      "Finished training for epoch 72, loss: 0.316, accuracy: 0.806, training set size: 1800\n",
      "Finished training for epoch 73, loss: 0.317, accuracy: 0.793, training set size: 1800\n",
      "Finished training for epoch 74, loss: 0.313, accuracy: 0.806, training set size: 1800\n",
      "Finished training for epoch 75, loss: 0.322, accuracy: 0.798, training set size: 1800\n",
      "Finished training for epoch 76, loss: 0.306, accuracy: 0.832, training set size: 1800\n",
      "Finished training for epoch 77, loss: 0.308, accuracy: 0.808, training set size: 1800\n",
      "Finished training for epoch 78, loss: 0.333, accuracy: 0.778, training set size: 1800\n",
      "Finished training for epoch 79, loss: 0.309, accuracy: 0.812, training set size: 1800\n",
      "Finished training for epoch 80, loss: 0.308, accuracy: 0.817, training set size: 1800\n",
      "Finished training for epoch 81, loss: 0.314, accuracy: 0.804, training set size: 1800\n",
      "Finished training for epoch 82, loss: 0.312, accuracy: 0.804, training set size: 1800\n",
      "Finished training for epoch 83, loss: 0.313, accuracy: 0.816, training set size: 1800\n",
      "Finished training for epoch 84, loss: 0.318, accuracy: 0.798, training set size: 1800\n",
      "Finished training for epoch 85, loss: 0.312, accuracy: 0.808, training set size: 1800\n",
      "Finished training for epoch 86, loss: 0.310, accuracy: 0.801, training set size: 1800\n",
      "Finished training for epoch 87, loss: 0.311, accuracy: 0.822, training set size: 1800\n",
      "Finished training for epoch 88, loss: 0.316, accuracy: 0.805, training set size: 1800\n",
      "Finished training for epoch 89, loss: 0.314, accuracy: 0.794, training set size: 1800\n",
      "Finished training for epoch 90, loss: 0.307, accuracy: 0.811, training set size: 1800\n",
      "Finished training for epoch 91, loss: 0.318, accuracy: 0.803, training set size: 1800\n",
      "Finished training for epoch 92, loss: 0.312, accuracy: 0.826, training set size: 1800\n",
      "Finished training for epoch 93, loss: 0.311, accuracy: 0.811, training set size: 1800\n",
      "Finished training for epoch 94, loss: 0.308, accuracy: 0.812, training set size: 1800\n",
      "Finished training for epoch 95, loss: 0.313, accuracy: 0.806, training set size: 1800\n",
      "Finished training for epoch 96, loss: 0.312, accuracy: 0.806, training set size: 1800\n",
      "Finished training for epoch 97, loss: 0.310, accuracy: 0.812, training set size: 1800\n",
      "Finished training for epoch 98, loss: 0.313, accuracy: 0.817, training set size: 1800\n",
      "Finished training for epoch 99, loss: 0.313, accuracy: 0.799, training set size: 1800\n",
      "Finished training for epoch 100, loss: 0.309, accuracy: 0.807, training set size: 1800\n",
      "Finished training for epoch 101, loss: 0.302, accuracy: 0.824, training set size: 1800\n",
      "Finished training for epoch 102, loss: 0.313, accuracy: 0.804, training set size: 1800\n",
      "Finished training for epoch 103, loss: 0.307, accuracy: 0.821, training set size: 1800\n",
      "Finished training for epoch 104, loss: 0.305, accuracy: 0.836, training set size: 1800\n",
      "Finished training for epoch 105, loss: 0.305, accuracy: 0.818, training set size: 1800\n",
      "Finished training for epoch 106, loss: 0.322, accuracy: 0.798, training set size: 1800\n",
      "Finished training for epoch 107, loss: 0.316, accuracy: 0.800, training set size: 1800\n",
      "Finished training for epoch 108, loss: 0.308, accuracy: 0.817, training set size: 1800\n",
      "Finished training for epoch 109, loss: 0.313, accuracy: 0.803, training set size: 1800\n",
      "Finished training for epoch 110, loss: 0.322, accuracy: 0.800, training set size: 1800\n",
      "Finished training for epoch 111, loss: 0.315, accuracy: 0.808, training set size: 1800\n",
      "Finished training for epoch 112, loss: 0.304, accuracy: 0.821, training set size: 1800\n",
      "Finished training for epoch 113, loss: 0.304, accuracy: 0.819, training set size: 1800\n",
      "Finished training for epoch 114, loss: 0.305, accuracy: 0.823, training set size: 1800\n",
      "Finished training for epoch 115, loss: 0.304, accuracy: 0.835, training set size: 1800\n",
      "Finished training for epoch 116, loss: 0.308, accuracy: 0.813, training set size: 1800\n",
      "Finished training for epoch 117, loss: 0.317, accuracy: 0.801, training set size: 1800\n",
      "Finished training for epoch 118, loss: 0.309, accuracy: 0.803, training set size: 1800\n",
      "Finished training for epoch 119, loss: 0.300, accuracy: 0.833, training set size: 1800\n",
      "Finished training for epoch 120, loss: 0.318, accuracy: 0.796, training set size: 1800\n",
      "Finished training for epoch 121, loss: 0.301, accuracy: 0.826, training set size: 1800\n",
      "Finished training for epoch 122, loss: 0.305, accuracy: 0.825, training set size: 1800\n",
      "Finished training for epoch 123, loss: 0.312, accuracy: 0.807, training set size: 1800\n",
      "Finished training for epoch 124, loss: 0.303, accuracy: 0.816, training set size: 1800\n",
      "Finished training for epoch 125, loss: 0.307, accuracy: 0.818, training set size: 1800\n",
      "Finished training for epoch 126, loss: 0.308, accuracy: 0.800, training set size: 1800\n",
      "Finished training for epoch 127, loss: 0.307, accuracy: 0.814, training set size: 1800\n",
      "Finished training for epoch 128, loss: 0.304, accuracy: 0.821, training set size: 1800\n",
      "Finished training for epoch 129, loss: 0.301, accuracy: 0.834, training set size: 1800\n",
      "Finished training for epoch 130, loss: 0.304, accuracy: 0.819, training set size: 1800\n",
      "Finished training for epoch 131, loss: 0.296, accuracy: 0.846, training set size: 1800\n",
      "Finished training for epoch 132, loss: 0.307, accuracy: 0.820, training set size: 1800\n",
      "Finished training for epoch 133, loss: 0.311, accuracy: 0.807, training set size: 1800\n",
      "Finished training for epoch 134, loss: 0.306, accuracy: 0.808, training set size: 1800\n",
      "Finished training for epoch 135, loss: 0.316, accuracy: 0.812, training set size: 1800\n",
      "Finished training for epoch 136, loss: 0.298, accuracy: 0.830, training set size: 1800\n",
      "Finished training for epoch 137, loss: 0.310, accuracy: 0.820, training set size: 1800\n",
      "Finished training for epoch 138, loss: 0.316, accuracy: 0.811, training set size: 1800\n",
      "Finished training for epoch 139, loss: 0.307, accuracy: 0.810, training set size: 1800\n",
      "Finished training for epoch 140, loss: 0.306, accuracy: 0.813, training set size: 1800\n",
      "Finished training for epoch 141, loss: 0.301, accuracy: 0.811, training set size: 1800\n",
      "Finished training for epoch 142, loss: 0.309, accuracy: 0.825, training set size: 1800\n",
      "Finished training for epoch 143, loss: 0.298, accuracy: 0.822, training set size: 1800\n",
      "Finished training for epoch 144, loss: 0.304, accuracy: 0.815, training set size: 1800\n",
      "Finished training for epoch 145, loss: 0.299, accuracy: 0.817, training set size: 1800\n",
      "Finished training for epoch 146, loss: 0.301, accuracy: 0.826, training set size: 1800\n",
      "Finished training for epoch 147, loss: 0.327, accuracy: 0.794, training set size: 1800\n",
      "Finished training for epoch 148, loss: 0.307, accuracy: 0.806, training set size: 1800\n",
      "Finished training for epoch 149, loss: 0.296, accuracy: 0.836, training set size: 1800\n",
      "Finished training for epoch 150, loss: 0.295, accuracy: 0.832, training set size: 1800\n",
      "Finished training for epoch 151, loss: 0.300, accuracy: 0.822, training set size: 1800\n",
      "Finished training for epoch 152, loss: 0.309, accuracy: 0.816, training set size: 1800\n",
      "Finished training for epoch 153, loss: 0.300, accuracy: 0.833, training set size: 1800\n",
      "Finished training for epoch 154, loss: 0.298, accuracy: 0.821, training set size: 1800\n",
      "Finished training for epoch 155, loss: 0.303, accuracy: 0.824, training set size: 1800\n",
      "Finished training for epoch 156, loss: 0.302, accuracy: 0.812, training set size: 1800\n",
      "Finished training for epoch 157, loss: 0.312, accuracy: 0.804, training set size: 1800\n",
      "Finished training for epoch 158, loss: 0.298, accuracy: 0.823, training set size: 1800\n",
      "Finished training for epoch 159, loss: 0.305, accuracy: 0.821, training set size: 1800\n",
      "Finished training for epoch 160, loss: 0.297, accuracy: 0.834, training set size: 1800\n",
      "Finished training for epoch 161, loss: 0.299, accuracy: 0.830, training set size: 1800\n",
      "Finished training for epoch 162, loss: 0.299, accuracy: 0.844, training set size: 1800\n",
      "Finished training for epoch 163, loss: 0.295, accuracy: 0.833, training set size: 1800\n",
      "Finished training for epoch 164, loss: 0.321, accuracy: 0.799, training set size: 1800\n",
      "Finished training for epoch 165, loss: 0.308, accuracy: 0.814, training set size: 1800\n",
      "Finished training for epoch 166, loss: 0.303, accuracy: 0.812, training set size: 1800\n",
      "Finished training for epoch 167, loss: 0.298, accuracy: 0.829, training set size: 1800\n",
      "Finished training for epoch 168, loss: 0.301, accuracy: 0.816, training set size: 1800\n",
      "Finished training for epoch 169, loss: 0.304, accuracy: 0.816, training set size: 1800\n",
      "Finished training for epoch 170, loss: 0.303, accuracy: 0.820, training set size: 1800\n",
      "Finished training for epoch 171, loss: 0.314, accuracy: 0.814, training set size: 1800\n",
      "Finished training for epoch 172, loss: 0.312, accuracy: 0.819, training set size: 1800\n",
      "Finished training for epoch 173, loss: 0.304, accuracy: 0.826, training set size: 1800\n",
      "Finished training for epoch 174, loss: 0.317, accuracy: 0.796, training set size: 1800\n",
      "Finished training for epoch 175, loss: 0.293, accuracy: 0.836, training set size: 1800\n",
      "Finished training for epoch 176, loss: 0.298, accuracy: 0.840, training set size: 1800\n",
      "Finished training for epoch 177, loss: 0.294, accuracy: 0.833, training set size: 1800\n",
      "Finished training for epoch 178, loss: 0.296, accuracy: 0.823, training set size: 1800\n",
      "Finished training for epoch 179, loss: 0.327, accuracy: 0.804, training set size: 1800\n",
      "Finished training for epoch 180, loss: 0.302, accuracy: 0.829, training set size: 1800\n",
      "Finished training for epoch 181, loss: 0.297, accuracy: 0.836, training set size: 1800\n",
      "Finished training for epoch 182, loss: 0.293, accuracy: 0.841, training set size: 1800\n",
      "Finished training for epoch 183, loss: 0.299, accuracy: 0.837, training set size: 1800\n",
      "Finished training for epoch 184, loss: 0.301, accuracy: 0.816, training set size: 1800\n",
      "Finished training for epoch 185, loss: 0.306, accuracy: 0.807, training set size: 1800\n",
      "Finished training for epoch 186, loss: 0.294, accuracy: 0.829, training set size: 1800\n",
      "Finished training for epoch 187, loss: 0.296, accuracy: 0.844, training set size: 1800\n",
      "Finished training for epoch 188, loss: 0.308, accuracy: 0.812, training set size: 1800\n",
      "Finished training for epoch 189, loss: 0.303, accuracy: 0.812, training set size: 1800\n",
      "Finished training for epoch 190, loss: 0.301, accuracy: 0.817, training set size: 1800\n",
      "Finished training for epoch 191, loss: 0.291, accuracy: 0.838, training set size: 1800\n",
      "Finished training for epoch 192, loss: 0.300, accuracy: 0.822, training set size: 1800\n",
      "Finished training for epoch 193, loss: 0.300, accuracy: 0.826, training set size: 1800\n",
      "Finished training for epoch 194, loss: 0.296, accuracy: 0.830, training set size: 1800\n",
      "Finished training for epoch 195, loss: 0.300, accuracy: 0.824, training set size: 1800\n",
      "Finished training for epoch 196, loss: 0.291, accuracy: 0.835, training set size: 1800\n",
      "Finished training for epoch 197, loss: 0.306, accuracy: 0.814, training set size: 1800\n",
      "Finished training for epoch 198, loss: 0.292, accuracy: 0.828, training set size: 1800\n",
      "Finished training for epoch 199, loss: 0.297, accuracy: 0.818, training set size: 1800\n",
      "Finished training for epoch 200, loss: 0.289, accuracy: 0.830, training set size: 1800\n",
      "Finished training for epoch 201, loss: 0.305, accuracy: 0.812, training set size: 1800\n",
      "Finished training for epoch 202, loss: 0.301, accuracy: 0.830, training set size: 1800\n",
      "Finished training for epoch 203, loss: 0.296, accuracy: 0.838, training set size: 1800\n",
      "Finished training for epoch 204, loss: 0.291, accuracy: 0.846, training set size: 1800\n",
      "Finished training for epoch 205, loss: 0.302, accuracy: 0.818, training set size: 1800\n",
      "Finished training for epoch 206, loss: 0.316, accuracy: 0.810, training set size: 1800\n",
      "Finished training for epoch 207, loss: 0.295, accuracy: 0.816, training set size: 1800\n",
      "Finished training for epoch 208, loss: 0.299, accuracy: 0.825, training set size: 1800\n",
      "Finished training for epoch 209, loss: 0.296, accuracy: 0.825, training set size: 1800\n",
      "Finished training for epoch 210, loss: 0.288, accuracy: 0.856, training set size: 1800\n",
      "Finished training for epoch 211, loss: 0.290, accuracy: 0.829, training set size: 1800\n",
      "Finished training for epoch 212, loss: 0.292, accuracy: 0.828, training set size: 1800\n",
      "Finished training for epoch 213, loss: 0.289, accuracy: 0.838, training set size: 1800\n",
      "Finished training for epoch 214, loss: 0.292, accuracy: 0.837, training set size: 1800\n",
      "Finished training for epoch 215, loss: 0.304, accuracy: 0.827, training set size: 1800\n",
      "Finished training for epoch 216, loss: 0.302, accuracy: 0.836, training set size: 1800\n",
      "Finished training for epoch 217, loss: 0.295, accuracy: 0.830, training set size: 1800\n",
      "Finished training for epoch 218, loss: 0.299, accuracy: 0.826, training set size: 1800\n",
      "Finished training for epoch 219, loss: 0.282, accuracy: 0.859, training set size: 1800\n",
      "Finished training for epoch 220, loss: 0.290, accuracy: 0.823, training set size: 1800\n",
      "Finished training for epoch 221, loss: 0.299, accuracy: 0.823, training set size: 1800\n",
      "Finished training for epoch 222, loss: 0.287, accuracy: 0.827, training set size: 1800\n",
      "Finished training for epoch 223, loss: 0.288, accuracy: 0.842, training set size: 1800\n",
      "Finished training for epoch 224, loss: 0.292, accuracy: 0.821, training set size: 1800\n",
      "Finished training for epoch 225, loss: 0.294, accuracy: 0.830, training set size: 1800\n",
      "Finished training for epoch 226, loss: 0.302, accuracy: 0.827, training set size: 1800\n",
      "Finished training for epoch 227, loss: 0.291, accuracy: 0.841, training set size: 1800\n",
      "Finished training for epoch 228, loss: 0.292, accuracy: 0.838, training set size: 1800\n",
      "Finished training for epoch 229, loss: 0.309, accuracy: 0.804, training set size: 1800\n",
      "Finished training for epoch 230, loss: 0.291, accuracy: 0.835, training set size: 1800\n",
      "Finished training for epoch 231, loss: 0.290, accuracy: 0.851, training set size: 1800\n",
      "Finished training for epoch 232, loss: 0.282, accuracy: 0.861, training set size: 1800\n",
      "Finished training for epoch 233, loss: 0.291, accuracy: 0.839, training set size: 1800\n",
      "Finished training for epoch 234, loss: 0.295, accuracy: 0.826, training set size: 1800\n",
      "Finished training for epoch 235, loss: 0.304, accuracy: 0.817, training set size: 1800\n",
      "Finished training for epoch 236, loss: 0.288, accuracy: 0.844, training set size: 1800\n",
      "Finished training for epoch 237, loss: 0.280, accuracy: 0.857, training set size: 1800\n",
      "Finished training for epoch 238, loss: 0.286, accuracy: 0.842, training set size: 1800\n",
      "Finished training for epoch 239, loss: 0.317, accuracy: 0.803, training set size: 1800\n",
      "Finished training for epoch 240, loss: 0.294, accuracy: 0.834, training set size: 1800\n",
      "Finished training for epoch 241, loss: 0.281, accuracy: 0.849, training set size: 1800\n",
      "Finished training for epoch 242, loss: 0.317, accuracy: 0.799, training set size: 1800\n",
      "Finished training for epoch 243, loss: 0.313, accuracy: 0.803, training set size: 1800\n",
      "Finished training for epoch 244, loss: 0.297, accuracy: 0.815, training set size: 1800\n",
      "Finished training for epoch 245, loss: 0.292, accuracy: 0.838, training set size: 1800\n",
      "Finished training for epoch 246, loss: 0.296, accuracy: 0.834, training set size: 1800\n",
      "Finished training for epoch 247, loss: 0.285, accuracy: 0.843, training set size: 1800\n",
      "Finished training for epoch 248, loss: 0.281, accuracy: 0.854, training set size: 1800\n",
      "Finished training for epoch 249, loss: 0.291, accuracy: 0.853, training set size: 1800\n",
      "Finished training for epoch 250, loss: 0.306, accuracy: 0.828, training set size: 1800\n",
      "Finished training for epoch 251, loss: 0.297, accuracy: 0.818, training set size: 1800\n",
      "Finished training for epoch 252, loss: 0.297, accuracy: 0.823, training set size: 1800\n",
      "Finished training for epoch 253, loss: 0.286, accuracy: 0.846, training set size: 1800\n",
      "Finished training for epoch 254, loss: 0.281, accuracy: 0.850, training set size: 1800\n",
      "Finished training for epoch 255, loss: 0.298, accuracy: 0.824, training set size: 1800\n",
      "Finished training for epoch 256, loss: 0.281, accuracy: 0.851, training set size: 1800\n",
      "Finished training for epoch 257, loss: 0.289, accuracy: 0.839, training set size: 1800\n",
      "Finished training for epoch 258, loss: 0.286, accuracy: 0.838, training set size: 1800\n",
      "Finished training for epoch 259, loss: 0.282, accuracy: 0.853, training set size: 1800\n",
      "Finished training for epoch 260, loss: 0.292, accuracy: 0.828, training set size: 1800\n",
      "Finished training for epoch 261, loss: 0.309, accuracy: 0.821, training set size: 1800\n",
      "Finished training for epoch 262, loss: 0.291, accuracy: 0.824, training set size: 1800\n",
      "Finished training for epoch 263, loss: 0.291, accuracy: 0.837, training set size: 1800\n",
      "Finished training for epoch 264, loss: 0.284, accuracy: 0.844, training set size: 1800\n",
      "Finished training for epoch 265, loss: 0.288, accuracy: 0.836, training set size: 1800\n",
      "Finished training for epoch 266, loss: 0.299, accuracy: 0.823, training set size: 1800\n",
      "Finished training for epoch 267, loss: 0.286, accuracy: 0.849, training set size: 1800\n",
      "Finished training for epoch 268, loss: 0.302, accuracy: 0.816, training set size: 1800\n",
      "Finished training for epoch 269, loss: 0.284, accuracy: 0.861, training set size: 1800\n",
      "Finished training for epoch 270, loss: 0.280, accuracy: 0.852, training set size: 1800\n",
      "Finished training for epoch 271, loss: 0.308, accuracy: 0.807, training set size: 1800\n",
      "Finished training for epoch 272, loss: 0.292, accuracy: 0.834, training set size: 1800\n",
      "Finished training for epoch 273, loss: 0.284, accuracy: 0.848, training set size: 1800\n",
      "Finished training for epoch 274, loss: 0.302, accuracy: 0.817, training set size: 1800\n",
      "Finished training for epoch 275, loss: 0.309, accuracy: 0.821, training set size: 1800\n",
      "Finished training for epoch 276, loss: 0.283, accuracy: 0.846, training set size: 1800\n",
      "Finished training for epoch 277, loss: 0.300, accuracy: 0.818, training set size: 1800\n",
      "Finished training for epoch 278, loss: 0.278, accuracy: 0.844, training set size: 1800\n",
      "Finished training for epoch 279, loss: 0.283, accuracy: 0.836, training set size: 1800\n",
      "Finished training for epoch 280, loss: 0.293, accuracy: 0.828, training set size: 1800\n",
      "Finished training for epoch 281, loss: 0.287, accuracy: 0.851, training set size: 1800\n",
      "Finished training for epoch 282, loss: 0.283, accuracy: 0.838, training set size: 1800\n",
      "Finished training for epoch 283, loss: 0.281, accuracy: 0.837, training set size: 1800\n",
      "Finished training for epoch 284, loss: 0.281, accuracy: 0.851, training set size: 1800\n",
      "Finished training for epoch 285, loss: 0.277, accuracy: 0.862, training set size: 1800\n",
      "Finished training for epoch 286, loss: 0.285, accuracy: 0.840, training set size: 1800\n",
      "Finished training for epoch 287, loss: 0.290, accuracy: 0.846, training set size: 1800\n",
      "Finished training for epoch 288, loss: 0.285, accuracy: 0.846, training set size: 1800\n",
      "Finished training for epoch 289, loss: 0.280, accuracy: 0.849, training set size: 1800\n",
      "Finished training for epoch 290, loss: 0.280, accuracy: 0.858, training set size: 1800\n",
      "Finished training for epoch 291, loss: 0.280, accuracy: 0.849, training set size: 1800\n",
      "Finished training for epoch 292, loss: 0.288, accuracy: 0.847, training set size: 1800\n",
      "Finished training for epoch 293, loss: 0.280, accuracy: 0.846, training set size: 1800\n",
      "Finished training for epoch 294, loss: 0.292, accuracy: 0.824, training set size: 1800\n",
      "Finished training for epoch 295, loss: 0.299, accuracy: 0.826, training set size: 1800\n",
      "Finished training for epoch 296, loss: 0.284, accuracy: 0.856, training set size: 1800\n",
      "Finished training for epoch 297, loss: 0.281, accuracy: 0.843, training set size: 1800\n",
      "Finished training for epoch 298, loss: 0.270, accuracy: 0.862, training set size: 1800\n",
      "Finished training for epoch 299, loss: 0.281, accuracy: 0.858, training set size: 1800\n",
      "Finished training for epoch 300, loss: 0.288, accuracy: 0.843, training set size: 1800\n",
      "Finished training for epoch 301, loss: 0.308, accuracy: 0.825, training set size: 1800\n",
      "Finished training for epoch 302, loss: 0.294, accuracy: 0.830, training set size: 1800\n",
      "Finished training for epoch 303, loss: 0.290, accuracy: 0.842, training set size: 1800\n",
      "Finished training for epoch 304, loss: 0.271, accuracy: 0.856, training set size: 1800\n",
      "Finished training for epoch 305, loss: 0.273, accuracy: 0.852, training set size: 1800\n",
      "Finished training for epoch 306, loss: 0.282, accuracy: 0.850, training set size: 1800\n",
      "Finished training for epoch 307, loss: 0.289, accuracy: 0.838, training set size: 1800\n",
      "Finished training for epoch 308, loss: 0.279, accuracy: 0.856, training set size: 1800\n",
      "Finished training for epoch 309, loss: 0.287, accuracy: 0.828, training set size: 1800\n",
      "Finished training for epoch 310, loss: 0.287, accuracy: 0.836, training set size: 1800\n",
      "Finished training for epoch 311, loss: 0.279, accuracy: 0.863, training set size: 1800\n",
      "Finished training for epoch 312, loss: 0.272, accuracy: 0.852, training set size: 1800\n",
      "Finished training for epoch 313, loss: 0.281, accuracy: 0.853, training set size: 1800\n",
      "Finished training for epoch 314, loss: 0.280, accuracy: 0.848, training set size: 1800\n",
      "Finished training for epoch 315, loss: 0.271, accuracy: 0.858, training set size: 1800\n",
      "Finished training for epoch 316, loss: 0.284, accuracy: 0.834, training set size: 1800\n",
      "Finished training for epoch 317, loss: 0.275, accuracy: 0.854, training set size: 1800\n",
      "Finished training for epoch 318, loss: 0.278, accuracy: 0.844, training set size: 1800\n",
      "Finished training for epoch 319, loss: 0.290, accuracy: 0.854, training set size: 1800\n",
      "Finished training for epoch 320, loss: 0.296, accuracy: 0.831, training set size: 1800\n",
      "Finished training for epoch 321, loss: 0.277, accuracy: 0.858, training set size: 1800\n",
      "Finished training for epoch 322, loss: 0.273, accuracy: 0.855, training set size: 1800\n",
      "Finished training for epoch 323, loss: 0.288, accuracy: 0.828, training set size: 1800\n",
      "Finished training for epoch 324, loss: 0.279, accuracy: 0.840, training set size: 1800\n",
      "Finished training for epoch 325, loss: 0.269, accuracy: 0.871, training set size: 1800\n",
      "Finished training for epoch 326, loss: 0.269, accuracy: 0.865, training set size: 1800\n",
      "Finished training for epoch 327, loss: 0.282, accuracy: 0.828, training set size: 1800\n",
      "Finished training for epoch 328, loss: 0.283, accuracy: 0.836, training set size: 1800\n",
      "Finished training for epoch 329, loss: 0.281, accuracy: 0.849, training set size: 1800\n",
      "Finished training for epoch 330, loss: 0.272, accuracy: 0.856, training set size: 1800\n",
      "Finished training for epoch 331, loss: 0.280, accuracy: 0.844, training set size: 1800\n",
      "Finished training for epoch 332, loss: 0.270, accuracy: 0.855, training set size: 1800\n",
      "Finished training for epoch 333, loss: 0.265, accuracy: 0.877, training set size: 1800\n",
      "Finished training for epoch 334, loss: 0.277, accuracy: 0.848, training set size: 1800\n",
      "Finished training for epoch 335, loss: 0.275, accuracy: 0.861, training set size: 1800\n",
      "Finished training for epoch 336, loss: 0.270, accuracy: 0.862, training set size: 1800\n",
      "Finished training for epoch 337, loss: 0.263, accuracy: 0.868, training set size: 1800\n",
      "Finished training for epoch 338, loss: 0.275, accuracy: 0.859, training set size: 1800\n",
      "Finished training for epoch 339, loss: 0.280, accuracy: 0.836, training set size: 1800\n",
      "Finished training for epoch 340, loss: 0.274, accuracy: 0.847, training set size: 1800\n",
      "Finished training for epoch 341, loss: 0.260, accuracy: 0.877, training set size: 1800\n",
      "Finished training for epoch 342, loss: 0.266, accuracy: 0.853, training set size: 1800\n",
      "Finished training for epoch 343, loss: 0.262, accuracy: 0.858, training set size: 1800\n",
      "Finished training for epoch 344, loss: 0.290, accuracy: 0.838, training set size: 1800\n",
      "Finished training for epoch 345, loss: 0.265, accuracy: 0.870, training set size: 1800\n",
      "Finished training for epoch 346, loss: 0.271, accuracy: 0.855, training set size: 1800\n",
      "Finished training for epoch 347, loss: 0.276, accuracy: 0.851, training set size: 1800\n",
      "Finished training for epoch 348, loss: 0.280, accuracy: 0.837, training set size: 1800\n",
      "Finished training for epoch 349, loss: 0.276, accuracy: 0.858, training set size: 1800\n",
      "Finished training for epoch 350, loss: 0.280, accuracy: 0.844, training set size: 1800\n",
      "Finished training for epoch 351, loss: 0.289, accuracy: 0.847, training set size: 1800\n",
      "Finished training for epoch 352, loss: 0.266, accuracy: 0.867, training set size: 1800\n",
      "Finished training for epoch 353, loss: 0.267, accuracy: 0.859, training set size: 1800\n",
      "Finished training for epoch 354, loss: 0.270, accuracy: 0.852, training set size: 1800\n",
      "Finished training for epoch 355, loss: 0.269, accuracy: 0.863, training set size: 1800\n",
      "Finished training for epoch 356, loss: 0.264, accuracy: 0.863, training set size: 1800\n",
      "Finished training for epoch 357, loss: 0.259, accuracy: 0.872, training set size: 1800\n",
      "Finished training for epoch 358, loss: 0.279, accuracy: 0.848, training set size: 1800\n",
      "Finished training for epoch 359, loss: 0.261, accuracy: 0.865, training set size: 1800\n",
      "Finished training for epoch 360, loss: 0.263, accuracy: 0.862, training set size: 1800\n",
      "Finished training for epoch 361, loss: 0.257, accuracy: 0.859, training set size: 1800\n",
      "Finished training for epoch 362, loss: 0.269, accuracy: 0.852, training set size: 1800\n",
      "Finished training for epoch 363, loss: 0.266, accuracy: 0.849, training set size: 1800\n",
      "Finished training for epoch 364, loss: 0.260, accuracy: 0.871, training set size: 1800\n",
      "Finished training for epoch 365, loss: 0.262, accuracy: 0.856, training set size: 1800\n",
      "Finished training for epoch 366, loss: 0.267, accuracy: 0.852, training set size: 1800\n",
      "Finished training for epoch 367, loss: 0.289, accuracy: 0.840, training set size: 1800\n",
      "Finished training for epoch 368, loss: 0.286, accuracy: 0.842, training set size: 1800\n",
      "Finished training for epoch 369, loss: 0.284, accuracy: 0.852, training set size: 1800\n",
      "Finished training for epoch 370, loss: 0.291, accuracy: 0.827, training set size: 1800\n",
      "Finished training for epoch 371, loss: 0.260, accuracy: 0.866, training set size: 1800\n",
      "Finished training for epoch 372, loss: 0.263, accuracy: 0.861, training set size: 1800\n",
      "Finished training for epoch 373, loss: 0.253, accuracy: 0.881, training set size: 1800\n",
      "Finished training for epoch 374, loss: 0.267, accuracy: 0.846, training set size: 1800\n",
      "Finished training for epoch 375, loss: 0.261, accuracy: 0.863, training set size: 1800\n",
      "Finished training for epoch 376, loss: 0.260, accuracy: 0.861, training set size: 1800\n",
      "Finished training for epoch 377, loss: 0.278, accuracy: 0.849, training set size: 1800\n",
      "Finished training for epoch 378, loss: 0.262, accuracy: 0.867, training set size: 1800\n",
      "Finished training for epoch 379, loss: 0.257, accuracy: 0.860, training set size: 1800\n",
      "Finished training for epoch 380, loss: 0.269, accuracy: 0.854, training set size: 1800\n",
      "Finished training for epoch 381, loss: 0.273, accuracy: 0.847, training set size: 1800\n",
      "Finished training for epoch 382, loss: 0.257, accuracy: 0.872, training set size: 1800\n",
      "Finished training for epoch 383, loss: 0.254, accuracy: 0.876, training set size: 1800\n",
      "Finished training for epoch 384, loss: 0.251, accuracy: 0.886, training set size: 1800\n",
      "Finished training for epoch 385, loss: 0.255, accuracy: 0.880, training set size: 1800\n",
      "Finished training for epoch 386, loss: 0.300, accuracy: 0.822, training set size: 1800\n",
      "Finished training for epoch 387, loss: 0.253, accuracy: 0.862, training set size: 1800\n",
      "Finished training for epoch 388, loss: 0.259, accuracy: 0.856, training set size: 1800\n",
      "Finished training for epoch 389, loss: 0.250, accuracy: 0.886, training set size: 1800\n",
      "Finished training for epoch 390, loss: 0.246, accuracy: 0.880, training set size: 1800\n",
      "Finished training for epoch 391, loss: 0.246, accuracy: 0.891, training set size: 1800\n",
      "Finished training for epoch 392, loss: 0.266, accuracy: 0.852, training set size: 1800\n",
      "Finished training for epoch 393, loss: 0.299, accuracy: 0.824, training set size: 1800\n",
      "Finished training for epoch 394, loss: 0.263, accuracy: 0.855, training set size: 1800\n",
      "Finished training for epoch 395, loss: 0.280, accuracy: 0.848, training set size: 1800\n",
      "Finished training for epoch 396, loss: 0.256, accuracy: 0.870, training set size: 1800\n",
      "Finished training for epoch 397, loss: 0.255, accuracy: 0.874, training set size: 1800\n",
      "Finished training for epoch 398, loss: 0.271, accuracy: 0.860, training set size: 1800\n",
      "Finished training for epoch 399, loss: 0.257, accuracy: 0.857, training set size: 1800\n",
      "Finished training for epoch 400, loss: 0.284, accuracy: 0.842, training set size: 1800\n",
      "Finished training for epoch 401, loss: 0.246, accuracy: 0.877, training set size: 1800\n",
      "Finished training for epoch 402, loss: 0.254, accuracy: 0.868, training set size: 1800\n",
      "Finished training for epoch 403, loss: 0.268, accuracy: 0.858, training set size: 1800\n",
      "Finished training for epoch 404, loss: 0.263, accuracy: 0.866, training set size: 1800\n",
      "Finished training for epoch 405, loss: 0.262, accuracy: 0.867, training set size: 1800\n",
      "Finished training for epoch 406, loss: 0.253, accuracy: 0.874, training set size: 1800\n",
      "Finished training for epoch 407, loss: 0.262, accuracy: 0.853, training set size: 1800\n",
      "Finished training for epoch 408, loss: 0.246, accuracy: 0.888, training set size: 1800\n",
      "Finished training for epoch 409, loss: 0.240, accuracy: 0.886, training set size: 1800\n",
      "Finished training for epoch 410, loss: 0.274, accuracy: 0.851, training set size: 1800\n",
      "Finished training for epoch 411, loss: 0.249, accuracy: 0.888, training set size: 1800\n",
      "Finished training for epoch 412, loss: 0.257, accuracy: 0.862, training set size: 1800\n",
      "Finished training for epoch 413, loss: 0.254, accuracy: 0.868, training set size: 1800\n",
      "Finished training for epoch 414, loss: 0.259, accuracy: 0.864, training set size: 1800\n",
      "Finished training for epoch 415, loss: 0.263, accuracy: 0.851, training set size: 1800\n",
      "Finished training for epoch 416, loss: 0.237, accuracy: 0.891, training set size: 1800\n",
      "Finished training for epoch 417, loss: 0.251, accuracy: 0.876, training set size: 1800\n",
      "Finished training for epoch 418, loss: 0.260, accuracy: 0.872, training set size: 1800\n",
      "Finished training for epoch 419, loss: 0.241, accuracy: 0.886, training set size: 1800\n",
      "Finished training for epoch 420, loss: 0.266, accuracy: 0.872, training set size: 1800\n",
      "Finished training for epoch 421, loss: 0.252, accuracy: 0.878, training set size: 1800\n",
      "Finished training for epoch 422, loss: 0.257, accuracy: 0.872, training set size: 1800\n",
      "Finished training for epoch 423, loss: 0.246, accuracy: 0.884, training set size: 1800\n",
      "Finished training for epoch 424, loss: 0.277, accuracy: 0.843, training set size: 1800\n",
      "Finished training for epoch 425, loss: 0.242, accuracy: 0.881, training set size: 1800\n",
      "Finished training for epoch 426, loss: 0.265, accuracy: 0.864, training set size: 1800\n",
      "Finished training for epoch 427, loss: 0.240, accuracy: 0.897, training set size: 1800\n",
      "Finished training for epoch 428, loss: 0.272, accuracy: 0.852, training set size: 1800\n",
      "Finished training for epoch 429, loss: 0.259, accuracy: 0.869, training set size: 1800\n",
      "Finished training for epoch 430, loss: 0.258, accuracy: 0.883, training set size: 1800\n",
      "Finished training for epoch 431, loss: 0.254, accuracy: 0.872, training set size: 1800\n",
      "Finished training for epoch 432, loss: 0.247, accuracy: 0.877, training set size: 1800\n",
      "Finished training for epoch 433, loss: 0.257, accuracy: 0.869, training set size: 1800\n",
      "Finished training for epoch 434, loss: 0.249, accuracy: 0.869, training set size: 1800\n",
      "Finished training for epoch 435, loss: 0.265, accuracy: 0.864, training set size: 1800\n",
      "Finished training for epoch 436, loss: 0.248, accuracy: 0.881, training set size: 1800\n",
      "Finished training for epoch 437, loss: 0.289, accuracy: 0.845, training set size: 1800\n",
      "Finished training for epoch 438, loss: 0.258, accuracy: 0.861, training set size: 1800\n",
      "Finished training for epoch 439, loss: 0.262, accuracy: 0.865, training set size: 1800\n",
      "Finished training for epoch 440, loss: 0.245, accuracy: 0.893, training set size: 1800\n",
      "Finished training for epoch 441, loss: 0.253, accuracy: 0.862, training set size: 1800\n",
      "Finished training for epoch 442, loss: 0.235, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 443, loss: 0.266, accuracy: 0.863, training set size: 1800\n",
      "Finished training for epoch 444, loss: 0.243, accuracy: 0.880, training set size: 1800\n",
      "Finished training for epoch 445, loss: 0.239, accuracy: 0.890, training set size: 1800\n",
      "Finished training for epoch 446, loss: 0.234, accuracy: 0.881, training set size: 1800\n",
      "Finished training for epoch 447, loss: 0.256, accuracy: 0.876, training set size: 1800\n",
      "Finished training for epoch 448, loss: 0.268, accuracy: 0.856, training set size: 1800\n",
      "Finished training for epoch 449, loss: 0.237, accuracy: 0.894, training set size: 1800\n",
      "Finished training for epoch 450, loss: 0.240, accuracy: 0.885, training set size: 1800\n",
      "Finished training for epoch 451, loss: 0.248, accuracy: 0.868, training set size: 1800\n",
      "Finished training for epoch 452, loss: 0.251, accuracy: 0.876, training set size: 1800\n",
      "Finished training for epoch 453, loss: 0.310, accuracy: 0.839, training set size: 1800\n",
      "Finished training for epoch 454, loss: 0.259, accuracy: 0.861, training set size: 1800\n",
      "Finished training for epoch 455, loss: 0.279, accuracy: 0.848, training set size: 1800\n",
      "Finished training for epoch 456, loss: 0.256, accuracy: 0.861, training set size: 1800\n",
      "Finished training for epoch 457, loss: 0.236, accuracy: 0.899, training set size: 1800\n",
      "Finished training for epoch 458, loss: 0.231, accuracy: 0.892, training set size: 1800\n",
      "Finished training for epoch 459, loss: 0.254, accuracy: 0.872, training set size: 1800\n",
      "Finished training for epoch 460, loss: 0.251, accuracy: 0.869, training set size: 1800\n",
      "Finished training for epoch 461, loss: 0.237, accuracy: 0.891, training set size: 1800\n",
      "Finished training for epoch 462, loss: 0.246, accuracy: 0.870, training set size: 1800\n",
      "Finished training for epoch 463, loss: 0.261, accuracy: 0.853, training set size: 1800\n",
      "Finished training for epoch 464, loss: 0.247, accuracy: 0.878, training set size: 1800\n",
      "Finished training for epoch 465, loss: 0.247, accuracy: 0.867, training set size: 1800\n",
      "Finished training for epoch 466, loss: 0.241, accuracy: 0.881, training set size: 1800\n",
      "Finished training for epoch 467, loss: 0.221, accuracy: 0.903, training set size: 1800\n",
      "Finished training for epoch 468, loss: 0.245, accuracy: 0.872, training set size: 1800\n",
      "Finished training for epoch 469, loss: 0.270, accuracy: 0.857, training set size: 1800\n",
      "Finished training for epoch 470, loss: 0.232, accuracy: 0.897, training set size: 1800\n",
      "Finished training for epoch 471, loss: 0.250, accuracy: 0.876, training set size: 1800\n",
      "Finished training for epoch 472, loss: 0.226, accuracy: 0.896, training set size: 1800\n",
      "Finished training for epoch 473, loss: 0.325, accuracy: 0.856, training set size: 1800\n",
      "Finished training for epoch 474, loss: 0.243, accuracy: 0.880, training set size: 1800\n",
      "Finished training for epoch 475, loss: 0.244, accuracy: 0.882, training set size: 1800\n",
      "Finished training for epoch 476, loss: 0.227, accuracy: 0.896, training set size: 1800\n",
      "Finished training for epoch 477, loss: 0.234, accuracy: 0.880, training set size: 1800\n",
      "Finished training for epoch 478, loss: 0.233, accuracy: 0.874, training set size: 1800\n",
      "Finished training for epoch 479, loss: 0.235, accuracy: 0.883, training set size: 1800\n",
      "Finished training for epoch 480, loss: 0.239, accuracy: 0.882, training set size: 1800\n",
      "Finished training for epoch 481, loss: 0.243, accuracy: 0.874, training set size: 1800\n",
      "Finished training for epoch 482, loss: 0.232, accuracy: 0.884, training set size: 1800\n",
      "Finished training for epoch 483, loss: 0.288, accuracy: 0.837, training set size: 1800\n",
      "Finished training for epoch 484, loss: 0.242, accuracy: 0.882, training set size: 1800\n",
      "Finished training for epoch 485, loss: 0.272, accuracy: 0.853, training set size: 1800\n",
      "Finished training for epoch 486, loss: 0.249, accuracy: 0.864, training set size: 1800\n",
      "Finished training for epoch 487, loss: 0.233, accuracy: 0.899, training set size: 1800\n",
      "Finished training for epoch 488, loss: 0.245, accuracy: 0.874, training set size: 1800\n",
      "Finished training for epoch 489, loss: 0.252, accuracy: 0.880, training set size: 1800\n",
      "Finished training for epoch 490, loss: 0.266, accuracy: 0.856, training set size: 1800\n",
      "Finished training for epoch 491, loss: 0.239, accuracy: 0.882, training set size: 1800\n",
      "Finished training for epoch 492, loss: 0.264, accuracy: 0.873, training set size: 1800\n",
      "Finished training for epoch 493, loss: 0.222, accuracy: 0.917, training set size: 1800\n",
      "Finished training for epoch 494, loss: 0.234, accuracy: 0.886, training set size: 1800\n",
      "Finished training for epoch 495, loss: 0.270, accuracy: 0.862, training set size: 1800\n",
      "Finished training for epoch 496, loss: 0.261, accuracy: 0.874, training set size: 1800\n",
      "Finished training for epoch 497, loss: 0.239, accuracy: 0.873, training set size: 1800\n",
      "Finished training for epoch 498, loss: 0.230, accuracy: 0.891, training set size: 1800\n",
      "Finished training for epoch 499, loss: 0.233, accuracy: 0.884, training set size: 1800\n",
      "Finished training for epoch 500, loss: 0.250, accuracy: 0.876, training set size: 1800\n",
      "Finished training for epoch 501, loss: 0.241, accuracy: 0.883, training set size: 1800\n",
      "Finished training for epoch 502, loss: 0.217, accuracy: 0.911, training set size: 1800\n",
      "Finished training for epoch 503, loss: 0.232, accuracy: 0.901, training set size: 1800\n",
      "Finished training for epoch 504, loss: 0.333, accuracy: 0.857, training set size: 1800\n",
      "Finished training for epoch 505, loss: 0.218, accuracy: 0.907, training set size: 1800\n",
      "Finished training for epoch 506, loss: 0.278, accuracy: 0.856, training set size: 1800\n",
      "Finished training for epoch 507, loss: 0.224, accuracy: 0.909, training set size: 1800\n",
      "Finished training for epoch 508, loss: 0.225, accuracy: 0.900, training set size: 1800\n",
      "Finished training for epoch 509, loss: 0.230, accuracy: 0.878, training set size: 1800\n",
      "Finished training for epoch 510, loss: 0.218, accuracy: 0.909, training set size: 1800\n",
      "Finished training for epoch 511, loss: 0.241, accuracy: 0.887, training set size: 1800\n",
      "Finished training for epoch 512, loss: 0.241, accuracy: 0.869, training set size: 1800\n",
      "Finished training for epoch 513, loss: 0.239, accuracy: 0.893, training set size: 1800\n",
      "Finished training for epoch 514, loss: 0.237, accuracy: 0.883, training set size: 1800\n",
      "Finished training for epoch 515, loss: 0.235, accuracy: 0.889, training set size: 1800\n",
      "Finished training for epoch 516, loss: 0.234, accuracy: 0.883, training set size: 1800\n",
      "Finished training for epoch 517, loss: 0.225, accuracy: 0.894, training set size: 1800\n",
      "Finished training for epoch 518, loss: 0.243, accuracy: 0.884, training set size: 1800\n",
      "Finished training for epoch 519, loss: 0.219, accuracy: 0.891, training set size: 1800\n",
      "Finished training for epoch 520, loss: 0.224, accuracy: 0.903, training set size: 1800\n",
      "Finished training for epoch 521, loss: 0.232, accuracy: 0.895, training set size: 1800\n",
      "Finished training for epoch 522, loss: 0.253, accuracy: 0.867, training set size: 1800\n",
      "Finished training for epoch 523, loss: 0.208, accuracy: 0.912, training set size: 1800\n",
      "Finished training for epoch 524, loss: 0.234, accuracy: 0.880, training set size: 1800\n",
      "Finished training for epoch 525, loss: 0.211, accuracy: 0.919, training set size: 1800\n",
      "Finished training for epoch 526, loss: 0.229, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 527, loss: 0.287, accuracy: 0.858, training set size: 1800\n",
      "Finished training for epoch 528, loss: 0.233, accuracy: 0.896, training set size: 1800\n",
      "Finished training for epoch 529, loss: 0.249, accuracy: 0.872, training set size: 1800\n",
      "Finished training for epoch 530, loss: 0.225, accuracy: 0.898, training set size: 1800\n",
      "Finished training for epoch 531, loss: 0.237, accuracy: 0.879, training set size: 1800\n",
      "Finished training for epoch 532, loss: 0.253, accuracy: 0.868, training set size: 1800\n",
      "Finished training for epoch 533, loss: 0.232, accuracy: 0.887, training set size: 1800\n",
      "Finished training for epoch 534, loss: 0.211, accuracy: 0.907, training set size: 1800\n",
      "Finished training for epoch 535, loss: 0.243, accuracy: 0.868, training set size: 1800\n",
      "Finished training for epoch 536, loss: 0.216, accuracy: 0.903, training set size: 1800\n",
      "Finished training for epoch 537, loss: 0.255, accuracy: 0.862, training set size: 1800\n",
      "Finished training for epoch 538, loss: 0.248, accuracy: 0.874, training set size: 1800\n",
      "Finished training for epoch 539, loss: 0.217, accuracy: 0.901, training set size: 1800\n",
      "Finished training for epoch 540, loss: 0.219, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 541, loss: 0.252, accuracy: 0.880, training set size: 1800\n",
      "Finished training for epoch 542, loss: 0.280, accuracy: 0.863, training set size: 1800\n",
      "Finished training for epoch 543, loss: 0.211, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 544, loss: 0.248, accuracy: 0.875, training set size: 1800\n",
      "Finished training for epoch 545, loss: 0.276, accuracy: 0.858, training set size: 1800\n",
      "Finished training for epoch 546, loss: 0.259, accuracy: 0.870, training set size: 1800\n",
      "Finished training for epoch 547, loss: 0.236, accuracy: 0.877, training set size: 1800\n",
      "Finished training for epoch 548, loss: 0.237, accuracy: 0.877, training set size: 1800\n",
      "Finished training for epoch 549, loss: 0.234, accuracy: 0.889, training set size: 1800\n",
      "Finished training for epoch 550, loss: 0.233, accuracy: 0.882, training set size: 1800\n",
      "Finished training for epoch 551, loss: 0.215, accuracy: 0.909, training set size: 1800\n",
      "Finished training for epoch 552, loss: 0.208, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 553, loss: 0.219, accuracy: 0.889, training set size: 1800\n",
      "Finished training for epoch 554, loss: 0.230, accuracy: 0.886, training set size: 1800\n",
      "Finished training for epoch 555, loss: 0.222, accuracy: 0.894, training set size: 1800\n",
      "Finished training for epoch 556, loss: 0.213, accuracy: 0.898, training set size: 1800\n",
      "Finished training for epoch 557, loss: 0.230, accuracy: 0.893, training set size: 1800\n",
      "Finished training for epoch 558, loss: 0.214, accuracy: 0.897, training set size: 1800\n",
      "Finished training for epoch 559, loss: 0.229, accuracy: 0.893, training set size: 1800\n",
      "Finished training for epoch 560, loss: 0.210, accuracy: 0.908, training set size: 1800\n",
      "Finished training for epoch 561, loss: 0.213, accuracy: 0.904, training set size: 1800\n",
      "Finished training for epoch 562, loss: 0.252, accuracy: 0.868, training set size: 1800\n",
      "Finished training for epoch 563, loss: 0.201, accuracy: 0.916, training set size: 1800\n",
      "Finished training for epoch 564, loss: 0.233, accuracy: 0.894, training set size: 1800\n",
      "Finished training for epoch 565, loss: 0.243, accuracy: 0.871, training set size: 1800\n",
      "Finished training for epoch 566, loss: 0.223, accuracy: 0.893, training set size: 1800\n",
      "Finished training for epoch 567, loss: 0.218, accuracy: 0.897, training set size: 1800\n",
      "Finished training for epoch 568, loss: 0.204, accuracy: 0.907, training set size: 1800\n",
      "Finished training for epoch 569, loss: 0.221, accuracy: 0.892, training set size: 1800\n",
      "Finished training for epoch 570, loss: 0.212, accuracy: 0.911, training set size: 1800\n",
      "Finished training for epoch 571, loss: 0.209, accuracy: 0.900, training set size: 1800\n",
      "Finished training for epoch 572, loss: 0.265, accuracy: 0.862, training set size: 1800\n",
      "Finished training for epoch 573, loss: 0.237, accuracy: 0.882, training set size: 1800\n",
      "Finished training for epoch 574, loss: 0.201, accuracy: 0.909, training set size: 1800\n",
      "Finished training for epoch 575, loss: 0.252, accuracy: 0.891, training set size: 1800\n",
      "Finished training for epoch 576, loss: 0.239, accuracy: 0.881, training set size: 1800\n",
      "Finished training for epoch 577, loss: 0.219, accuracy: 0.892, training set size: 1800\n",
      "Finished training for epoch 578, loss: 0.195, accuracy: 0.918, training set size: 1800\n",
      "Finished training for epoch 579, loss: 0.227, accuracy: 0.882, training set size: 1800\n",
      "Finished training for epoch 580, loss: 0.222, accuracy: 0.876, training set size: 1800\n",
      "Finished training for epoch 581, loss: 0.223, accuracy: 0.898, training set size: 1800\n",
      "Finished training for epoch 582, loss: 0.206, accuracy: 0.904, training set size: 1800\n",
      "Finished training for epoch 583, loss: 0.205, accuracy: 0.916, training set size: 1800\n",
      "Finished training for epoch 584, loss: 0.216, accuracy: 0.896, training set size: 1800\n",
      "Finished training for epoch 585, loss: 0.194, accuracy: 0.922, training set size: 1800\n",
      "Finished training for epoch 586, loss: 0.200, accuracy: 0.910, training set size: 1800\n",
      "Finished training for epoch 587, loss: 0.219, accuracy: 0.893, training set size: 1800\n",
      "Finished training for epoch 588, loss: 0.192, accuracy: 0.914, training set size: 1800\n",
      "Finished training for epoch 589, loss: 0.245, accuracy: 0.878, training set size: 1800\n",
      "Finished training for epoch 590, loss: 0.220, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 591, loss: 0.243, accuracy: 0.874, training set size: 1800\n",
      "Finished training for epoch 592, loss: 0.183, accuracy: 0.933, training set size: 1800\n",
      "Finished training for epoch 593, loss: 0.210, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 594, loss: 0.238, accuracy: 0.891, training set size: 1800\n",
      "Finished training for epoch 595, loss: 0.288, accuracy: 0.851, training set size: 1800\n",
      "Finished training for epoch 596, loss: 0.205, accuracy: 0.909, training set size: 1800\n",
      "Finished training for epoch 597, loss: 0.192, accuracy: 0.923, training set size: 1800\n",
      "Finished training for epoch 598, loss: 0.212, accuracy: 0.904, training set size: 1800\n",
      "Finished training for epoch 599, loss: 0.212, accuracy: 0.899, training set size: 1800\n",
      "Finished training for epoch 600, loss: 0.206, accuracy: 0.893, training set size: 1800\n",
      "Finished training for epoch 601, loss: 0.217, accuracy: 0.898, training set size: 1800\n",
      "Finished training for epoch 602, loss: 0.189, accuracy: 0.921, training set size: 1800\n",
      "Finished training for epoch 603, loss: 0.191, accuracy: 0.916, training set size: 1800\n",
      "Finished training for epoch 604, loss: 0.194, accuracy: 0.915, training set size: 1800\n",
      "Finished training for epoch 605, loss: 0.247, accuracy: 0.876, training set size: 1800\n",
      "Finished training for epoch 606, loss: 0.239, accuracy: 0.878, training set size: 1800\n",
      "Finished training for epoch 607, loss: 0.244, accuracy: 0.869, training set size: 1800\n",
      "Finished training for epoch 608, loss: 0.202, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 609, loss: 0.195, accuracy: 0.912, training set size: 1800\n",
      "Finished training for epoch 610, loss: 0.196, accuracy: 0.909, training set size: 1800\n",
      "Finished training for epoch 611, loss: 0.189, accuracy: 0.922, training set size: 1800\n",
      "Finished training for epoch 612, loss: 0.233, accuracy: 0.886, training set size: 1800\n",
      "Finished training for epoch 613, loss: 0.218, accuracy: 0.891, training set size: 1800\n",
      "Finished training for epoch 614, loss: 0.190, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 615, loss: 0.214, accuracy: 0.901, training set size: 1800\n",
      "Finished training for epoch 616, loss: 0.263, accuracy: 0.866, training set size: 1800\n",
      "Finished training for epoch 617, loss: 0.201, accuracy: 0.914, training set size: 1800\n",
      "Finished training for epoch 618, loss: 0.260, accuracy: 0.871, training set size: 1800\n",
      "Finished training for epoch 619, loss: 0.188, accuracy: 0.915, training set size: 1800\n",
      "Finished training for epoch 620, loss: 0.196, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 621, loss: 0.216, accuracy: 0.892, training set size: 1800\n",
      "Finished training for epoch 622, loss: 0.205, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 623, loss: 0.195, accuracy: 0.907, training set size: 1800\n",
      "Finished training for epoch 624, loss: 0.186, accuracy: 0.923, training set size: 1800\n",
      "Finished training for epoch 625, loss: 0.201, accuracy: 0.898, training set size: 1800\n",
      "Finished training for epoch 626, loss: 0.200, accuracy: 0.915, training set size: 1800\n",
      "Finished training for epoch 627, loss: 0.203, accuracy: 0.908, training set size: 1800\n",
      "Finished training for epoch 628, loss: 0.211, accuracy: 0.898, training set size: 1800\n",
      "Finished training for epoch 629, loss: 0.206, accuracy: 0.908, training set size: 1800\n",
      "Finished training for epoch 630, loss: 0.241, accuracy: 0.876, training set size: 1800\n",
      "Finished training for epoch 631, loss: 0.252, accuracy: 0.878, training set size: 1800\n",
      "Finished training for epoch 632, loss: 0.214, accuracy: 0.892, training set size: 1800\n",
      "Finished training for epoch 633, loss: 0.192, accuracy: 0.919, training set size: 1800\n",
      "Finished training for epoch 634, loss: 0.183, accuracy: 0.924, training set size: 1800\n",
      "Finished training for epoch 635, loss: 0.219, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 636, loss: 0.263, accuracy: 0.859, training set size: 1800\n",
      "Finished training for epoch 637, loss: 0.216, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 638, loss: 0.202, accuracy: 0.904, training set size: 1800\n",
      "Finished training for epoch 639, loss: 0.199, accuracy: 0.904, training set size: 1800\n",
      "Finished training for epoch 640, loss: 0.209, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 641, loss: 0.199, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 642, loss: 0.251, accuracy: 0.876, training set size: 1800\n",
      "Finished training for epoch 643, loss: 0.196, accuracy: 0.914, training set size: 1800\n",
      "Finished training for epoch 644, loss: 0.199, accuracy: 0.908, training set size: 1800\n",
      "Finished training for epoch 645, loss: 0.220, accuracy: 0.889, training set size: 1800\n",
      "Finished training for epoch 646, loss: 0.184, accuracy: 0.912, training set size: 1800\n",
      "Finished training for epoch 647, loss: 0.178, accuracy: 0.926, training set size: 1800\n",
      "Finished training for epoch 648, loss: 0.201, accuracy: 0.906, training set size: 1800\n",
      "Finished training for epoch 649, loss: 0.187, accuracy: 0.921, training set size: 1800\n",
      "Finished training for epoch 650, loss: 0.193, accuracy: 0.914, training set size: 1800\n",
      "Finished training for epoch 651, loss: 0.170, accuracy: 0.931, training set size: 1800\n",
      "Finished training for epoch 652, loss: 0.269, accuracy: 0.855, training set size: 1800\n",
      "Finished training for epoch 653, loss: 0.187, accuracy: 0.905, training set size: 1800\n",
      "Finished training for epoch 654, loss: 0.205, accuracy: 0.901, training set size: 1800\n",
      "Finished training for epoch 655, loss: 0.249, accuracy: 0.873, training set size: 1800\n",
      "Finished training for epoch 656, loss: 0.204, accuracy: 0.899, training set size: 1800\n",
      "Finished training for epoch 657, loss: 0.195, accuracy: 0.911, training set size: 1800\n",
      "Finished training for epoch 658, loss: 0.210, accuracy: 0.903, training set size: 1800\n",
      "Finished training for epoch 659, loss: 0.229, accuracy: 0.895, training set size: 1800\n",
      "Finished training for epoch 660, loss: 0.186, accuracy: 0.906, training set size: 1800\n",
      "Finished training for epoch 661, loss: 0.206, accuracy: 0.891, training set size: 1800\n",
      "Finished training for epoch 662, loss: 0.204, accuracy: 0.903, training set size: 1800\n",
      "Finished training for epoch 663, loss: 0.197, accuracy: 0.906, training set size: 1800\n",
      "Finished training for epoch 664, loss: 0.195, accuracy: 0.914, training set size: 1800\n",
      "Finished training for epoch 665, loss: 0.212, accuracy: 0.888, training set size: 1800\n",
      "Finished training for epoch 666, loss: 0.190, accuracy: 0.912, training set size: 1800\n",
      "Finished training for epoch 667, loss: 0.186, accuracy: 0.923, training set size: 1800\n",
      "Finished training for epoch 668, loss: 0.205, accuracy: 0.898, training set size: 1800\n",
      "Finished training for epoch 669, loss: 0.273, accuracy: 0.887, training set size: 1800\n",
      "Finished training for epoch 670, loss: 0.242, accuracy: 0.882, training set size: 1800\n",
      "Finished training for epoch 671, loss: 0.204, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 672, loss: 0.196, accuracy: 0.903, training set size: 1800\n",
      "Finished training for epoch 673, loss: 0.195, accuracy: 0.915, training set size: 1800\n",
      "Finished training for epoch 674, loss: 0.201, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 675, loss: 0.215, accuracy: 0.891, training set size: 1800\n",
      "Finished training for epoch 676, loss: 0.204, accuracy: 0.910, training set size: 1800\n",
      "Finished training for epoch 677, loss: 0.186, accuracy: 0.924, training set size: 1800\n",
      "Finished training for epoch 678, loss: 0.206, accuracy: 0.903, training set size: 1800\n",
      "Finished training for epoch 679, loss: 0.178, accuracy: 0.924, training set size: 1800\n",
      "Finished training for epoch 680, loss: 0.187, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 681, loss: 0.189, accuracy: 0.910, training set size: 1800\n",
      "Finished training for epoch 682, loss: 0.208, accuracy: 0.905, training set size: 1800\n",
      "Finished training for epoch 683, loss: 0.261, accuracy: 0.870, training set size: 1800\n",
      "Finished training for epoch 684, loss: 0.265, accuracy: 0.868, training set size: 1800\n",
      "Finished training for epoch 685, loss: 0.189, accuracy: 0.908, training set size: 1800\n",
      "Finished training for epoch 686, loss: 0.202, accuracy: 0.900, training set size: 1800\n",
      "Finished training for epoch 687, loss: 0.207, accuracy: 0.901, training set size: 1800\n",
      "Finished training for epoch 688, loss: 0.180, accuracy: 0.920, training set size: 1800\n",
      "Finished training for epoch 689, loss: 0.196, accuracy: 0.919, training set size: 1800\n",
      "Finished training for epoch 690, loss: 0.194, accuracy: 0.910, training set size: 1800\n",
      "Finished training for epoch 691, loss: 0.193, accuracy: 0.914, training set size: 1800\n",
      "Finished training for epoch 692, loss: 0.217, accuracy: 0.897, training set size: 1800\n",
      "Finished training for epoch 693, loss: 0.240, accuracy: 0.880, training set size: 1800\n",
      "Finished training for epoch 694, loss: 0.188, accuracy: 0.917, training set size: 1800\n",
      "Finished training for epoch 695, loss: 0.193, accuracy: 0.911, training set size: 1800\n",
      "Finished training for epoch 696, loss: 0.231, accuracy: 0.882, training set size: 1800\n",
      "Finished training for epoch 697, loss: 0.172, accuracy: 0.927, training set size: 1800\n",
      "Finished training for epoch 698, loss: 0.189, accuracy: 0.916, training set size: 1800\n",
      "Finished training for epoch 699, loss: 0.206, accuracy: 0.895, training set size: 1800\n",
      "Finished training for epoch 700, loss: 0.163, accuracy: 0.939, training set size: 1800\n",
      "Finished training for epoch 701, loss: 0.209, accuracy: 0.895, training set size: 1800\n",
      "Finished training for epoch 702, loss: 0.172, accuracy: 0.924, training set size: 1800\n",
      "Finished training for epoch 703, loss: 0.185, accuracy: 0.919, training set size: 1800\n",
      "Finished training for epoch 704, loss: 0.209, accuracy: 0.898, training set size: 1800\n",
      "Finished training for epoch 705, loss: 0.195, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 706, loss: 0.220, accuracy: 0.894, training set size: 1800\n",
      "Finished training for epoch 707, loss: 0.205, accuracy: 0.898, training set size: 1800\n",
      "Finished training for epoch 708, loss: 0.198, accuracy: 0.903, training set size: 1800\n",
      "Finished training for epoch 709, loss: 0.183, accuracy: 0.918, training set size: 1800\n",
      "Finished training for epoch 710, loss: 0.262, accuracy: 0.883, training set size: 1800\n",
      "Finished training for epoch 711, loss: 0.207, accuracy: 0.893, training set size: 1800\n",
      "Finished training for epoch 712, loss: 0.172, accuracy: 0.928, training set size: 1800\n",
      "Finished training for epoch 713, loss: 0.170, accuracy: 0.923, training set size: 1800\n",
      "Finished training for epoch 714, loss: 0.172, accuracy: 0.917, training set size: 1800\n",
      "Finished training for epoch 715, loss: 0.179, accuracy: 0.919, training set size: 1800\n",
      "Finished training for epoch 716, loss: 0.191, accuracy: 0.909, training set size: 1800\n",
      "Finished training for epoch 717, loss: 0.193, accuracy: 0.909, training set size: 1800\n",
      "Finished training for epoch 718, loss: 0.188, accuracy: 0.903, training set size: 1800\n",
      "Finished training for epoch 719, loss: 0.311, accuracy: 0.850, training set size: 1800\n",
      "Finished training for epoch 720, loss: 0.208, accuracy: 0.908, training set size: 1800\n",
      "Finished training for epoch 721, loss: 0.199, accuracy: 0.903, training set size: 1800\n",
      "Finished training for epoch 722, loss: 0.237, accuracy: 0.884, training set size: 1800\n",
      "Finished training for epoch 723, loss: 0.180, accuracy: 0.924, training set size: 1800\n",
      "Finished training for epoch 724, loss: 0.216, accuracy: 0.894, training set size: 1800\n",
      "Finished training for epoch 725, loss: 0.215, accuracy: 0.901, training set size: 1800\n",
      "Finished training for epoch 726, loss: 0.168, accuracy: 0.935, training set size: 1800\n",
      "Finished training for epoch 727, loss: 0.177, accuracy: 0.917, training set size: 1800\n",
      "Finished training for epoch 728, loss: 0.198, accuracy: 0.907, training set size: 1800\n",
      "Finished training for epoch 729, loss: 0.187, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 730, loss: 0.221, accuracy: 0.892, training set size: 1800\n",
      "Finished training for epoch 731, loss: 0.233, accuracy: 0.882, training set size: 1800\n",
      "Finished training for epoch 732, loss: 0.171, accuracy: 0.929, training set size: 1800\n",
      "Finished training for epoch 733, loss: 0.202, accuracy: 0.907, training set size: 1800\n",
      "Finished training for epoch 734, loss: 0.207, accuracy: 0.899, training set size: 1800\n",
      "Finished training for epoch 735, loss: 0.172, accuracy: 0.927, training set size: 1800\n",
      "Finished training for epoch 736, loss: 0.200, accuracy: 0.915, training set size: 1800\n",
      "Finished training for epoch 737, loss: 0.246, accuracy: 0.879, training set size: 1800\n",
      "Finished training for epoch 738, loss: 0.187, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 739, loss: 0.217, accuracy: 0.886, training set size: 1800\n",
      "Finished training for epoch 740, loss: 0.233, accuracy: 0.872, training set size: 1800\n",
      "Finished training for epoch 741, loss: 0.200, accuracy: 0.905, training set size: 1800\n",
      "Finished training for epoch 742, loss: 0.196, accuracy: 0.904, training set size: 1800\n",
      "Finished training for epoch 743, loss: 0.192, accuracy: 0.917, training set size: 1800\n",
      "Finished training for epoch 744, loss: 0.196, accuracy: 0.906, training set size: 1800\n",
      "Finished training for epoch 745, loss: 0.174, accuracy: 0.923, training set size: 1800\n",
      "Finished training for epoch 746, loss: 0.164, accuracy: 0.936, training set size: 1800\n",
      "Finished training for epoch 747, loss: 0.176, accuracy: 0.926, training set size: 1800\n",
      "Finished training for epoch 748, loss: 0.177, accuracy: 0.921, training set size: 1800\n",
      "Finished training for epoch 749, loss: 0.161, accuracy: 0.935, training set size: 1800\n",
      "Finished training for epoch 750, loss: 0.182, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 751, loss: 0.193, accuracy: 0.910, training set size: 1800\n",
      "Finished training for epoch 752, loss: 0.201, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 753, loss: 0.209, accuracy: 0.898, training set size: 1800\n",
      "Finished training for epoch 754, loss: 0.197, accuracy: 0.903, training set size: 1800\n",
      "Finished training for epoch 755, loss: 0.241, accuracy: 0.888, training set size: 1800\n",
      "Finished training for epoch 756, loss: 0.176, accuracy: 0.926, training set size: 1800\n",
      "Finished training for epoch 757, loss: 0.194, accuracy: 0.912, training set size: 1800\n",
      "Finished training for epoch 758, loss: 0.190, accuracy: 0.921, training set size: 1800\n",
      "Finished training for epoch 759, loss: 0.191, accuracy: 0.903, training set size: 1800\n",
      "Finished training for epoch 760, loss: 0.160, accuracy: 0.939, training set size: 1800\n",
      "Finished training for epoch 761, loss: 0.175, accuracy: 0.920, training set size: 1800\n",
      "Finished training for epoch 762, loss: 0.181, accuracy: 0.917, training set size: 1800\n",
      "Finished training for epoch 763, loss: 0.227, accuracy: 0.884, training set size: 1800\n",
      "Finished training for epoch 764, loss: 0.265, accuracy: 0.867, training set size: 1800\n",
      "Finished training for epoch 765, loss: 0.181, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 766, loss: 0.193, accuracy: 0.909, training set size: 1800\n",
      "Finished training for epoch 767, loss: 0.187, accuracy: 0.910, training set size: 1800\n",
      "Finished training for epoch 768, loss: 0.164, accuracy: 0.929, training set size: 1800\n",
      "Finished training for epoch 769, loss: 0.196, accuracy: 0.911, training set size: 1800\n",
      "Finished training for epoch 770, loss: 0.163, accuracy: 0.932, training set size: 1800\n",
      "Finished training for epoch 771, loss: 0.184, accuracy: 0.912, training set size: 1800\n",
      "Finished training for epoch 772, loss: 0.171, accuracy: 0.921, training set size: 1800\n",
      "Finished training for epoch 773, loss: 0.208, accuracy: 0.897, training set size: 1800\n",
      "Finished training for epoch 774, loss: 0.195, accuracy: 0.911, training set size: 1800\n",
      "Finished training for epoch 775, loss: 0.177, accuracy: 0.918, training set size: 1800\n",
      "Finished training for epoch 776, loss: 0.199, accuracy: 0.905, training set size: 1800\n",
      "Finished training for epoch 777, loss: 0.193, accuracy: 0.909, training set size: 1800\n",
      "Finished training for epoch 778, loss: 0.207, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 779, loss: 0.161, accuracy: 0.932, training set size: 1800\n",
      "Finished training for epoch 780, loss: 0.211, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 781, loss: 0.168, accuracy: 0.927, training set size: 1800\n",
      "Finished training for epoch 782, loss: 0.177, accuracy: 0.917, training set size: 1800\n",
      "Finished training for epoch 783, loss: 0.168, accuracy: 0.932, training set size: 1800\n",
      "Finished training for epoch 784, loss: 0.185, accuracy: 0.914, training set size: 1800\n",
      "Finished training for epoch 785, loss: 0.201, accuracy: 0.908, training set size: 1800\n",
      "Finished training for epoch 786, loss: 0.171, accuracy: 0.927, training set size: 1800\n",
      "Finished training for epoch 787, loss: 0.207, accuracy: 0.904, training set size: 1800\n",
      "Finished training for epoch 788, loss: 0.167, accuracy: 0.926, training set size: 1800\n",
      "Finished training for epoch 789, loss: 0.212, accuracy: 0.896, training set size: 1800\n",
      "Finished training for epoch 790, loss: 0.183, accuracy: 0.917, training set size: 1800\n",
      "Finished training for epoch 791, loss: 0.305, accuracy: 0.872, training set size: 1800\n",
      "Finished training for epoch 792, loss: 0.207, accuracy: 0.897, training set size: 1800\n",
      "Finished training for epoch 793, loss: 0.177, accuracy: 0.923, training set size: 1800\n",
      "Finished training for epoch 794, loss: 0.159, accuracy: 0.932, training set size: 1800\n",
      "Finished training for epoch 795, loss: 0.184, accuracy: 0.914, training set size: 1800\n",
      "Finished training for epoch 796, loss: 0.294, accuracy: 0.864, training set size: 1800\n",
      "Finished training for epoch 797, loss: 0.168, accuracy: 0.932, training set size: 1800\n",
      "Finished training for epoch 798, loss: 0.218, accuracy: 0.891, training set size: 1800\n",
      "Finished training for epoch 799, loss: 0.177, accuracy: 0.926, training set size: 1800\n",
      "Finished training for epoch 800, loss: 0.200, accuracy: 0.911, training set size: 1800\n",
      "Finished training for epoch 801, loss: 0.168, accuracy: 0.926, training set size: 1800\n",
      "Finished training for epoch 802, loss: 0.147, accuracy: 0.942, training set size: 1800\n",
      "Finished training for epoch 803, loss: 0.197, accuracy: 0.904, training set size: 1800\n",
      "Finished training for epoch 804, loss: 0.214, accuracy: 0.898, training set size: 1800\n",
      "Finished training for epoch 805, loss: 0.198, accuracy: 0.903, training set size: 1800\n",
      "Finished training for epoch 806, loss: 0.189, accuracy: 0.910, training set size: 1800\n",
      "Finished training for epoch 807, loss: 0.159, accuracy: 0.936, training set size: 1800\n",
      "Finished training for epoch 808, loss: 0.283, accuracy: 0.873, training set size: 1800\n",
      "Finished training for epoch 809, loss: 0.177, accuracy: 0.922, training set size: 1800\n",
      "Finished training for epoch 810, loss: 0.212, accuracy: 0.897, training set size: 1800\n",
      "Finished training for epoch 811, loss: 0.292, accuracy: 0.868, training set size: 1800\n",
      "Finished training for epoch 812, loss: 0.162, accuracy: 0.933, training set size: 1800\n",
      "Finished training for epoch 813, loss: 0.194, accuracy: 0.909, training set size: 1800\n",
      "Finished training for epoch 814, loss: 0.192, accuracy: 0.904, training set size: 1800\n",
      "Finished training for epoch 815, loss: 0.170, accuracy: 0.923, training set size: 1800\n",
      "Finished training for epoch 816, loss: 0.175, accuracy: 0.918, training set size: 1800\n",
      "Finished training for epoch 817, loss: 0.180, accuracy: 0.922, training set size: 1800\n",
      "Finished training for epoch 818, loss: 0.232, accuracy: 0.883, training set size: 1800\n",
      "Finished training for epoch 819, loss: 0.183, accuracy: 0.909, training set size: 1800\n",
      "Finished training for epoch 820, loss: 0.215, accuracy: 0.895, training set size: 1800\n",
      "Finished training for epoch 821, loss: 0.186, accuracy: 0.914, training set size: 1800\n",
      "Finished training for epoch 822, loss: 0.176, accuracy: 0.927, training set size: 1800\n",
      "Finished training for epoch 823, loss: 0.173, accuracy: 0.922, training set size: 1800\n",
      "Finished training for epoch 824, loss: 0.167, accuracy: 0.928, training set size: 1800\n",
      "Finished training for epoch 825, loss: 0.212, accuracy: 0.899, training set size: 1800\n",
      "Finished training for epoch 826, loss: 0.316, accuracy: 0.857, training set size: 1800\n",
      "Finished training for epoch 827, loss: 0.190, accuracy: 0.914, training set size: 1800\n",
      "Finished training for epoch 828, loss: 0.197, accuracy: 0.901, training set size: 1800\n",
      "Finished training for epoch 829, loss: 0.170, accuracy: 0.925, training set size: 1800\n",
      "Finished training for epoch 830, loss: 0.269, accuracy: 0.859, training set size: 1800\n",
      "Finished training for epoch 831, loss: 0.212, accuracy: 0.891, training set size: 1800\n",
      "Finished training for epoch 832, loss: 0.159, accuracy: 0.944, training set size: 1800\n",
      "Finished training for epoch 833, loss: 0.197, accuracy: 0.903, training set size: 1800\n",
      "Finished training for epoch 834, loss: 0.242, accuracy: 0.879, training set size: 1800\n",
      "Finished training for epoch 835, loss: 0.262, accuracy: 0.871, training set size: 1800\n",
      "Finished training for epoch 836, loss: 0.178, accuracy: 0.928, training set size: 1800\n",
      "Finished training for epoch 837, loss: 0.190, accuracy: 0.908, training set size: 1800\n",
      "Finished training for epoch 838, loss: 0.190, accuracy: 0.917, training set size: 1800\n",
      "Finished training for epoch 839, loss: 0.176, accuracy: 0.923, training set size: 1800\n",
      "Finished training for epoch 840, loss: 0.169, accuracy: 0.920, training set size: 1800\n",
      "Finished training for epoch 841, loss: 0.188, accuracy: 0.911, training set size: 1800\n",
      "Finished training for epoch 842, loss: 0.149, accuracy: 0.947, training set size: 1800\n",
      "Finished training for epoch 843, loss: 0.184, accuracy: 0.911, training set size: 1800\n",
      "Finished training for epoch 844, loss: 0.173, accuracy: 0.921, training set size: 1800\n",
      "Finished training for epoch 845, loss: 0.155, accuracy: 0.937, training set size: 1800\n",
      "Finished training for epoch 846, loss: 0.196, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 847, loss: 0.212, accuracy: 0.901, training set size: 1800\n",
      "Finished training for epoch 848, loss: 0.167, accuracy: 0.924, training set size: 1800\n",
      "Finished training for epoch 849, loss: 0.225, accuracy: 0.899, training set size: 1800\n",
      "Finished training for epoch 850, loss: 0.188, accuracy: 0.909, training set size: 1800\n",
      "Finished training for epoch 851, loss: 0.184, accuracy: 0.911, training set size: 1800\n",
      "Finished training for epoch 852, loss: 0.195, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 853, loss: 0.211, accuracy: 0.895, training set size: 1800\n",
      "Finished training for epoch 854, loss: 0.191, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 855, loss: 0.187, accuracy: 0.908, training set size: 1800\n",
      "Finished training for epoch 856, loss: 0.165, accuracy: 0.927, training set size: 1800\n",
      "Finished training for epoch 857, loss: 0.165, accuracy: 0.921, training set size: 1800\n",
      "Finished training for epoch 858, loss: 0.159, accuracy: 0.936, training set size: 1800\n",
      "Finished training for epoch 859, loss: 0.199, accuracy: 0.901, training set size: 1800\n",
      "Finished training for epoch 860, loss: 0.265, accuracy: 0.879, training set size: 1800\n",
      "Finished training for epoch 861, loss: 0.192, accuracy: 0.907, training set size: 1800\n",
      "Finished training for epoch 862, loss: 0.166, accuracy: 0.926, training set size: 1800\n",
      "Finished training for epoch 863, loss: 0.215, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 864, loss: 0.170, accuracy: 0.923, training set size: 1800\n",
      "Finished training for epoch 865, loss: 0.158, accuracy: 0.938, training set size: 1800\n",
      "Finished training for epoch 866, loss: 0.158, accuracy: 0.928, training set size: 1800\n",
      "Finished training for epoch 867, loss: 0.174, accuracy: 0.920, training set size: 1800\n",
      "Finished training for epoch 868, loss: 0.191, accuracy: 0.905, training set size: 1800\n",
      "Finished training for epoch 869, loss: 0.230, accuracy: 0.893, training set size: 1800\n",
      "Finished training for epoch 870, loss: 0.221, accuracy: 0.888, training set size: 1800\n",
      "Finished training for epoch 871, loss: 0.190, accuracy: 0.921, training set size: 1800\n",
      "Finished training for epoch 872, loss: 0.184, accuracy: 0.915, training set size: 1800\n",
      "Finished training for epoch 873, loss: 0.173, accuracy: 0.924, training set size: 1800\n",
      "Finished training for epoch 874, loss: 0.177, accuracy: 0.926, training set size: 1800\n",
      "Finished training for epoch 875, loss: 0.194, accuracy: 0.923, training set size: 1800\n",
      "Finished training for epoch 876, loss: 0.195, accuracy: 0.904, training set size: 1800\n",
      "Finished training for epoch 877, loss: 0.166, accuracy: 0.925, training set size: 1800\n",
      "Finished training for epoch 878, loss: 0.176, accuracy: 0.921, training set size: 1800\n",
      "Finished training for epoch 879, loss: 0.202, accuracy: 0.901, training set size: 1800\n",
      "Finished training for epoch 880, loss: 0.170, accuracy: 0.929, training set size: 1800\n",
      "Finished training for epoch 881, loss: 0.190, accuracy: 0.903, training set size: 1800\n",
      "Finished training for epoch 882, loss: 0.169, accuracy: 0.919, training set size: 1800\n",
      "Finished training for epoch 883, loss: 0.156, accuracy: 0.929, training set size: 1800\n",
      "Finished training for epoch 884, loss: 0.156, accuracy: 0.933, training set size: 1800\n",
      "Finished training for epoch 885, loss: 0.183, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 886, loss: 0.177, accuracy: 0.927, training set size: 1800\n",
      "Finished training for epoch 887, loss: 0.239, accuracy: 0.882, training set size: 1800\n",
      "Finished training for epoch 888, loss: 0.169, accuracy: 0.929, training set size: 1800\n",
      "Finished training for epoch 889, loss: 0.216, accuracy: 0.893, training set size: 1800\n",
      "Finished training for epoch 890, loss: 0.234, accuracy: 0.886, training set size: 1800\n",
      "Finished training for epoch 891, loss: 0.284, accuracy: 0.873, training set size: 1800\n",
      "Finished training for epoch 892, loss: 0.193, accuracy: 0.904, training set size: 1800\n",
      "Finished training for epoch 893, loss: 0.190, accuracy: 0.911, training set size: 1800\n",
      "Finished training for epoch 894, loss: 0.212, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 895, loss: 0.191, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 896, loss: 0.189, accuracy: 0.911, training set size: 1800\n",
      "Finished training for epoch 897, loss: 0.211, accuracy: 0.897, training set size: 1800\n",
      "Finished training for epoch 898, loss: 0.164, accuracy: 0.933, training set size: 1800\n",
      "Finished training for epoch 899, loss: 0.168, accuracy: 0.929, training set size: 1800\n",
      "Finished training for epoch 900, loss: 0.165, accuracy: 0.922, training set size: 1800\n",
      "Finished training for epoch 901, loss: 0.178, accuracy: 0.916, training set size: 1800\n",
      "Finished training for epoch 902, loss: 0.173, accuracy: 0.919, training set size: 1800\n",
      "Finished training for epoch 903, loss: 0.159, accuracy: 0.934, training set size: 1800\n",
      "Finished training for epoch 904, loss: 0.194, accuracy: 0.904, training set size: 1800\n",
      "Finished training for epoch 905, loss: 0.181, accuracy: 0.916, training set size: 1800\n",
      "Finished training for epoch 906, loss: 0.205, accuracy: 0.899, training set size: 1800\n",
      "Finished training for epoch 907, loss: 0.182, accuracy: 0.916, training set size: 1800\n",
      "Finished training for epoch 908, loss: 0.158, accuracy: 0.928, training set size: 1800\n",
      "Finished training for epoch 909, loss: 0.151, accuracy: 0.935, training set size: 1800\n",
      "Finished training for epoch 910, loss: 0.180, accuracy: 0.914, training set size: 1800\n",
      "Finished training for epoch 911, loss: 0.165, accuracy: 0.928, training set size: 1800\n",
      "Finished training for epoch 912, loss: 0.189, accuracy: 0.917, training set size: 1800\n",
      "Finished training for epoch 913, loss: 0.182, accuracy: 0.917, training set size: 1800\n",
      "Finished training for epoch 914, loss: 0.185, accuracy: 0.909, training set size: 1800\n",
      "Finished training for epoch 915, loss: 0.190, accuracy: 0.914, training set size: 1800\n",
      "Finished training for epoch 916, loss: 0.205, accuracy: 0.908, training set size: 1800\n",
      "Finished training for epoch 917, loss: 0.190, accuracy: 0.908, training set size: 1800\n",
      "Finished training for epoch 918, loss: 0.205, accuracy: 0.899, training set size: 1800\n",
      "Finished training for epoch 919, loss: 0.204, accuracy: 0.900, training set size: 1800\n",
      "Finished training for epoch 920, loss: 0.211, accuracy: 0.901, training set size: 1800\n",
      "Finished training for epoch 921, loss: 0.174, accuracy: 0.917, training set size: 1800\n",
      "Finished training for epoch 922, loss: 0.196, accuracy: 0.901, training set size: 1800\n",
      "Finished training for epoch 923, loss: 0.248, accuracy: 0.873, training set size: 1800\n",
      "Finished training for epoch 924, loss: 0.195, accuracy: 0.904, training set size: 1800\n",
      "Finished training for epoch 925, loss: 0.171, accuracy: 0.921, training set size: 1800\n",
      "Finished training for epoch 926, loss: 0.179, accuracy: 0.918, training set size: 1800\n",
      "Finished training for epoch 927, loss: 0.162, accuracy: 0.926, training set size: 1800\n",
      "Finished training for epoch 928, loss: 0.182, accuracy: 0.914, training set size: 1800\n",
      "Finished training for epoch 929, loss: 0.169, accuracy: 0.921, training set size: 1800\n",
      "Finished training for epoch 930, loss: 0.192, accuracy: 0.909, training set size: 1800\n",
      "Finished training for epoch 931, loss: 0.176, accuracy: 0.928, training set size: 1800\n",
      "Finished training for epoch 932, loss: 0.170, accuracy: 0.920, training set size: 1800\n",
      "Finished training for epoch 933, loss: 0.176, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 934, loss: 0.187, accuracy: 0.908, training set size: 1800\n",
      "Finished training for epoch 935, loss: 0.213, accuracy: 0.893, training set size: 1800\n",
      "Finished training for epoch 936, loss: 0.187, accuracy: 0.912, training set size: 1800\n",
      "Finished training for epoch 937, loss: 0.155, accuracy: 0.936, training set size: 1800\n",
      "Finished training for epoch 938, loss: 0.171, accuracy: 0.921, training set size: 1800\n",
      "Finished training for epoch 939, loss: 0.205, accuracy: 0.908, training set size: 1800\n",
      "Finished training for epoch 940, loss: 0.173, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 941, loss: 0.215, accuracy: 0.888, training set size: 1800\n",
      "Finished training for epoch 942, loss: 0.234, accuracy: 0.889, training set size: 1800\n",
      "Finished training for epoch 943, loss: 0.185, accuracy: 0.916, training set size: 1800\n",
      "Finished training for epoch 944, loss: 0.181, accuracy: 0.911, training set size: 1800\n",
      "Finished training for epoch 945, loss: 0.172, accuracy: 0.923, training set size: 1800\n",
      "Finished training for epoch 946, loss: 0.198, accuracy: 0.908, training set size: 1800\n",
      "Finished training for epoch 947, loss: 0.157, accuracy: 0.927, training set size: 1800\n",
      "Finished training for epoch 948, loss: 0.188, accuracy: 0.917, training set size: 1800\n",
      "Finished training for epoch 949, loss: 0.182, accuracy: 0.916, training set size: 1800\n",
      "Finished training for epoch 950, loss: 0.163, accuracy: 0.930, training set size: 1800\n",
      "Finished training for epoch 951, loss: 0.237, accuracy: 0.890, training set size: 1800\n",
      "Finished training for epoch 952, loss: 0.160, accuracy: 0.937, training set size: 1800\n",
      "Finished training for epoch 953, loss: 0.233, accuracy: 0.889, training set size: 1800\n",
      "Finished training for epoch 954, loss: 0.186, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 955, loss: 0.186, accuracy: 0.915, training set size: 1800\n",
      "Finished training for epoch 956, loss: 0.212, accuracy: 0.891, training set size: 1800\n",
      "Finished training for epoch 957, loss: 0.189, accuracy: 0.909, training set size: 1800\n",
      "Finished training for epoch 958, loss: 0.189, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 959, loss: 0.189, accuracy: 0.906, training set size: 1800\n",
      "Finished training for epoch 960, loss: 0.151, accuracy: 0.945, training set size: 1800\n",
      "Finished training for epoch 961, loss: 0.183, accuracy: 0.917, training set size: 1800\n",
      "Finished training for epoch 962, loss: 0.158, accuracy: 0.929, training set size: 1800\n",
      "Finished training for epoch 963, loss: 0.166, accuracy: 0.923, training set size: 1800\n",
      "Finished training for epoch 964, loss: 0.225, accuracy: 0.894, training set size: 1800\n",
      "Finished training for epoch 965, loss: 0.160, accuracy: 0.927, training set size: 1800\n",
      "Finished training for epoch 966, loss: 0.186, accuracy: 0.914, training set size: 1800\n",
      "Finished training for epoch 967, loss: 0.173, accuracy: 0.923, training set size: 1800\n",
      "Finished training for epoch 968, loss: 0.199, accuracy: 0.910, training set size: 1800\n",
      "Finished training for epoch 969, loss: 0.177, accuracy: 0.922, training set size: 1800\n",
      "Finished training for epoch 970, loss: 0.200, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 971, loss: 0.180, accuracy: 0.916, training set size: 1800\n",
      "Finished training for epoch 972, loss: 0.175, accuracy: 0.922, training set size: 1800\n",
      "Finished training for epoch 973, loss: 0.144, accuracy: 0.942, training set size: 1800\n",
      "Finished training for epoch 974, loss: 0.171, accuracy: 0.928, training set size: 1800\n",
      "Finished training for epoch 975, loss: 0.200, accuracy: 0.908, training set size: 1800\n",
      "Finished training for epoch 976, loss: 0.152, accuracy: 0.937, training set size: 1800\n",
      "Finished training for epoch 977, loss: 0.143, accuracy: 0.947, training set size: 1800\n",
      "Finished training for epoch 978, loss: 0.183, accuracy: 0.913, training set size: 1800\n",
      "Finished training for epoch 979, loss: 0.143, accuracy: 0.938, training set size: 1800\n",
      "Finished training for epoch 980, loss: 0.155, accuracy: 0.931, training set size: 1800\n",
      "Finished training for epoch 981, loss: 0.166, accuracy: 0.918, training set size: 1800\n",
      "Finished training for epoch 982, loss: 0.182, accuracy: 0.914, training set size: 1800\n",
      "Finished training for epoch 983, loss: 0.177, accuracy: 0.918, training set size: 1800\n",
      "Finished training for epoch 984, loss: 0.307, accuracy: 0.886, training set size: 1800\n",
      "Finished training for epoch 985, loss: 0.159, accuracy: 0.929, training set size: 1800\n",
      "Finished training for epoch 986, loss: 0.167, accuracy: 0.930, training set size: 1800\n",
      "Finished training for epoch 987, loss: 0.155, accuracy: 0.936, training set size: 1800\n",
      "Finished training for epoch 988, loss: 0.224, accuracy: 0.893, training set size: 1800\n",
      "Finished training for epoch 989, loss: 0.273, accuracy: 0.867, training set size: 1800\n",
      "Finished training for epoch 990, loss: 0.181, accuracy: 0.902, training set size: 1800\n",
      "Finished training for epoch 991, loss: 0.186, accuracy: 0.917, training set size: 1800\n",
      "Finished training for epoch 992, loss: 0.189, accuracy: 0.903, training set size: 1800\n",
      "Finished training for epoch 993, loss: 0.153, accuracy: 0.937, training set size: 1800\n",
      "Finished training for epoch 994, loss: 0.180, accuracy: 0.916, training set size: 1800\n",
      "Finished training for epoch 995, loss: 0.160, accuracy: 0.933, training set size: 1800\n",
      "Finished training for epoch 996, loss: 0.201, accuracy: 0.903, training set size: 1800\n",
      "Finished training for epoch 997, loss: 0.196, accuracy: 0.898, training set size: 1800\n",
      "Finished training for epoch 998, loss: 0.173, accuracy: 0.926, training set size: 1800\n",
      "Finished training for epoch 999, loss: 0.137, accuracy: 0.947, training set size: 1800\n",
      "Finished training for epoch 1000, loss: 0.168, accuracy: 0.928, training set size: 1800\n",
      "Finished training for epoch 1001, loss: 0.213, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1002, loss: 0.176, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1003, loss: 0.204, accuracy: 0.887, training set size: 1930\n",
      "Finished training for epoch 1004, loss: 0.184, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1005, loss: 0.211, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1006, loss: 0.211, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1007, loss: 0.191, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1008, loss: 0.203, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1009, loss: 0.183, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1010, loss: 0.211, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1011, loss: 0.202, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1012, loss: 0.199, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1013, loss: 0.205, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1014, loss: 0.300, accuracy: 0.847, training set size: 1930\n",
      "Finished training for epoch 1015, loss: 0.196, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1016, loss: 0.208, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1017, loss: 0.206, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1018, loss: 0.204, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1019, loss: 0.195, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1020, loss: 0.211, accuracy: 0.878, training set size: 1930\n",
      "Finished training for epoch 1021, loss: 0.225, accuracy: 0.865, training set size: 1930\n",
      "Finished training for epoch 1022, loss: 0.211, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1023, loss: 0.221, accuracy: 0.870, training set size: 1930\n",
      "Finished training for epoch 1024, loss: 0.211, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1025, loss: 0.241, accuracy: 0.874, training set size: 1930\n",
      "Finished training for epoch 1026, loss: 0.183, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1027, loss: 0.187, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1028, loss: 0.204, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1029, loss: 0.226, accuracy: 0.872, training set size: 1930\n",
      "Finished training for epoch 1030, loss: 0.200, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1031, loss: 0.250, accuracy: 0.870, training set size: 1930\n",
      "Finished training for epoch 1032, loss: 0.193, accuracy: 0.904, training set size: 1930\n",
      "Finished training for epoch 1033, loss: 0.209, accuracy: 0.887, training set size: 1930\n",
      "Finished training for epoch 1034, loss: 0.191, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1035, loss: 0.179, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1036, loss: 0.230, accuracy: 0.868, training set size: 1930\n",
      "Finished training for epoch 1037, loss: 0.198, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1038, loss: 0.205, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1039, loss: 0.240, accuracy: 0.865, training set size: 1930\n",
      "Finished training for epoch 1040, loss: 0.278, accuracy: 0.849, training set size: 1930\n",
      "Finished training for epoch 1041, loss: 0.193, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1042, loss: 0.204, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1043, loss: 0.174, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1044, loss: 0.264, accuracy: 0.870, training set size: 1930\n",
      "Finished training for epoch 1045, loss: 0.234, accuracy: 0.876, training set size: 1930\n",
      "Finished training for epoch 1046, loss: 0.223, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1047, loss: 0.186, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1048, loss: 0.179, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1049, loss: 0.203, accuracy: 0.886, training set size: 1930\n",
      "Finished training for epoch 1050, loss: 0.181, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1051, loss: 0.201, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1052, loss: 0.186, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1053, loss: 0.215, accuracy: 0.866, training set size: 1930\n",
      "Finished training for epoch 1054, loss: 0.241, accuracy: 0.866, training set size: 1930\n",
      "Finished training for epoch 1055, loss: 0.185, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1056, loss: 0.248, accuracy: 0.865, training set size: 1930\n",
      "Finished training for epoch 1057, loss: 0.216, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1058, loss: 0.206, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1059, loss: 0.205, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1060, loss: 0.198, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1061, loss: 0.198, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1062, loss: 0.209, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1063, loss: 0.218, accuracy: 0.873, training set size: 1930\n",
      "Finished training for epoch 1064, loss: 0.234, accuracy: 0.864, training set size: 1930\n",
      "Finished training for epoch 1065, loss: 0.211, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1066, loss: 0.190, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1067, loss: 0.225, accuracy: 0.865, training set size: 1930\n",
      "Finished training for epoch 1068, loss: 0.208, accuracy: 0.878, training set size: 1930\n",
      "Finished training for epoch 1069, loss: 0.180, accuracy: 0.904, training set size: 1930\n",
      "Finished training for epoch 1070, loss: 0.182, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1071, loss: 0.200, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1072, loss: 0.219, accuracy: 0.872, training set size: 1930\n",
      "Finished training for epoch 1073, loss: 0.194, accuracy: 0.886, training set size: 1930\n",
      "Finished training for epoch 1074, loss: 0.178, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1075, loss: 0.225, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1076, loss: 0.213, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1077, loss: 0.208, accuracy: 0.886, training set size: 1930\n",
      "Finished training for epoch 1078, loss: 0.179, accuracy: 0.900, training set size: 1930\n",
      "Finished training for epoch 1079, loss: 0.197, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1080, loss: 0.221, accuracy: 0.876, training set size: 1930\n",
      "Finished training for epoch 1081, loss: 0.228, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1082, loss: 0.201, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1083, loss: 0.208, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1084, loss: 0.179, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1085, loss: 0.215, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1086, loss: 0.203, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1087, loss: 0.245, accuracy: 0.867, training set size: 1930\n",
      "Finished training for epoch 1088, loss: 0.286, accuracy: 0.855, training set size: 1930\n",
      "Finished training for epoch 1089, loss: 0.238, accuracy: 0.869, training set size: 1930\n",
      "Finished training for epoch 1090, loss: 0.182, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1091, loss: 0.195, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1092, loss: 0.240, accuracy: 0.866, training set size: 1930\n",
      "Finished training for epoch 1093, loss: 0.232, accuracy: 0.873, training set size: 1930\n",
      "Finished training for epoch 1094, loss: 0.197, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1095, loss: 0.176, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1096, loss: 0.223, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1097, loss: 0.184, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1098, loss: 0.214, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1099, loss: 0.197, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1100, loss: 0.262, accuracy: 0.857, training set size: 1930\n",
      "Finished training for epoch 1101, loss: 0.231, accuracy: 0.870, training set size: 1930\n",
      "Finished training for epoch 1102, loss: 0.193, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1103, loss: 0.194, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1104, loss: 0.215, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1105, loss: 0.184, accuracy: 0.900, training set size: 1930\n",
      "Finished training for epoch 1106, loss: 0.200, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1107, loss: 0.196, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1108, loss: 0.221, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1109, loss: 0.205, accuracy: 0.887, training set size: 1930\n",
      "Finished training for epoch 1110, loss: 0.222, accuracy: 0.878, training set size: 1930\n",
      "Finished training for epoch 1111, loss: 0.195, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1112, loss: 0.196, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1113, loss: 0.313, accuracy: 0.859, training set size: 1930\n",
      "Finished training for epoch 1114, loss: 0.254, accuracy: 0.861, training set size: 1930\n",
      "Finished training for epoch 1115, loss: 0.204, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1116, loss: 0.197, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1117, loss: 0.180, accuracy: 0.904, training set size: 1930\n",
      "Finished training for epoch 1118, loss: 0.190, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1119, loss: 0.197, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1120, loss: 0.188, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1121, loss: 0.204, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1122, loss: 0.225, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1123, loss: 0.180, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1124, loss: 0.216, accuracy: 0.871, training set size: 1930\n",
      "Finished training for epoch 1125, loss: 0.225, accuracy: 0.872, training set size: 1930\n",
      "Finished training for epoch 1126, loss: 0.177, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1127, loss: 0.179, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1128, loss: 0.210, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1129, loss: 0.214, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1130, loss: 0.166, accuracy: 0.918, training set size: 1930\n",
      "Finished training for epoch 1131, loss: 0.262, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1132, loss: 0.284, accuracy: 0.855, training set size: 1930\n",
      "Finished training for epoch 1133, loss: 0.204, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1134, loss: 0.192, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1135, loss: 0.187, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1136, loss: 0.233, accuracy: 0.871, training set size: 1930\n",
      "Finished training for epoch 1137, loss: 0.222, accuracy: 0.878, training set size: 1930\n",
      "Finished training for epoch 1138, loss: 0.211, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1139, loss: 0.200, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1140, loss: 0.217, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1141, loss: 0.203, accuracy: 0.887, training set size: 1930\n",
      "Finished training for epoch 1142, loss: 0.184, accuracy: 0.900, training set size: 1930\n",
      "Finished training for epoch 1143, loss: 0.203, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1144, loss: 0.206, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1145, loss: 0.185, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1146, loss: 0.195, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1147, loss: 0.195, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1148, loss: 0.207, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1149, loss: 0.181, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1150, loss: 0.216, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1151, loss: 0.214, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1152, loss: 0.224, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1153, loss: 0.197, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1154, loss: 0.198, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1155, loss: 0.208, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1156, loss: 0.182, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1157, loss: 0.191, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1158, loss: 0.207, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1159, loss: 0.207, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1160, loss: 0.206, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1161, loss: 0.191, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1162, loss: 0.194, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1163, loss: 0.196, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1164, loss: 0.190, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1165, loss: 0.212, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1166, loss: 0.209, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1167, loss: 0.240, accuracy: 0.866, training set size: 1930\n",
      "Finished training for epoch 1168, loss: 0.189, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1169, loss: 0.224, accuracy: 0.878, training set size: 1930\n",
      "Finished training for epoch 1170, loss: 0.218, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1171, loss: 0.214, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1172, loss: 0.209, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1173, loss: 0.201, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1174, loss: 0.186, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1175, loss: 0.270, accuracy: 0.854, training set size: 1930\n",
      "Finished training for epoch 1176, loss: 0.263, accuracy: 0.855, training set size: 1930\n",
      "Finished training for epoch 1177, loss: 0.200, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1178, loss: 0.237, accuracy: 0.869, training set size: 1930\n",
      "Finished training for epoch 1179, loss: 0.209, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1180, loss: 0.187, accuracy: 0.907, training set size: 1930\n",
      "Finished training for epoch 1181, loss: 0.202, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1182, loss: 0.209, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1183, loss: 0.201, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1184, loss: 0.166, accuracy: 0.914, training set size: 1930\n",
      "Finished training for epoch 1185, loss: 0.221, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1186, loss: 0.183, accuracy: 0.904, training set size: 1930\n",
      "Finished training for epoch 1187, loss: 0.188, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1188, loss: 0.182, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1189, loss: 0.197, accuracy: 0.886, training set size: 1930\n",
      "Finished training for epoch 1190, loss: 0.268, accuracy: 0.855, training set size: 1930\n",
      "Finished training for epoch 1191, loss: 0.248, accuracy: 0.862, training set size: 1930\n",
      "Finished training for epoch 1192, loss: 0.175, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1193, loss: 0.204, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1194, loss: 0.218, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1195, loss: 0.238, accuracy: 0.869, training set size: 1930\n",
      "Finished training for epoch 1196, loss: 0.218, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1197, loss: 0.181, accuracy: 0.910, training set size: 1930\n",
      "Finished training for epoch 1198, loss: 0.179, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1199, loss: 0.191, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1200, loss: 0.187, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1201, loss: 0.294, accuracy: 0.849, training set size: 1930\n",
      "Finished training for epoch 1202, loss: 0.180, accuracy: 0.906, training set size: 1930\n",
      "Finished training for epoch 1203, loss: 0.229, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1204, loss: 0.191, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1205, loss: 0.199, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1206, loss: 0.203, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1207, loss: 0.208, accuracy: 0.887, training set size: 1930\n",
      "Finished training for epoch 1208, loss: 0.205, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1209, loss: 0.190, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1210, loss: 0.196, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1211, loss: 0.178, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1212, loss: 0.194, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1213, loss: 0.224, accuracy: 0.876, training set size: 1930\n",
      "Finished training for epoch 1214, loss: 0.192, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1215, loss: 0.203, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1216, loss: 0.187, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1217, loss: 0.220, accuracy: 0.878, training set size: 1930\n",
      "Finished training for epoch 1218, loss: 0.178, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1219, loss: 0.194, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1220, loss: 0.236, accuracy: 0.860, training set size: 1930\n",
      "Finished training for epoch 1221, loss: 0.271, accuracy: 0.860, training set size: 1930\n",
      "Finished training for epoch 1222, loss: 0.196, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1223, loss: 0.182, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1224, loss: 0.203, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1225, loss: 0.217, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1226, loss: 0.226, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1227, loss: 0.189, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1228, loss: 0.204, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1229, loss: 0.176, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1230, loss: 0.213, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1231, loss: 0.174, accuracy: 0.910, training set size: 1930\n",
      "Finished training for epoch 1232, loss: 0.178, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1233, loss: 0.175, accuracy: 0.904, training set size: 1930\n",
      "Finished training for epoch 1234, loss: 0.185, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1235, loss: 0.186, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1236, loss: 0.186, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1237, loss: 0.199, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1238, loss: 0.243, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1239, loss: 0.229, accuracy: 0.873, training set size: 1930\n",
      "Finished training for epoch 1240, loss: 0.220, accuracy: 0.876, training set size: 1930\n",
      "Finished training for epoch 1241, loss: 0.189, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1242, loss: 0.184, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1243, loss: 0.228, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1244, loss: 0.194, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1245, loss: 0.176, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1246, loss: 0.194, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1247, loss: 0.214, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1248, loss: 0.223, accuracy: 0.876, training set size: 1930\n",
      "Finished training for epoch 1249, loss: 0.167, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1250, loss: 0.184, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1251, loss: 0.221, accuracy: 0.873, training set size: 1930\n",
      "Finished training for epoch 1252, loss: 0.178, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1253, loss: 0.224, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1254, loss: 0.177, accuracy: 0.906, training set size: 1930\n",
      "Finished training for epoch 1255, loss: 0.197, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1256, loss: 0.174, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1257, loss: 0.224, accuracy: 0.878, training set size: 1930\n",
      "Finished training for epoch 1258, loss: 0.206, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1259, loss: 0.197, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1260, loss: 0.251, accuracy: 0.864, training set size: 1930\n",
      "Finished training for epoch 1261, loss: 0.196, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1262, loss: 0.209, accuracy: 0.876, training set size: 1930\n",
      "Finished training for epoch 1263, loss: 0.171, accuracy: 0.912, training set size: 1930\n",
      "Finished training for epoch 1264, loss: 0.175, accuracy: 0.909, training set size: 1930\n",
      "Finished training for epoch 1265, loss: 0.200, accuracy: 0.887, training set size: 1930\n",
      "Finished training for epoch 1266, loss: 0.247, accuracy: 0.866, training set size: 1930\n",
      "Finished training for epoch 1267, loss: 0.228, accuracy: 0.870, training set size: 1930\n",
      "Finished training for epoch 1268, loss: 0.208, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1269, loss: 0.185, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1270, loss: 0.196, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1271, loss: 0.205, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1272, loss: 0.240, accuracy: 0.867, training set size: 1930\n",
      "Finished training for epoch 1273, loss: 0.192, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1274, loss: 0.248, accuracy: 0.862, training set size: 1930\n",
      "Finished training for epoch 1275, loss: 0.215, accuracy: 0.886, training set size: 1930\n",
      "Finished training for epoch 1276, loss: 0.178, accuracy: 0.908, training set size: 1930\n",
      "Finished training for epoch 1277, loss: 0.194, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1278, loss: 0.218, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1279, loss: 0.207, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1280, loss: 0.216, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1281, loss: 0.366, accuracy: 0.832, training set size: 1930\n",
      "Finished training for epoch 1282, loss: 0.211, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1283, loss: 0.190, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1284, loss: 0.179, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1285, loss: 0.201, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1286, loss: 0.179, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1287, loss: 0.179, accuracy: 0.909, training set size: 1930\n",
      "Finished training for epoch 1288, loss: 0.214, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1289, loss: 0.200, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1290, loss: 0.195, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1291, loss: 0.357, accuracy: 0.834, training set size: 1930\n",
      "Finished training for epoch 1292, loss: 0.191, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1293, loss: 0.203, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1294, loss: 0.184, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1295, loss: 0.235, accuracy: 0.868, training set size: 1930\n",
      "Finished training for epoch 1296, loss: 0.225, accuracy: 0.869, training set size: 1930\n",
      "Finished training for epoch 1297, loss: 0.209, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1298, loss: 0.191, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1299, loss: 0.197, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1300, loss: 0.201, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1301, loss: 0.186, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1302, loss: 0.248, accuracy: 0.861, training set size: 1930\n",
      "Finished training for epoch 1303, loss: 0.197, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1304, loss: 0.182, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1305, loss: 0.188, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1306, loss: 0.224, accuracy: 0.876, training set size: 1930\n",
      "Finished training for epoch 1307, loss: 0.189, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1308, loss: 0.203, accuracy: 0.886, training set size: 1930\n",
      "Finished training for epoch 1309, loss: 0.189, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1310, loss: 0.188, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1311, loss: 0.210, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1312, loss: 0.204, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1313, loss: 0.216, accuracy: 0.878, training set size: 1930\n",
      "Finished training for epoch 1314, loss: 0.189, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1315, loss: 0.278, accuracy: 0.855, training set size: 1930\n",
      "Finished training for epoch 1316, loss: 0.222, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1317, loss: 0.191, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1318, loss: 0.202, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1319, loss: 0.186, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1320, loss: 0.205, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1321, loss: 0.222, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1322, loss: 0.198, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1323, loss: 0.191, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1324, loss: 0.196, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1325, loss: 0.180, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1326, loss: 0.233, accuracy: 0.866, training set size: 1930\n",
      "Finished training for epoch 1327, loss: 0.211, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1328, loss: 0.218, accuracy: 0.874, training set size: 1930\n",
      "Finished training for epoch 1329, loss: 0.188, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1330, loss: 0.234, accuracy: 0.863, training set size: 1930\n",
      "Finished training for epoch 1331, loss: 0.224, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1332, loss: 0.170, accuracy: 0.909, training set size: 1930\n",
      "Finished training for epoch 1333, loss: 0.238, accuracy: 0.874, training set size: 1930\n",
      "Finished training for epoch 1334, loss: 0.173, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1335, loss: 0.187, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1336, loss: 0.218, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1337, loss: 0.209, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1338, loss: 0.188, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1339, loss: 0.254, accuracy: 0.855, training set size: 1930\n",
      "Finished training for epoch 1340, loss: 0.236, accuracy: 0.868, training set size: 1930\n",
      "Finished training for epoch 1341, loss: 0.213, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1342, loss: 0.225, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1343, loss: 0.197, accuracy: 0.886, training set size: 1930\n",
      "Finished training for epoch 1344, loss: 0.190, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1345, loss: 0.198, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1346, loss: 0.206, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1347, loss: 0.252, accuracy: 0.864, training set size: 1930\n",
      "Finished training for epoch 1348, loss: 0.189, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1349, loss: 0.184, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1350, loss: 0.187, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1351, loss: 0.192, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1352, loss: 0.197, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1353, loss: 0.188, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1354, loss: 0.229, accuracy: 0.870, training set size: 1930\n",
      "Finished training for epoch 1355, loss: 0.221, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1356, loss: 0.219, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1357, loss: 0.174, accuracy: 0.912, training set size: 1930\n",
      "Finished training for epoch 1358, loss: 0.198, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1359, loss: 0.208, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1360, loss: 0.194, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1361, loss: 0.226, accuracy: 0.872, training set size: 1930\n",
      "Finished training for epoch 1362, loss: 0.177, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1363, loss: 0.189, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1364, loss: 0.215, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1365, loss: 0.172, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1366, loss: 0.208, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1367, loss: 0.225, accuracy: 0.876, training set size: 1930\n",
      "Finished training for epoch 1368, loss: 0.181, accuracy: 0.904, training set size: 1930\n",
      "Finished training for epoch 1369, loss: 0.174, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1370, loss: 0.195, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1371, loss: 0.228, accuracy: 0.866, training set size: 1930\n",
      "Finished training for epoch 1372, loss: 0.199, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1373, loss: 0.173, accuracy: 0.900, training set size: 1930\n",
      "Finished training for epoch 1374, loss: 0.217, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1375, loss: 0.229, accuracy: 0.874, training set size: 1930\n",
      "Finished training for epoch 1376, loss: 0.219, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1377, loss: 0.203, accuracy: 0.886, training set size: 1930\n",
      "Finished training for epoch 1378, loss: 0.191, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1379, loss: 0.183, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1380, loss: 0.190, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1381, loss: 0.214, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1382, loss: 0.234, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1383, loss: 0.257, accuracy: 0.848, training set size: 1930\n",
      "Finished training for epoch 1384, loss: 0.201, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1385, loss: 0.205, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1386, loss: 0.182, accuracy: 0.900, training set size: 1930\n",
      "Finished training for epoch 1387, loss: 0.167, accuracy: 0.915, training set size: 1930\n",
      "Finished training for epoch 1388, loss: 0.168, accuracy: 0.918, training set size: 1930\n",
      "Finished training for epoch 1389, loss: 0.174, accuracy: 0.909, training set size: 1930\n",
      "Finished training for epoch 1390, loss: 0.169, accuracy: 0.908, training set size: 1930\n",
      "Finished training for epoch 1391, loss: 0.194, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1392, loss: 0.206, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1393, loss: 0.205, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1394, loss: 0.203, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1395, loss: 0.241, accuracy: 0.866, training set size: 1930\n",
      "Finished training for epoch 1396, loss: 0.201, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1397, loss: 0.208, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1398, loss: 0.189, accuracy: 0.900, training set size: 1930\n",
      "Finished training for epoch 1399, loss: 0.198, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1400, loss: 0.187, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1401, loss: 0.244, accuracy: 0.866, training set size: 1930\n",
      "Finished training for epoch 1402, loss: 0.182, accuracy: 0.900, training set size: 1930\n",
      "Finished training for epoch 1403, loss: 0.190, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1404, loss: 0.192, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1405, loss: 0.217, accuracy: 0.876, training set size: 1930\n",
      "Finished training for epoch 1406, loss: 0.195, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1407, loss: 0.172, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1408, loss: 0.177, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1409, loss: 0.168, accuracy: 0.907, training set size: 1930\n",
      "Finished training for epoch 1410, loss: 0.226, accuracy: 0.876, training set size: 1930\n",
      "Finished training for epoch 1411, loss: 0.229, accuracy: 0.876, training set size: 1930\n",
      "Finished training for epoch 1412, loss: 0.173, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1413, loss: 0.204, accuracy: 0.887, training set size: 1930\n",
      "Finished training for epoch 1414, loss: 0.186, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1415, loss: 0.197, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1416, loss: 0.217, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1417, loss: 0.187, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1418, loss: 0.217, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1419, loss: 0.165, accuracy: 0.915, training set size: 1930\n",
      "Finished training for epoch 1420, loss: 0.209, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1421, loss: 0.188, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1422, loss: 0.185, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1423, loss: 0.191, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1424, loss: 0.187, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1425, loss: 0.205, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1426, loss: 0.185, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1427, loss: 0.204, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1428, loss: 0.192, accuracy: 0.886, training set size: 1930\n",
      "Finished training for epoch 1429, loss: 0.176, accuracy: 0.907, training set size: 1930\n",
      "Finished training for epoch 1430, loss: 0.193, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1431, loss: 0.202, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1432, loss: 0.223, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1433, loss: 0.226, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1434, loss: 0.234, accuracy: 0.869, training set size: 1930\n",
      "Finished training for epoch 1435, loss: 0.200, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1436, loss: 0.217, accuracy: 0.868, training set size: 1930\n",
      "Finished training for epoch 1437, loss: 0.171, accuracy: 0.913, training set size: 1930\n",
      "Finished training for epoch 1438, loss: 0.224, accuracy: 0.871, training set size: 1930\n",
      "Finished training for epoch 1439, loss: 0.177, accuracy: 0.910, training set size: 1930\n",
      "Finished training for epoch 1440, loss: 0.169, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1441, loss: 0.236, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1442, loss: 0.215, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1443, loss: 0.252, accuracy: 0.863, training set size: 1930\n",
      "Finished training for epoch 1444, loss: 0.267, accuracy: 0.868, training set size: 1930\n",
      "Finished training for epoch 1445, loss: 0.207, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1446, loss: 0.175, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1447, loss: 0.230, accuracy: 0.872, training set size: 1930\n",
      "Finished training for epoch 1448, loss: 0.169, accuracy: 0.912, training set size: 1930\n",
      "Finished training for epoch 1449, loss: 0.173, accuracy: 0.909, training set size: 1930\n",
      "Finished training for epoch 1450, loss: 0.176, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1451, loss: 0.181, accuracy: 0.904, training set size: 1930\n",
      "Finished training for epoch 1452, loss: 0.179, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1453, loss: 0.225, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1454, loss: 0.219, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1455, loss: 0.188, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1456, loss: 0.205, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1457, loss: 0.227, accuracy: 0.867, training set size: 1930\n",
      "Finished training for epoch 1458, loss: 0.193, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1459, loss: 0.199, accuracy: 0.886, training set size: 1930\n",
      "Finished training for epoch 1460, loss: 0.217, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1461, loss: 0.180, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1462, loss: 0.170, accuracy: 0.909, training set size: 1930\n",
      "Finished training for epoch 1463, loss: 0.202, accuracy: 0.886, training set size: 1930\n",
      "Finished training for epoch 1464, loss: 0.226, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1465, loss: 0.176, accuracy: 0.907, training set size: 1930\n",
      "Finished training for epoch 1466, loss: 0.211, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1467, loss: 0.181, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1468, loss: 0.156, accuracy: 0.918, training set size: 1930\n",
      "Finished training for epoch 1469, loss: 0.184, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1470, loss: 0.168, accuracy: 0.904, training set size: 1930\n",
      "Finished training for epoch 1471, loss: 0.213, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1472, loss: 0.191, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1473, loss: 0.190, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1474, loss: 0.185, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1475, loss: 0.266, accuracy: 0.857, training set size: 1930\n",
      "Finished training for epoch 1476, loss: 0.188, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1477, loss: 0.199, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1478, loss: 0.190, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1479, loss: 0.228, accuracy: 0.870, training set size: 1930\n",
      "Finished training for epoch 1480, loss: 0.199, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1481, loss: 0.169, accuracy: 0.909, training set size: 1930\n",
      "Finished training for epoch 1482, loss: 0.188, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1483, loss: 0.196, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1484, loss: 0.234, accuracy: 0.868, training set size: 1930\n",
      "Finished training for epoch 1485, loss: 0.228, accuracy: 0.873, training set size: 1930\n",
      "Finished training for epoch 1486, loss: 0.175, accuracy: 0.907, training set size: 1930\n",
      "Finished training for epoch 1487, loss: 0.188, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1488, loss: 0.210, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1489, loss: 0.233, accuracy: 0.860, training set size: 1930\n",
      "Finished training for epoch 1490, loss: 0.217, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1491, loss: 0.252, accuracy: 0.860, training set size: 1930\n",
      "Finished training for epoch 1492, loss: 0.211, accuracy: 0.886, training set size: 1930\n",
      "Finished training for epoch 1493, loss: 0.186, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1494, loss: 0.176, accuracy: 0.906, training set size: 1930\n",
      "Finished training for epoch 1495, loss: 0.165, accuracy: 0.913, training set size: 1930\n",
      "Finished training for epoch 1496, loss: 0.245, accuracy: 0.861, training set size: 1930\n",
      "Finished training for epoch 1497, loss: 0.197, accuracy: 0.900, training set size: 1930\n",
      "Finished training for epoch 1498, loss: 0.173, accuracy: 0.909, training set size: 1930\n",
      "Finished training for epoch 1499, loss: 0.176, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1500, loss: 0.230, accuracy: 0.873, training set size: 1930\n",
      "Finished training for epoch 1501, loss: 0.178, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1502, loss: 0.195, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1503, loss: 0.201, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1504, loss: 0.197, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1505, loss: 0.179, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1506, loss: 0.208, accuracy: 0.874, training set size: 1930\n",
      "Finished training for epoch 1507, loss: 0.201, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1508, loss: 0.187, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1509, loss: 0.209, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1510, loss: 0.206, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1511, loss: 0.181, accuracy: 0.904, training set size: 1930\n",
      "Finished training for epoch 1512, loss: 0.224, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1513, loss: 0.181, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1514, loss: 0.206, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1515, loss: 0.205, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1516, loss: 0.171, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1517, loss: 0.196, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1518, loss: 0.181, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1519, loss: 0.164, accuracy: 0.910, training set size: 1930\n",
      "Finished training for epoch 1520, loss: 0.171, accuracy: 0.912, training set size: 1930\n",
      "Finished training for epoch 1521, loss: 0.194, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1522, loss: 0.298, accuracy: 0.850, training set size: 1930\n",
      "Finished training for epoch 1523, loss: 0.229, accuracy: 0.874, training set size: 1930\n",
      "Finished training for epoch 1524, loss: 0.209, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1525, loss: 0.181, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1526, loss: 0.182, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1527, loss: 0.206, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1528, loss: 0.195, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1529, loss: 0.233, accuracy: 0.866, training set size: 1930\n",
      "Finished training for epoch 1530, loss: 0.201, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1531, loss: 0.190, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1532, loss: 0.175, accuracy: 0.909, training set size: 1930\n",
      "Finished training for epoch 1533, loss: 0.185, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1534, loss: 0.192, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1535, loss: 0.178, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1536, loss: 0.159, accuracy: 0.913, training set size: 1930\n",
      "Finished training for epoch 1537, loss: 0.212, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1538, loss: 0.187, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1539, loss: 0.197, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1540, loss: 0.238, accuracy: 0.862, training set size: 1930\n",
      "Finished training for epoch 1541, loss: 0.200, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1542, loss: 0.213, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1543, loss: 0.249, accuracy: 0.864, training set size: 1930\n",
      "Finished training for epoch 1544, loss: 0.196, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1545, loss: 0.197, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1546, loss: 0.163, accuracy: 0.915, training set size: 1930\n",
      "Finished training for epoch 1547, loss: 0.175, accuracy: 0.907, training set size: 1930\n",
      "Finished training for epoch 1548, loss: 0.238, accuracy: 0.862, training set size: 1930\n",
      "Finished training for epoch 1549, loss: 0.184, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1550, loss: 0.207, accuracy: 0.887, training set size: 1930\n",
      "Finished training for epoch 1551, loss: 0.196, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1552, loss: 0.190, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1553, loss: 0.174, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1554, loss: 0.154, accuracy: 0.919, training set size: 1930\n",
      "Finished training for epoch 1555, loss: 0.190, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1556, loss: 0.215, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1557, loss: 0.183, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1558, loss: 0.232, accuracy: 0.876, training set size: 1930\n",
      "Finished training for epoch 1559, loss: 0.173, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1560, loss: 0.166, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1561, loss: 0.183, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1562, loss: 0.177, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1563, loss: 0.195, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1564, loss: 0.189, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1565, loss: 0.208, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1566, loss: 0.175, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1567, loss: 0.235, accuracy: 0.870, training set size: 1930\n",
      "Finished training for epoch 1568, loss: 0.235, accuracy: 0.874, training set size: 1930\n",
      "Finished training for epoch 1569, loss: 0.186, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1570, loss: 0.181, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1571, loss: 0.199, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1572, loss: 0.194, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1573, loss: 0.161, accuracy: 0.909, training set size: 1930\n",
      "Finished training for epoch 1574, loss: 0.177, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1575, loss: 0.208, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1576, loss: 0.177, accuracy: 0.907, training set size: 1930\n",
      "Finished training for epoch 1577, loss: 0.173, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1578, loss: 0.243, accuracy: 0.866, training set size: 1930\n",
      "Finished training for epoch 1579, loss: 0.185, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1580, loss: 0.184, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1581, loss: 0.200, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1582, loss: 0.252, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1583, loss: 0.188, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1584, loss: 0.275, accuracy: 0.856, training set size: 1930\n",
      "Finished training for epoch 1585, loss: 0.250, accuracy: 0.857, training set size: 1930\n",
      "Finished training for epoch 1586, loss: 0.206, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1587, loss: 0.188, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1588, loss: 0.178, accuracy: 0.906, training set size: 1930\n",
      "Finished training for epoch 1589, loss: 0.174, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1590, loss: 0.233, accuracy: 0.874, training set size: 1930\n",
      "Finished training for epoch 1591, loss: 0.219, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1592, loss: 0.211, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1593, loss: 0.201, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1594, loss: 0.182, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1595, loss: 0.215, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1596, loss: 0.197, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1597, loss: 0.245, accuracy: 0.867, training set size: 1930\n",
      "Finished training for epoch 1598, loss: 0.293, accuracy: 0.850, training set size: 1930\n",
      "Finished training for epoch 1599, loss: 0.187, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1600, loss: 0.200, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1601, loss: 0.211, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1602, loss: 0.210, accuracy: 0.886, training set size: 1930\n",
      "Finished training for epoch 1603, loss: 0.174, accuracy: 0.907, training set size: 1930\n",
      "Finished training for epoch 1604, loss: 0.192, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1605, loss: 0.168, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1606, loss: 0.228, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1607, loss: 0.200, accuracy: 0.887, training set size: 1930\n",
      "Finished training for epoch 1608, loss: 0.186, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1609, loss: 0.220, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1610, loss: 0.231, accuracy: 0.872, training set size: 1930\n",
      "Finished training for epoch 1611, loss: 0.204, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1612, loss: 0.224, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1613, loss: 0.192, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1614, loss: 0.186, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1615, loss: 0.219, accuracy: 0.874, training set size: 1930\n",
      "Finished training for epoch 1616, loss: 0.184, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1617, loss: 0.173, accuracy: 0.909, training set size: 1930\n",
      "Finished training for epoch 1618, loss: 0.192, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1619, loss: 0.227, accuracy: 0.870, training set size: 1930\n",
      "Finished training for epoch 1620, loss: 0.188, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1621, loss: 0.215, accuracy: 0.874, training set size: 1930\n",
      "Finished training for epoch 1622, loss: 0.256, accuracy: 0.861, training set size: 1930\n",
      "Finished training for epoch 1623, loss: 0.209, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1624, loss: 0.195, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1625, loss: 0.173, accuracy: 0.913, training set size: 1930\n",
      "Finished training for epoch 1626, loss: 0.168, accuracy: 0.909, training set size: 1930\n",
      "Finished training for epoch 1627, loss: 0.316, accuracy: 0.862, training set size: 1930\n",
      "Finished training for epoch 1628, loss: 0.307, accuracy: 0.849, training set size: 1930\n",
      "Finished training for epoch 1629, loss: 0.199, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1630, loss: 0.177, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1631, loss: 0.194, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1632, loss: 0.184, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1633, loss: 0.175, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1634, loss: 0.175, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1635, loss: 0.210, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1636, loss: 0.213, accuracy: 0.876, training set size: 1930\n",
      "Finished training for epoch 1637, loss: 0.219, accuracy: 0.874, training set size: 1930\n",
      "Finished training for epoch 1638, loss: 0.210, accuracy: 0.886, training set size: 1930\n",
      "Finished training for epoch 1639, loss: 0.184, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1640, loss: 0.173, accuracy: 0.910, training set size: 1930\n",
      "Finished training for epoch 1641, loss: 0.185, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1642, loss: 0.281, accuracy: 0.854, training set size: 1930\n",
      "Finished training for epoch 1643, loss: 0.182, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1644, loss: 0.194, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1645, loss: 0.191, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1646, loss: 0.181, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1647, loss: 0.223, accuracy: 0.872, training set size: 1930\n",
      "Finished training for epoch 1648, loss: 0.188, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1649, loss: 0.231, accuracy: 0.863, training set size: 1930\n",
      "Finished training for epoch 1650, loss: 0.195, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1651, loss: 0.179, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1652, loss: 0.174, accuracy: 0.912, training set size: 1930\n",
      "Finished training for epoch 1653, loss: 0.172, accuracy: 0.906, training set size: 1930\n",
      "Finished training for epoch 1654, loss: 0.184, accuracy: 0.906, training set size: 1930\n",
      "Finished training for epoch 1655, loss: 0.199, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1656, loss: 0.203, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1657, loss: 0.182, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1658, loss: 0.195, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1659, loss: 0.163, accuracy: 0.912, training set size: 1930\n",
      "Finished training for epoch 1660, loss: 0.181, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1661, loss: 0.192, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1662, loss: 0.168, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1663, loss: 0.247, accuracy: 0.870, training set size: 1930\n",
      "Finished training for epoch 1664, loss: 0.224, accuracy: 0.874, training set size: 1930\n",
      "Finished training for epoch 1665, loss: 0.196, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1666, loss: 0.214, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1667, loss: 0.216, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1668, loss: 0.197, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1669, loss: 0.182, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1670, loss: 0.173, accuracy: 0.908, training set size: 1930\n",
      "Finished training for epoch 1671, loss: 0.180, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1672, loss: 0.224, accuracy: 0.878, training set size: 1930\n",
      "Finished training for epoch 1673, loss: 0.230, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1674, loss: 0.185, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1675, loss: 0.202, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1676, loss: 0.199, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1677, loss: 0.179, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1678, loss: 0.189, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1679, loss: 0.173, accuracy: 0.904, training set size: 1930\n",
      "Finished training for epoch 1680, loss: 0.197, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1681, loss: 0.186, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1682, loss: 0.167, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1683, loss: 0.276, accuracy: 0.860, training set size: 1930\n",
      "Finished training for epoch 1684, loss: 0.185, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1685, loss: 0.178, accuracy: 0.904, training set size: 1930\n",
      "Finished training for epoch 1686, loss: 0.206, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1687, loss: 0.176, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1688, loss: 0.214, accuracy: 0.869, training set size: 1930\n",
      "Finished training for epoch 1689, loss: 0.236, accuracy: 0.862, training set size: 1930\n",
      "Finished training for epoch 1690, loss: 0.184, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1691, loss: 0.182, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1692, loss: 0.165, accuracy: 0.910, training set size: 1930\n",
      "Finished training for epoch 1693, loss: 0.215, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1694, loss: 0.230, accuracy: 0.873, training set size: 1930\n",
      "Finished training for epoch 1695, loss: 0.168, accuracy: 0.917, training set size: 1930\n",
      "Finished training for epoch 1696, loss: 0.183, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1697, loss: 0.177, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1698, loss: 0.174, accuracy: 0.908, training set size: 1930\n",
      "Finished training for epoch 1699, loss: 0.173, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1700, loss: 0.214, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1701, loss: 0.319, accuracy: 0.845, training set size: 1930\n",
      "Finished training for epoch 1702, loss: 0.237, accuracy: 0.868, training set size: 1930\n",
      "Finished training for epoch 1703, loss: 0.187, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1704, loss: 0.188, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1705, loss: 0.198, accuracy: 0.887, training set size: 1930\n",
      "Finished training for epoch 1706, loss: 0.194, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1707, loss: 0.246, accuracy: 0.869, training set size: 1930\n",
      "Finished training for epoch 1708, loss: 0.262, accuracy: 0.839, training set size: 1930\n",
      "Finished training for epoch 1709, loss: 0.185, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1710, loss: 0.228, accuracy: 0.869, training set size: 1930\n",
      "Finished training for epoch 1711, loss: 0.190, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1712, loss: 0.179, accuracy: 0.910, training set size: 1930\n",
      "Finished training for epoch 1713, loss: 0.175, accuracy: 0.904, training set size: 1930\n",
      "Finished training for epoch 1714, loss: 0.172, accuracy: 0.908, training set size: 1930\n",
      "Finished training for epoch 1715, loss: 0.197, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1716, loss: 0.230, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1717, loss: 0.191, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1718, loss: 0.188, accuracy: 0.900, training set size: 1930\n",
      "Finished training for epoch 1719, loss: 0.191, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1720, loss: 0.190, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1721, loss: 0.237, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1722, loss: 0.199, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1723, loss: 0.187, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1724, loss: 0.197, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1725, loss: 0.176, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1726, loss: 0.159, accuracy: 0.915, training set size: 1930\n",
      "Finished training for epoch 1727, loss: 0.213, accuracy: 0.887, training set size: 1930\n",
      "Finished training for epoch 1728, loss: 0.206, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1729, loss: 0.182, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1730, loss: 0.189, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1731, loss: 0.264, accuracy: 0.869, training set size: 1930\n",
      "Finished training for epoch 1732, loss: 0.175, accuracy: 0.910, training set size: 1930\n",
      "Finished training for epoch 1733, loss: 0.189, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1734, loss: 0.177, accuracy: 0.907, training set size: 1930\n",
      "Finished training for epoch 1735, loss: 0.211, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1736, loss: 0.164, accuracy: 0.916, training set size: 1930\n",
      "Finished training for epoch 1737, loss: 0.299, accuracy: 0.863, training set size: 1930\n",
      "Finished training for epoch 1738, loss: 0.250, accuracy: 0.859, training set size: 1930\n",
      "Finished training for epoch 1739, loss: 0.209, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1740, loss: 0.181, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1741, loss: 0.199, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1742, loss: 0.209, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1743, loss: 0.234, accuracy: 0.874, training set size: 1930\n",
      "Finished training for epoch 1744, loss: 0.192, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1745, loss: 0.203, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1746, loss: 0.194, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1747, loss: 0.195, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1748, loss: 0.182, accuracy: 0.906, training set size: 1930\n",
      "Finished training for epoch 1749, loss: 0.194, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1750, loss: 0.204, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1751, loss: 0.222, accuracy: 0.878, training set size: 1930\n",
      "Finished training for epoch 1752, loss: 0.209, accuracy: 0.887, training set size: 1930\n",
      "Finished training for epoch 1753, loss: 0.223, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1754, loss: 0.168, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1755, loss: 0.183, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1756, loss: 0.203, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1757, loss: 0.190, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1758, loss: 0.200, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1759, loss: 0.171, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1760, loss: 0.228, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1761, loss: 0.184, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1762, loss: 0.204, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1763, loss: 0.198, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1764, loss: 0.204, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1765, loss: 0.193, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1766, loss: 0.208, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1767, loss: 0.250, accuracy: 0.864, training set size: 1930\n",
      "Finished training for epoch 1768, loss: 0.182, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1769, loss: 0.180, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1770, loss: 0.239, accuracy: 0.869, training set size: 1930\n",
      "Finished training for epoch 1771, loss: 0.213, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1772, loss: 0.195, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1773, loss: 0.171, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1774, loss: 0.176, accuracy: 0.900, training set size: 1930\n",
      "Finished training for epoch 1775, loss: 0.194, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1776, loss: 0.180, accuracy: 0.904, training set size: 1930\n",
      "Finished training for epoch 1777, loss: 0.241, accuracy: 0.866, training set size: 1930\n",
      "Finished training for epoch 1778, loss: 0.187, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1779, loss: 0.198, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1780, loss: 0.155, accuracy: 0.916, training set size: 1930\n",
      "Finished training for epoch 1781, loss: 0.201, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1782, loss: 0.232, accuracy: 0.866, training set size: 1930\n",
      "Finished training for epoch 1783, loss: 0.195, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1784, loss: 0.186, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1785, loss: 0.175, accuracy: 0.904, training set size: 1930\n",
      "Finished training for epoch 1786, loss: 0.168, accuracy: 0.915, training set size: 1930\n",
      "Finished training for epoch 1787, loss: 0.252, accuracy: 0.859, training set size: 1930\n",
      "Finished training for epoch 1788, loss: 0.184, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1789, loss: 0.246, accuracy: 0.872, training set size: 1930\n",
      "Finished training for epoch 1790, loss: 0.192, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1791, loss: 0.229, accuracy: 0.861, training set size: 1930\n",
      "Finished training for epoch 1792, loss: 0.182, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1793, loss: 0.184, accuracy: 0.900, training set size: 1930\n",
      "Finished training for epoch 1794, loss: 0.192, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1795, loss: 0.187, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1796, loss: 0.187, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1797, loss: 0.174, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1798, loss: 0.221, accuracy: 0.874, training set size: 1930\n",
      "Finished training for epoch 1799, loss: 0.192, accuracy: 0.886, training set size: 1930\n",
      "Finished training for epoch 1800, loss: 0.196, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1801, loss: 0.182, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1802, loss: 0.189, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1803, loss: 0.189, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1804, loss: 0.208, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1805, loss: 0.194, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1806, loss: 0.171, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1807, loss: 0.195, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1808, loss: 0.191, accuracy: 0.886, training set size: 1930\n",
      "Finished training for epoch 1809, loss: 0.237, accuracy: 0.868, training set size: 1930\n",
      "Finished training for epoch 1810, loss: 0.168, accuracy: 0.907, training set size: 1930\n",
      "Finished training for epoch 1811, loss: 0.205, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1812, loss: 0.239, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1813, loss: 0.168, accuracy: 0.908, training set size: 1930\n",
      "Finished training for epoch 1814, loss: 0.192, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1815, loss: 0.186, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1816, loss: 0.189, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1817, loss: 0.232, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1818, loss: 0.183, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1819, loss: 0.177, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1820, loss: 0.179, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1821, loss: 0.199, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1822, loss: 0.230, accuracy: 0.869, training set size: 1930\n",
      "Finished training for epoch 1823, loss: 0.223, accuracy: 0.866, training set size: 1930\n",
      "Finished training for epoch 1824, loss: 0.178, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1825, loss: 0.207, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1826, loss: 0.191, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1827, loss: 0.224, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1828, loss: 0.200, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1829, loss: 0.225, accuracy: 0.878, training set size: 1930\n",
      "Finished training for epoch 1830, loss: 0.184, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1831, loss: 0.222, accuracy: 0.880, training set size: 1930\n",
      "Finished training for epoch 1832, loss: 0.180, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1833, loss: 0.202, accuracy: 0.876, training set size: 1930\n",
      "Finished training for epoch 1834, loss: 0.180, accuracy: 0.900, training set size: 1930\n",
      "Finished training for epoch 1835, loss: 0.210, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1836, loss: 0.192, accuracy: 0.887, training set size: 1930\n",
      "Finished training for epoch 1837, loss: 0.164, accuracy: 0.913, training set size: 1930\n",
      "Finished training for epoch 1838, loss: 0.191, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1839, loss: 0.229, accuracy: 0.870, training set size: 1930\n",
      "Finished training for epoch 1840, loss: 0.240, accuracy: 0.862, training set size: 1930\n",
      "Finished training for epoch 1841, loss: 0.180, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1842, loss: 0.220, accuracy: 0.870, training set size: 1930\n",
      "Finished training for epoch 1843, loss: 0.197, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1844, loss: 0.192, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1845, loss: 0.161, accuracy: 0.914, training set size: 1930\n",
      "Finished training for epoch 1846, loss: 0.201, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1847, loss: 0.183, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1848, loss: 0.185, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1849, loss: 0.181, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1850, loss: 0.213, accuracy: 0.890, training set size: 1930\n",
      "Finished training for epoch 1851, loss: 0.168, accuracy: 0.908, training set size: 1930\n",
      "Finished training for epoch 1852, loss: 0.193, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1853, loss: 0.235, accuracy: 0.867, training set size: 1930\n",
      "Finished training for epoch 1854, loss: 0.216, accuracy: 0.878, training set size: 1930\n",
      "Finished training for epoch 1855, loss: 0.197, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1856, loss: 0.309, accuracy: 0.840, training set size: 1930\n",
      "Finished training for epoch 1857, loss: 0.173, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1858, loss: 0.171, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1859, loss: 0.199, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1860, loss: 0.205, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1861, loss: 0.164, accuracy: 0.915, training set size: 1930\n",
      "Finished training for epoch 1862, loss: 0.172, accuracy: 0.909, training set size: 1930\n",
      "Finished training for epoch 1863, loss: 0.187, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1864, loss: 0.191, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1865, loss: 0.227, accuracy: 0.870, training set size: 1930\n",
      "Finished training for epoch 1866, loss: 0.183, accuracy: 0.904, training set size: 1930\n",
      "Finished training for epoch 1867, loss: 0.162, accuracy: 0.914, training set size: 1930\n",
      "Finished training for epoch 1868, loss: 0.230, accuracy: 0.872, training set size: 1930\n",
      "Finished training for epoch 1869, loss: 0.209, accuracy: 0.877, training set size: 1930\n",
      "Finished training for epoch 1870, loss: 0.176, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1871, loss: 0.222, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1872, loss: 0.235, accuracy: 0.864, training set size: 1930\n",
      "Finished training for epoch 1873, loss: 0.176, accuracy: 0.907, training set size: 1930\n",
      "Finished training for epoch 1874, loss: 0.187, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1875, loss: 0.200, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1876, loss: 0.169, accuracy: 0.907, training set size: 1930\n",
      "Finished training for epoch 1877, loss: 0.180, accuracy: 0.904, training set size: 1930\n",
      "Finished training for epoch 1878, loss: 0.163, accuracy: 0.913, training set size: 1930\n",
      "Finished training for epoch 1879, loss: 0.206, accuracy: 0.882, training set size: 1930\n",
      "Finished training for epoch 1880, loss: 0.177, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1881, loss: 0.190, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1882, loss: 0.174, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1883, loss: 0.205, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1884, loss: 0.220, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1885, loss: 0.230, accuracy: 0.875, training set size: 1930\n",
      "Finished training for epoch 1886, loss: 0.180, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1887, loss: 0.192, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1888, loss: 0.241, accuracy: 0.869, training set size: 1930\n",
      "Finished training for epoch 1889, loss: 0.182, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1890, loss: 0.184, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1891, loss: 0.191, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1892, loss: 0.158, accuracy: 0.916, training set size: 1930\n",
      "Finished training for epoch 1893, loss: 0.174, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1894, loss: 0.204, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1895, loss: 0.201, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1896, loss: 0.230, accuracy: 0.872, training set size: 1930\n",
      "Finished training for epoch 1897, loss: 0.214, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1898, loss: 0.168, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1899, loss: 0.182, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1900, loss: 0.244, accuracy: 0.872, training set size: 1930\n",
      "Finished training for epoch 1901, loss: 0.221, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1902, loss: 0.178, accuracy: 0.906, training set size: 1930\n",
      "Finished training for epoch 1903, loss: 0.189, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1904, loss: 0.190, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1905, loss: 0.168, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1906, loss: 0.209, accuracy: 0.881, training set size: 1930\n",
      "Finished training for epoch 1907, loss: 0.225, accuracy: 0.876, training set size: 1930\n",
      "Finished training for epoch 1908, loss: 0.208, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1909, loss: 0.236, accuracy: 0.873, training set size: 1930\n",
      "Finished training for epoch 1910, loss: 0.179, accuracy: 0.906, training set size: 1930\n",
      "Finished training for epoch 1911, loss: 0.222, accuracy: 0.874, training set size: 1930\n",
      "Finished training for epoch 1912, loss: 0.164, accuracy: 0.917, training set size: 1930\n",
      "Finished training for epoch 1913, loss: 0.186, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1914, loss: 0.191, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1915, loss: 0.171, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1916, loss: 0.171, accuracy: 0.907, training set size: 1930\n",
      "Finished training for epoch 1917, loss: 0.210, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1918, loss: 0.336, accuracy: 0.832, training set size: 1930\n",
      "Finished training for epoch 1919, loss: 0.183, accuracy: 0.907, training set size: 1930\n",
      "Finished training for epoch 1920, loss: 0.182, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1921, loss: 0.175, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1922, loss: 0.219, accuracy: 0.883, training set size: 1930\n",
      "Finished training for epoch 1923, loss: 0.177, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1924, loss: 0.182, accuracy: 0.900, training set size: 1930\n",
      "Finished training for epoch 1925, loss: 0.202, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1926, loss: 0.178, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1927, loss: 0.168, accuracy: 0.916, training set size: 1930\n",
      "Finished training for epoch 1928, loss: 0.276, accuracy: 0.862, training set size: 1930\n",
      "Finished training for epoch 1929, loss: 0.191, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1930, loss: 0.184, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1931, loss: 0.184, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1932, loss: 0.180, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1933, loss: 0.173, accuracy: 0.912, training set size: 1930\n",
      "Finished training for epoch 1934, loss: 0.212, accuracy: 0.879, training set size: 1930\n",
      "Finished training for epoch 1935, loss: 0.178, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1936, loss: 0.189, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1937, loss: 0.174, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1938, loss: 0.178, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1939, loss: 0.200, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1940, loss: 0.233, accuracy: 0.869, training set size: 1930\n",
      "Finished training for epoch 1941, loss: 0.234, accuracy: 0.873, training set size: 1930\n",
      "Finished training for epoch 1942, loss: 0.234, accuracy: 0.876, training set size: 1930\n",
      "Finished training for epoch 1943, loss: 0.179, accuracy: 0.900, training set size: 1930\n",
      "Finished training for epoch 1944, loss: 0.163, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1945, loss: 0.193, accuracy: 0.888, training set size: 1930\n",
      "Finished training for epoch 1946, loss: 0.168, accuracy: 0.913, training set size: 1930\n",
      "Finished training for epoch 1947, loss: 0.191, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1948, loss: 0.184, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1949, loss: 0.199, accuracy: 0.887, training set size: 1930\n",
      "Finished training for epoch 1950, loss: 0.192, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1951, loss: 0.203, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1952, loss: 0.168, accuracy: 0.910, training set size: 1930\n",
      "Finished training for epoch 1953, loss: 0.162, accuracy: 0.913, training set size: 1930\n",
      "Finished training for epoch 1954, loss: 0.205, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1955, loss: 0.187, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1956, loss: 0.186, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1957, loss: 0.269, accuracy: 0.869, training set size: 1930\n",
      "Finished training for epoch 1958, loss: 0.230, accuracy: 0.862, training set size: 1930\n",
      "Finished training for epoch 1959, loss: 0.181, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1960, loss: 0.165, accuracy: 0.910, training set size: 1930\n",
      "Finished training for epoch 1961, loss: 0.185, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1962, loss: 0.184, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1963, loss: 0.203, accuracy: 0.894, training set size: 1930\n",
      "Finished training for epoch 1964, loss: 0.165, accuracy: 0.908, training set size: 1930\n",
      "Finished training for epoch 1965, loss: 0.182, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1966, loss: 0.161, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1967, loss: 0.189, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1968, loss: 0.179, accuracy: 0.907, training set size: 1930\n",
      "Finished training for epoch 1969, loss: 0.165, accuracy: 0.911, training set size: 1930\n",
      "Finished training for epoch 1970, loss: 0.186, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1971, loss: 0.178, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1972, loss: 0.186, accuracy: 0.891, training set size: 1930\n",
      "Finished training for epoch 1973, loss: 0.186, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 1974, loss: 0.162, accuracy: 0.917, training set size: 1930\n",
      "Finished training for epoch 1975, loss: 0.177, accuracy: 0.909, training set size: 1930\n",
      "Finished training for epoch 1976, loss: 0.251, accuracy: 0.870, training set size: 1930\n",
      "Finished training for epoch 1977, loss: 0.155, accuracy: 0.920, training set size: 1930\n",
      "Finished training for epoch 1978, loss: 0.178, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1979, loss: 0.181, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1980, loss: 0.179, accuracy: 0.892, training set size: 1930\n",
      "Finished training for epoch 1981, loss: 0.177, accuracy: 0.905, training set size: 1930\n",
      "Finished training for epoch 1982, loss: 0.192, accuracy: 0.898, training set size: 1930\n",
      "Finished training for epoch 1983, loss: 0.197, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1984, loss: 0.171, accuracy: 0.901, training set size: 1930\n",
      "Finished training for epoch 1985, loss: 0.162, accuracy: 0.912, training set size: 1930\n",
      "Finished training for epoch 1986, loss: 0.155, accuracy: 0.918, training set size: 1930\n",
      "Finished training for epoch 1987, loss: 0.175, accuracy: 0.899, training set size: 1930\n",
      "Finished training for epoch 1988, loss: 0.173, accuracy: 0.904, training set size: 1930\n",
      "Finished training for epoch 1989, loss: 0.175, accuracy: 0.902, training set size: 1930\n",
      "Finished training for epoch 1990, loss: 0.203, accuracy: 0.885, training set size: 1930\n",
      "Finished training for epoch 1991, loss: 0.177, accuracy: 0.896, training set size: 1930\n",
      "Finished training for epoch 1992, loss: 0.211, accuracy: 0.887, training set size: 1930\n",
      "Finished training for epoch 1993, loss: 0.183, accuracy: 0.893, training set size: 1930\n",
      "Finished training for epoch 1994, loss: 0.169, accuracy: 0.903, training set size: 1930\n",
      "Finished training for epoch 1995, loss: 0.212, accuracy: 0.884, training set size: 1930\n",
      "Finished training for epoch 1996, loss: 0.180, accuracy: 0.895, training set size: 1930\n",
      "Finished training for epoch 1997, loss: 0.193, accuracy: 0.889, training set size: 1930\n",
      "Finished training for epoch 1998, loss: 0.168, accuracy: 0.909, training set size: 1930\n",
      "Finished training for epoch 1999, loss: 0.208, accuracy: 0.887, training set size: 1930\n",
      "Finished training for epoch 2000, loss: 0.177, accuracy: 0.897, training set size: 1930\n",
      "Finished training for epoch 2001, loss: 0.228, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2002, loss: 0.309, accuracy: 0.813, training set size: 2129\n",
      "Finished training for epoch 2003, loss: 0.233, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2004, loss: 0.221, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2005, loss: 0.256, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2006, loss: 0.228, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2007, loss: 0.229, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2008, loss: 0.254, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2009, loss: 0.223, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2010, loss: 0.250, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2011, loss: 0.225, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2012, loss: 0.274, accuracy: 0.816, training set size: 2129\n",
      "Finished training for epoch 2013, loss: 0.274, accuracy: 0.814, training set size: 2129\n",
      "Finished training for epoch 2014, loss: 0.228, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2015, loss: 0.222, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2016, loss: 0.238, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2017, loss: 0.227, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2018, loss: 0.282, accuracy: 0.817, training set size: 2129\n",
      "Finished training for epoch 2019, loss: 0.243, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2020, loss: 0.220, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2021, loss: 0.232, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2022, loss: 0.220, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2023, loss: 0.224, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2024, loss: 0.225, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2025, loss: 0.262, accuracy: 0.822, training set size: 2129\n",
      "Finished training for epoch 2026, loss: 0.252, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2027, loss: 0.236, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2028, loss: 0.237, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2029, loss: 0.249, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2030, loss: 0.236, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2031, loss: 0.221, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2032, loss: 0.239, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2033, loss: 0.267, accuracy: 0.825, training set size: 2129\n",
      "Finished training for epoch 2034, loss: 0.249, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2035, loss: 0.224, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2036, loss: 0.238, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2037, loss: 0.237, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2038, loss: 0.224, accuracy: 0.855, training set size: 2129\n",
      "Finished training for epoch 2039, loss: 0.252, accuracy: 0.823, training set size: 2129\n",
      "Finished training for epoch 2040, loss: 0.266, accuracy: 0.820, training set size: 2129\n",
      "Finished training for epoch 2041, loss: 0.293, accuracy: 0.803, training set size: 2129\n",
      "Finished training for epoch 2042, loss: 0.234, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2043, loss: 0.222, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2044, loss: 0.218, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2045, loss: 0.233, accuracy: 0.835, training set size: 2129\n",
      "Finished training for epoch 2046, loss: 0.227, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2047, loss: 0.255, accuracy: 0.825, training set size: 2129\n",
      "Finished training for epoch 2048, loss: 0.257, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2049, loss: 0.209, accuracy: 0.860, training set size: 2129\n",
      "Finished training for epoch 2050, loss: 0.257, accuracy: 0.824, training set size: 2129\n",
      "Finished training for epoch 2051, loss: 0.227, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2052, loss: 0.255, accuracy: 0.822, training set size: 2129\n",
      "Finished training for epoch 2053, loss: 0.222, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2054, loss: 0.216, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2055, loss: 0.212, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2056, loss: 0.217, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2057, loss: 0.275, accuracy: 0.818, training set size: 2129\n",
      "Finished training for epoch 2058, loss: 0.220, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2059, loss: 0.230, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2060, loss: 0.230, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2061, loss: 0.240, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2062, loss: 0.261, accuracy: 0.820, training set size: 2129\n",
      "Finished training for epoch 2063, loss: 0.242, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2064, loss: 0.230, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2065, loss: 0.225, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2066, loss: 0.264, accuracy: 0.820, training set size: 2129\n",
      "Finished training for epoch 2067, loss: 0.232, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2068, loss: 0.236, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2069, loss: 0.232, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2070, loss: 0.235, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2071, loss: 0.249, accuracy: 0.820, training set size: 2129\n",
      "Finished training for epoch 2072, loss: 0.215, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2073, loss: 0.258, accuracy: 0.823, training set size: 2129\n",
      "Finished training for epoch 2074, loss: 0.242, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2075, loss: 0.261, accuracy: 0.821, training set size: 2129\n",
      "Finished training for epoch 2076, loss: 0.231, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2077, loss: 0.230, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2078, loss: 0.232, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2079, loss: 0.264, accuracy: 0.826, training set size: 2129\n",
      "Finished training for epoch 2080, loss: 0.237, accuracy: 0.835, training set size: 2129\n",
      "Finished training for epoch 2081, loss: 0.293, accuracy: 0.808, training set size: 2129\n",
      "Finished training for epoch 2082, loss: 0.230, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2083, loss: 0.232, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2084, loss: 0.254, accuracy: 0.824, training set size: 2129\n",
      "Finished training for epoch 2085, loss: 0.280, accuracy: 0.808, training set size: 2129\n",
      "Finished training for epoch 2086, loss: 0.248, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2087, loss: 0.221, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2088, loss: 0.221, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2089, loss: 0.270, accuracy: 0.819, training set size: 2129\n",
      "Finished training for epoch 2090, loss: 0.256, accuracy: 0.826, training set size: 2129\n",
      "Finished training for epoch 2091, loss: 0.258, accuracy: 0.825, training set size: 2129\n",
      "Finished training for epoch 2092, loss: 0.321, accuracy: 0.801, training set size: 2129\n",
      "Finished training for epoch 2093, loss: 0.234, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2094, loss: 0.252, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2095, loss: 0.243, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2096, loss: 0.239, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2097, loss: 0.230, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2098, loss: 0.253, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2099, loss: 0.230, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2100, loss: 0.223, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2101, loss: 0.232, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2102, loss: 0.269, accuracy: 0.822, training set size: 2129\n",
      "Finished training for epoch 2103, loss: 0.220, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2104, loss: 0.237, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2105, loss: 0.227, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2106, loss: 0.232, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2107, loss: 0.269, accuracy: 0.816, training set size: 2129\n",
      "Finished training for epoch 2108, loss: 0.212, accuracy: 0.855, training set size: 2129\n",
      "Finished training for epoch 2109, loss: 0.237, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2110, loss: 0.260, accuracy: 0.822, training set size: 2129\n",
      "Finished training for epoch 2111, loss: 0.250, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2112, loss: 0.252, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2113, loss: 0.211, accuracy: 0.858, training set size: 2129\n",
      "Finished training for epoch 2114, loss: 0.238, accuracy: 0.835, training set size: 2129\n",
      "Finished training for epoch 2115, loss: 0.225, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2116, loss: 0.216, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2117, loss: 0.215, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2118, loss: 0.258, accuracy: 0.826, training set size: 2129\n",
      "Finished training for epoch 2119, loss: 0.222, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2120, loss: 0.252, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2121, loss: 0.239, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2122, loss: 0.230, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2123, loss: 0.224, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2124, loss: 0.223, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2125, loss: 0.242, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2126, loss: 0.260, accuracy: 0.822, training set size: 2129\n",
      "Finished training for epoch 2127, loss: 0.218, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2128, loss: 0.252, accuracy: 0.822, training set size: 2129\n",
      "Finished training for epoch 2129, loss: 0.234, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2130, loss: 0.241, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2131, loss: 0.214, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2132, loss: 0.240, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2133, loss: 0.214, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2134, loss: 0.232, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2135, loss: 0.223, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2136, loss: 0.237, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2137, loss: 0.235, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2138, loss: 0.234, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2139, loss: 0.237, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2140, loss: 0.213, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2141, loss: 0.276, accuracy: 0.821, training set size: 2129\n",
      "Finished training for epoch 2142, loss: 0.238, accuracy: 0.830, training set size: 2129\n",
      "Finished training for epoch 2143, loss: 0.219, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2144, loss: 0.245, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2145, loss: 0.234, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2146, loss: 0.230, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2147, loss: 0.229, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2148, loss: 0.250, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2149, loss: 0.230, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2150, loss: 0.219, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2151, loss: 0.244, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2152, loss: 0.237, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2153, loss: 0.388, accuracy: 0.775, training set size: 2129\n",
      "Finished training for epoch 2154, loss: 0.245, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2155, loss: 0.233, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2156, loss: 0.235, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2157, loss: 0.254, accuracy: 0.825, training set size: 2129\n",
      "Finished training for epoch 2158, loss: 0.240, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2159, loss: 0.274, accuracy: 0.814, training set size: 2129\n",
      "Finished training for epoch 2160, loss: 0.243, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2161, loss: 0.255, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2162, loss: 0.236, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2163, loss: 0.236, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2164, loss: 0.219, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2165, loss: 0.235, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2166, loss: 0.234, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2167, loss: 0.252, accuracy: 0.822, training set size: 2129\n",
      "Finished training for epoch 2168, loss: 0.248, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2169, loss: 0.229, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2170, loss: 0.250, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2171, loss: 0.237, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2172, loss: 0.246, accuracy: 0.830, training set size: 2129\n",
      "Finished training for epoch 2173, loss: 0.274, accuracy: 0.816, training set size: 2129\n",
      "Finished training for epoch 2174, loss: 0.222, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2175, loss: 0.262, accuracy: 0.830, training set size: 2129\n",
      "Finished training for epoch 2176, loss: 0.219, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2177, loss: 0.219, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2178, loss: 0.214, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2179, loss: 0.221, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2180, loss: 0.271, accuracy: 0.823, training set size: 2129\n",
      "Finished training for epoch 2181, loss: 0.228, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2182, loss: 0.234, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2183, loss: 0.213, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2184, loss: 0.217, accuracy: 0.855, training set size: 2129\n",
      "Finished training for epoch 2185, loss: 0.217, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2186, loss: 0.283, accuracy: 0.815, training set size: 2129\n",
      "Finished training for epoch 2187, loss: 0.236, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2188, loss: 0.219, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2189, loss: 0.232, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2190, loss: 0.246, accuracy: 0.830, training set size: 2129\n",
      "Finished training for epoch 2191, loss: 0.227, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2192, loss: 0.228, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2193, loss: 0.239, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2194, loss: 0.242, accuracy: 0.830, training set size: 2129\n",
      "Finished training for epoch 2195, loss: 0.229, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2196, loss: 0.233, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2197, loss: 0.214, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2198, loss: 0.270, accuracy: 0.824, training set size: 2129\n",
      "Finished training for epoch 2199, loss: 0.206, accuracy: 0.863, training set size: 2129\n",
      "Finished training for epoch 2200, loss: 0.215, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2201, loss: 0.253, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2202, loss: 0.314, accuracy: 0.805, training set size: 2129\n",
      "Finished training for epoch 2203, loss: 0.241, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2204, loss: 0.252, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2205, loss: 0.245, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2206, loss: 0.227, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2207, loss: 0.212, accuracy: 0.857, training set size: 2129\n",
      "Finished training for epoch 2208, loss: 0.256, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2209, loss: 0.211, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2210, loss: 0.221, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2211, loss: 0.228, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2212, loss: 0.228, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2213, loss: 0.221, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2214, loss: 0.206, accuracy: 0.858, training set size: 2129\n",
      "Finished training for epoch 2215, loss: 0.210, accuracy: 0.857, training set size: 2129\n",
      "Finished training for epoch 2216, loss: 0.229, accuracy: 0.835, training set size: 2129\n",
      "Finished training for epoch 2217, loss: 0.243, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2218, loss: 0.221, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2219, loss: 0.248, accuracy: 0.830, training set size: 2129\n",
      "Finished training for epoch 2220, loss: 0.245, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2221, loss: 0.249, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2222, loss: 0.223, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2223, loss: 0.217, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2224, loss: 0.237, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2225, loss: 0.226, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2226, loss: 0.220, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2227, loss: 0.240, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2228, loss: 0.239, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2229, loss: 0.231, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2230, loss: 0.239, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2231, loss: 0.235, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2232, loss: 0.258, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2233, loss: 0.240, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2234, loss: 0.207, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2235, loss: 0.229, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2236, loss: 0.221, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2237, loss: 0.216, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2238, loss: 0.232, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2239, loss: 0.311, accuracy: 0.810, training set size: 2129\n",
      "Finished training for epoch 2240, loss: 0.221, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2241, loss: 0.216, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2242, loss: 0.213, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2243, loss: 0.251, accuracy: 0.825, training set size: 2129\n",
      "Finished training for epoch 2244, loss: 0.235, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2245, loss: 0.221, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2246, loss: 0.244, accuracy: 0.824, training set size: 2129\n",
      "Finished training for epoch 2247, loss: 0.240, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2248, loss: 0.220, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2249, loss: 0.241, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2250, loss: 0.237, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2251, loss: 0.245, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2252, loss: 0.212, accuracy: 0.855, training set size: 2129\n",
      "Finished training for epoch 2253, loss: 0.236, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2254, loss: 0.290, accuracy: 0.808, training set size: 2129\n",
      "Finished training for epoch 2255, loss: 0.267, accuracy: 0.819, training set size: 2129\n",
      "Finished training for epoch 2256, loss: 0.245, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2257, loss: 0.236, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2258, loss: 0.226, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2259, loss: 0.237, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2260, loss: 0.223, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2261, loss: 0.250, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2262, loss: 0.237, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2263, loss: 0.265, accuracy: 0.822, training set size: 2129\n",
      "Finished training for epoch 2264, loss: 0.238, accuracy: 0.830, training set size: 2129\n",
      "Finished training for epoch 2265, loss: 0.215, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2266, loss: 0.222, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2267, loss: 0.233, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2268, loss: 0.230, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2269, loss: 0.315, accuracy: 0.808, training set size: 2129\n",
      "Finished training for epoch 2270, loss: 0.230, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2271, loss: 0.203, accuracy: 0.866, training set size: 2129\n",
      "Finished training for epoch 2272, loss: 0.223, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2273, loss: 0.219, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2274, loss: 0.251, accuracy: 0.826, training set size: 2129\n",
      "Finished training for epoch 2275, loss: 0.218, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2276, loss: 0.226, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2277, loss: 0.236, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2278, loss: 0.211, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2279, loss: 0.249, accuracy: 0.825, training set size: 2129\n",
      "Finished training for epoch 2280, loss: 0.231, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2281, loss: 0.270, accuracy: 0.812, training set size: 2129\n",
      "Finished training for epoch 2282, loss: 0.213, accuracy: 0.859, training set size: 2129\n",
      "Finished training for epoch 2283, loss: 0.228, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2284, loss: 0.219, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2285, loss: 0.206, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2286, loss: 0.228, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2287, loss: 0.252, accuracy: 0.825, training set size: 2129\n",
      "Finished training for epoch 2288, loss: 0.282, accuracy: 0.816, training set size: 2129\n",
      "Finished training for epoch 2289, loss: 0.223, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2290, loss: 0.271, accuracy: 0.807, training set size: 2129\n",
      "Finished training for epoch 2291, loss: 0.244, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2292, loss: 0.219, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2293, loss: 0.249, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2294, loss: 0.217, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2295, loss: 0.249, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2296, loss: 0.218, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2297, loss: 0.225, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2298, loss: 0.224, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2299, loss: 0.231, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2300, loss: 0.243, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2301, loss: 0.299, accuracy: 0.808, training set size: 2129\n",
      "Finished training for epoch 2302, loss: 0.216, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2303, loss: 0.234, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2304, loss: 0.230, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2305, loss: 0.230, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2306, loss: 0.364, accuracy: 0.780, training set size: 2129\n",
      "Finished training for epoch 2307, loss: 0.248, accuracy: 0.825, training set size: 2129\n",
      "Finished training for epoch 2308, loss: 0.237, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2309, loss: 0.227, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2310, loss: 0.224, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2311, loss: 0.248, accuracy: 0.825, training set size: 2129\n",
      "Finished training for epoch 2312, loss: 0.245, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2313, loss: 0.244, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2314, loss: 0.226, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2315, loss: 0.233, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2316, loss: 0.214, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2317, loss: 0.217, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2318, loss: 0.221, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2319, loss: 0.211, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2320, loss: 0.264, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2321, loss: 0.269, accuracy: 0.815, training set size: 2129\n",
      "Finished training for epoch 2322, loss: 0.217, accuracy: 0.857, training set size: 2129\n",
      "Finished training for epoch 2323, loss: 0.289, accuracy: 0.815, training set size: 2129\n",
      "Finished training for epoch 2324, loss: 0.230, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2325, loss: 0.229, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2326, loss: 0.277, accuracy: 0.817, training set size: 2129\n",
      "Finished training for epoch 2327, loss: 0.236, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2328, loss: 0.208, accuracy: 0.861, training set size: 2129\n",
      "Finished training for epoch 2329, loss: 0.241, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2330, loss: 0.231, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2331, loss: 0.258, accuracy: 0.822, training set size: 2129\n",
      "Finished training for epoch 2332, loss: 0.235, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2333, loss: 0.233, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2334, loss: 0.227, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2335, loss: 0.241, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2336, loss: 0.220, accuracy: 0.856, training set size: 2129\n",
      "Finished training for epoch 2337, loss: 0.230, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2338, loss: 0.216, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2339, loss: 0.240, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2340, loss: 0.216, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2341, loss: 0.238, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2342, loss: 0.214, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2343, loss: 0.229, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2344, loss: 0.250, accuracy: 0.826, training set size: 2129\n",
      "Finished training for epoch 2345, loss: 0.241, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2346, loss: 0.207, accuracy: 0.858, training set size: 2129\n",
      "Finished training for epoch 2347, loss: 0.220, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2348, loss: 0.232, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2349, loss: 0.229, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2350, loss: 0.273, accuracy: 0.815, training set size: 2129\n",
      "Finished training for epoch 2351, loss: 0.239, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2352, loss: 0.252, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2353, loss: 0.218, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2354, loss: 0.209, accuracy: 0.858, training set size: 2129\n",
      "Finished training for epoch 2355, loss: 0.219, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2356, loss: 0.240, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2357, loss: 0.222, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2358, loss: 0.258, accuracy: 0.817, training set size: 2129\n",
      "Finished training for epoch 2359, loss: 0.263, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2360, loss: 0.249, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2361, loss: 0.268, accuracy: 0.814, training set size: 2129\n",
      "Finished training for epoch 2362, loss: 0.228, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2363, loss: 0.237, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2364, loss: 0.223, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2365, loss: 0.230, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2366, loss: 0.215, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2367, loss: 0.223, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2368, loss: 0.247, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2369, loss: 0.225, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2370, loss: 0.222, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2371, loss: 0.236, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2372, loss: 0.347, accuracy: 0.791, training set size: 2129\n",
      "Finished training for epoch 2373, loss: 0.232, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2374, loss: 0.226, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2375, loss: 0.222, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2376, loss: 0.223, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2377, loss: 0.254, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2378, loss: 0.217, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2379, loss: 0.271, accuracy: 0.814, training set size: 2129\n",
      "Finished training for epoch 2380, loss: 0.242, accuracy: 0.826, training set size: 2129\n",
      "Finished training for epoch 2381, loss: 0.245, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2382, loss: 0.210, accuracy: 0.857, training set size: 2129\n",
      "Finished training for epoch 2383, loss: 0.215, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2384, loss: 0.245, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2385, loss: 0.241, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2386, loss: 0.233, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2387, loss: 0.241, accuracy: 0.825, training set size: 2129\n",
      "Finished training for epoch 2388, loss: 0.214, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2389, loss: 0.241, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2390, loss: 0.263, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2391, loss: 0.230, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2392, loss: 0.214, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2393, loss: 0.246, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2394, loss: 0.219, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2395, loss: 0.235, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2396, loss: 0.221, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2397, loss: 0.231, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2398, loss: 0.228, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2399, loss: 0.233, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2400, loss: 0.219, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2401, loss: 0.221, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2402, loss: 0.228, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2403, loss: 0.233, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2404, loss: 0.244, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2405, loss: 0.215, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2406, loss: 0.215, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2407, loss: 0.216, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2408, loss: 0.204, accuracy: 0.858, training set size: 2129\n",
      "Finished training for epoch 2409, loss: 0.238, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2410, loss: 0.273, accuracy: 0.820, training set size: 2129\n",
      "Finished training for epoch 2411, loss: 0.237, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2412, loss: 0.238, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2413, loss: 0.242, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2414, loss: 0.258, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2415, loss: 0.216, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2416, loss: 0.243, accuracy: 0.826, training set size: 2129\n",
      "Finished training for epoch 2417, loss: 0.224, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2418, loss: 0.232, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2419, loss: 0.223, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2420, loss: 0.222, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2421, loss: 0.207, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2422, loss: 0.241, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2423, loss: 0.232, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2424, loss: 0.286, accuracy: 0.817, training set size: 2129\n",
      "Finished training for epoch 2425, loss: 0.217, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2426, loss: 0.212, accuracy: 0.856, training set size: 2129\n",
      "Finished training for epoch 2427, loss: 0.244, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2428, loss: 0.204, accuracy: 0.861, training set size: 2129\n",
      "Finished training for epoch 2429, loss: 0.296, accuracy: 0.814, training set size: 2129\n",
      "Finished training for epoch 2430, loss: 0.243, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2431, loss: 0.222, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2432, loss: 0.248, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2433, loss: 0.238, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2434, loss: 0.249, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2435, loss: 0.256, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2436, loss: 0.229, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2437, loss: 0.235, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2438, loss: 0.230, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2439, loss: 0.216, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2440, loss: 0.216, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2441, loss: 0.226, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2442, loss: 0.227, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2443, loss: 0.284, accuracy: 0.817, training set size: 2129\n",
      "Finished training for epoch 2444, loss: 0.234, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2445, loss: 0.217, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2446, loss: 0.249, accuracy: 0.826, training set size: 2129\n",
      "Finished training for epoch 2447, loss: 0.240, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2448, loss: 0.249, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2449, loss: 0.239, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2450, loss: 0.226, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2451, loss: 0.213, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2452, loss: 0.219, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2453, loss: 0.258, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2454, loss: 0.300, accuracy: 0.803, training set size: 2129\n",
      "Finished training for epoch 2455, loss: 0.223, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2456, loss: 0.235, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2457, loss: 0.252, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2458, loss: 0.228, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2459, loss: 0.217, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2460, loss: 0.223, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2461, loss: 0.244, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2462, loss: 0.231, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2463, loss: 0.218, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2464, loss: 0.234, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2465, loss: 0.213, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2466, loss: 0.228, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2467, loss: 0.295, accuracy: 0.819, training set size: 2129\n",
      "Finished training for epoch 2468, loss: 0.222, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2469, loss: 0.259, accuracy: 0.822, training set size: 2129\n",
      "Finished training for epoch 2470, loss: 0.219, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2471, loss: 0.210, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2472, loss: 0.232, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2473, loss: 0.219, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2474, loss: 0.344, accuracy: 0.793, training set size: 2129\n",
      "Finished training for epoch 2475, loss: 0.232, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2476, loss: 0.214, accuracy: 0.855, training set size: 2129\n",
      "Finished training for epoch 2477, loss: 0.225, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2478, loss: 0.263, accuracy: 0.818, training set size: 2129\n",
      "Finished training for epoch 2479, loss: 0.268, accuracy: 0.812, training set size: 2129\n",
      "Finished training for epoch 2480, loss: 0.220, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2481, loss: 0.218, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2482, loss: 0.247, accuracy: 0.826, training set size: 2129\n",
      "Finished training for epoch 2483, loss: 0.252, accuracy: 0.823, training set size: 2129\n",
      "Finished training for epoch 2484, loss: 0.214, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2485, loss: 0.216, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2486, loss: 0.208, accuracy: 0.862, training set size: 2129\n",
      "Finished training for epoch 2487, loss: 0.215, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2488, loss: 0.288, accuracy: 0.808, training set size: 2129\n",
      "Finished training for epoch 2489, loss: 0.249, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2490, loss: 0.231, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2491, loss: 0.234, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2492, loss: 0.216, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2493, loss: 0.256, accuracy: 0.825, training set size: 2129\n",
      "Finished training for epoch 2494, loss: 0.241, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2495, loss: 0.256, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2496, loss: 0.226, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2497, loss: 0.235, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2498, loss: 0.224, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2499, loss: 0.250, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2500, loss: 0.222, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2501, loss: 0.228, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2502, loss: 0.223, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2503, loss: 0.250, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2504, loss: 0.242, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2505, loss: 0.253, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2506, loss: 0.244, accuracy: 0.830, training set size: 2129\n",
      "Finished training for epoch 2507, loss: 0.239, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2508, loss: 0.217, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2509, loss: 0.238, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2510, loss: 0.230, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2511, loss: 0.219, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2512, loss: 0.221, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2513, loss: 0.212, accuracy: 0.855, training set size: 2129\n",
      "Finished training for epoch 2514, loss: 0.236, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2515, loss: 0.232, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2516, loss: 0.284, accuracy: 0.823, training set size: 2129\n",
      "Finished training for epoch 2517, loss: 0.269, accuracy: 0.815, training set size: 2129\n",
      "Finished training for epoch 2518, loss: 0.222, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2519, loss: 0.232, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2520, loss: 0.234, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2521, loss: 0.247, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2522, loss: 0.217, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2523, loss: 0.258, accuracy: 0.818, training set size: 2129\n",
      "Finished training for epoch 2524, loss: 0.247, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2525, loss: 0.209, accuracy: 0.859, training set size: 2129\n",
      "Finished training for epoch 2526, loss: 0.218, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2527, loss: 0.222, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2528, loss: 0.220, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2529, loss: 0.201, accuracy: 0.858, training set size: 2129\n",
      "Finished training for epoch 2530, loss: 0.208, accuracy: 0.855, training set size: 2129\n",
      "Finished training for epoch 2531, loss: 0.225, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2532, loss: 0.303, accuracy: 0.816, training set size: 2129\n",
      "Finished training for epoch 2533, loss: 0.275, accuracy: 0.819, training set size: 2129\n",
      "Finished training for epoch 2534, loss: 0.225, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2535, loss: 0.215, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2536, loss: 0.199, accuracy: 0.860, training set size: 2129\n",
      "Finished training for epoch 2537, loss: 0.222, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2538, loss: 0.241, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2539, loss: 0.252, accuracy: 0.824, training set size: 2129\n",
      "Finished training for epoch 2540, loss: 0.230, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2541, loss: 0.225, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2542, loss: 0.225, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2543, loss: 0.203, accuracy: 0.860, training set size: 2129\n",
      "Finished training for epoch 2544, loss: 0.247, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2545, loss: 0.210, accuracy: 0.859, training set size: 2129\n",
      "Finished training for epoch 2546, loss: 0.231, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2547, loss: 0.306, accuracy: 0.802, training set size: 2129\n",
      "Finished training for epoch 2548, loss: 0.232, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2549, loss: 0.249, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2550, loss: 0.270, accuracy: 0.825, training set size: 2129\n",
      "Finished training for epoch 2551, loss: 0.221, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2552, loss: 0.236, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2553, loss: 0.220, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2554, loss: 0.224, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2555, loss: 0.225, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2556, loss: 0.215, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2557, loss: 0.254, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2558, loss: 0.229, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2559, loss: 0.229, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2560, loss: 0.223, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2561, loss: 0.217, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2562, loss: 0.255, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2563, loss: 0.211, accuracy: 0.856, training set size: 2129\n",
      "Finished training for epoch 2564, loss: 0.224, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2565, loss: 0.221, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2566, loss: 0.216, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2567, loss: 0.209, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2568, loss: 0.227, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2569, loss: 0.288, accuracy: 0.815, training set size: 2129\n",
      "Finished training for epoch 2570, loss: 0.235, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2571, loss: 0.240, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2572, loss: 0.233, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2573, loss: 0.212, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2574, loss: 0.233, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2575, loss: 0.224, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2576, loss: 0.218, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2577, loss: 0.224, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2578, loss: 0.238, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2579, loss: 0.236, accuracy: 0.835, training set size: 2129\n",
      "Finished training for epoch 2580, loss: 0.215, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2581, loss: 0.229, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2582, loss: 0.238, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2583, loss: 0.235, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2584, loss: 0.228, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2585, loss: 0.214, accuracy: 0.856, training set size: 2129\n",
      "Finished training for epoch 2586, loss: 0.296, accuracy: 0.807, training set size: 2129\n",
      "Finished training for epoch 2587, loss: 0.221, accuracy: 0.857, training set size: 2129\n",
      "Finished training for epoch 2588, loss: 0.222, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2589, loss: 0.237, accuracy: 0.835, training set size: 2129\n",
      "Finished training for epoch 2590, loss: 0.217, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2591, loss: 0.226, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2592, loss: 0.211, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2593, loss: 0.215, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2594, loss: 0.220, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2595, loss: 0.261, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2596, loss: 0.212, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2597, loss: 0.256, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2598, loss: 0.226, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2599, loss: 0.226, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2600, loss: 0.219, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2601, loss: 0.231, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2602, loss: 0.224, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2603, loss: 0.224, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2604, loss: 0.239, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2605, loss: 0.235, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2606, loss: 0.236, accuracy: 0.835, training set size: 2129\n",
      "Finished training for epoch 2607, loss: 0.287, accuracy: 0.814, training set size: 2129\n",
      "Finished training for epoch 2608, loss: 0.243, accuracy: 0.830, training set size: 2129\n",
      "Finished training for epoch 2609, loss: 0.224, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2610, loss: 0.256, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2611, loss: 0.226, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2612, loss: 0.207, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2613, loss: 0.208, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2614, loss: 0.249, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2615, loss: 0.204, accuracy: 0.862, training set size: 2129\n",
      "Finished training for epoch 2616, loss: 0.251, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2617, loss: 0.225, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2618, loss: 0.239, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2619, loss: 0.214, accuracy: 0.855, training set size: 2129\n",
      "Finished training for epoch 2620, loss: 0.201, accuracy: 0.860, training set size: 2129\n",
      "Finished training for epoch 2621, loss: 0.255, accuracy: 0.824, training set size: 2129\n",
      "Finished training for epoch 2622, loss: 0.255, accuracy: 0.826, training set size: 2129\n",
      "Finished training for epoch 2623, loss: 0.225, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2624, loss: 0.237, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2625, loss: 0.229, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2626, loss: 0.232, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2627, loss: 0.260, accuracy: 0.830, training set size: 2129\n",
      "Finished training for epoch 2628, loss: 0.225, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2629, loss: 0.206, accuracy: 0.857, training set size: 2129\n",
      "Finished training for epoch 2630, loss: 0.264, accuracy: 0.818, training set size: 2129\n",
      "Finished training for epoch 2631, loss: 0.224, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2632, loss: 0.230, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2633, loss: 0.227, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2634, loss: 0.228, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2635, loss: 0.215, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2636, loss: 0.231, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2637, loss: 0.231, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2638, loss: 0.218, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2639, loss: 0.238, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2640, loss: 0.219, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2641, loss: 0.225, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2642, loss: 0.273, accuracy: 0.825, training set size: 2129\n",
      "Finished training for epoch 2643, loss: 0.228, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2644, loss: 0.220, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2645, loss: 0.221, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2646, loss: 0.261, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2647, loss: 0.220, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2648, loss: 0.209, accuracy: 0.856, training set size: 2129\n",
      "Finished training for epoch 2649, loss: 0.216, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2650, loss: 0.245, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2651, loss: 0.222, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2652, loss: 0.238, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2653, loss: 0.233, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2654, loss: 0.236, accuracy: 0.835, training set size: 2129\n",
      "Finished training for epoch 2655, loss: 0.236, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2656, loss: 0.224, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2657, loss: 0.235, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2658, loss: 0.226, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2659, loss: 0.250, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2660, loss: 0.294, accuracy: 0.807, training set size: 2129\n",
      "Finished training for epoch 2661, loss: 0.238, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2662, loss: 0.210, accuracy: 0.856, training set size: 2129\n",
      "Finished training for epoch 2663, loss: 0.219, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2664, loss: 0.222, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2665, loss: 0.246, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2666, loss: 0.241, accuracy: 0.826, training set size: 2129\n",
      "Finished training for epoch 2667, loss: 0.214, accuracy: 0.855, training set size: 2129\n",
      "Finished training for epoch 2668, loss: 0.216, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2669, loss: 0.213, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2670, loss: 0.238, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2671, loss: 0.228, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2672, loss: 0.229, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2673, loss: 0.257, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2674, loss: 0.222, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2675, loss: 0.226, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2676, loss: 0.222, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2677, loss: 0.235, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2678, loss: 0.246, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2679, loss: 0.211, accuracy: 0.856, training set size: 2129\n",
      "Finished training for epoch 2680, loss: 0.222, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2681, loss: 0.215, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2682, loss: 0.227, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2683, loss: 0.243, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2684, loss: 0.219, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2685, loss: 0.206, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2686, loss: 0.209, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2687, loss: 0.257, accuracy: 0.821, training set size: 2129\n",
      "Finished training for epoch 2688, loss: 0.311, accuracy: 0.808, training set size: 2129\n",
      "Finished training for epoch 2689, loss: 0.235, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2690, loss: 0.222, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2691, loss: 0.237, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2692, loss: 0.224, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2693, loss: 0.236, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2694, loss: 0.226, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2695, loss: 0.225, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2696, loss: 0.224, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2697, loss: 0.261, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2698, loss: 0.237, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2699, loss: 0.226, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2700, loss: 0.212, accuracy: 0.856, training set size: 2129\n",
      "Finished training for epoch 2701, loss: 0.220, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2702, loss: 0.230, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2703, loss: 0.215, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2704, loss: 0.226, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2705, loss: 0.286, accuracy: 0.818, training set size: 2129\n",
      "Finished training for epoch 2706, loss: 0.239, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2707, loss: 0.229, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2708, loss: 0.211, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2709, loss: 0.221, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2710, loss: 0.258, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2711, loss: 0.230, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2712, loss: 0.252, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2713, loss: 0.274, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2714, loss: 0.232, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2715, loss: 0.219, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2716, loss: 0.224, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2717, loss: 0.212, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2718, loss: 0.258, accuracy: 0.822, training set size: 2129\n",
      "Finished training for epoch 2719, loss: 0.209, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2720, loss: 0.211, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2721, loss: 0.252, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2722, loss: 0.263, accuracy: 0.830, training set size: 2129\n",
      "Finished training for epoch 2723, loss: 0.240, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2724, loss: 0.221, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2725, loss: 0.246, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2726, loss: 0.280, accuracy: 0.815, training set size: 2129\n",
      "Finished training for epoch 2727, loss: 0.242, accuracy: 0.826, training set size: 2129\n",
      "Finished training for epoch 2728, loss: 0.229, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2729, loss: 0.225, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2730, loss: 0.219, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2731, loss: 0.193, accuracy: 0.866, training set size: 2129\n",
      "Finished training for epoch 2732, loss: 0.227, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2733, loss: 0.222, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2734, loss: 0.230, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2735, loss: 0.247, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2736, loss: 0.265, accuracy: 0.826, training set size: 2129\n",
      "Finished training for epoch 2737, loss: 0.285, accuracy: 0.809, training set size: 2129\n",
      "Finished training for epoch 2738, loss: 0.254, accuracy: 0.830, training set size: 2129\n",
      "Finished training for epoch 2739, loss: 0.224, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2740, loss: 0.210, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2741, loss: 0.219, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2742, loss: 0.262, accuracy: 0.820, training set size: 2129\n",
      "Finished training for epoch 2743, loss: 0.250, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2744, loss: 0.235, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2745, loss: 0.223, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2746, loss: 0.227, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2747, loss: 0.221, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2748, loss: 0.248, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2749, loss: 0.227, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2750, loss: 0.225, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2751, loss: 0.230, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2752, loss: 0.227, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2753, loss: 0.234, accuracy: 0.835, training set size: 2129\n",
      "Finished training for epoch 2754, loss: 0.236, accuracy: 0.835, training set size: 2129\n",
      "Finished training for epoch 2755, loss: 0.233, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2756, loss: 0.224, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2757, loss: 0.219, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2758, loss: 0.234, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2759, loss: 0.236, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2760, loss: 0.221, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2761, loss: 0.219, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2762, loss: 0.210, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2763, loss: 0.225, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2764, loss: 0.205, accuracy: 0.858, training set size: 2129\n",
      "Finished training for epoch 2765, loss: 0.241, accuracy: 0.835, training set size: 2129\n",
      "Finished training for epoch 2766, loss: 0.223, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2767, loss: 0.204, accuracy: 0.859, training set size: 2129\n",
      "Finished training for epoch 2768, loss: 0.220, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2769, loss: 0.243, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2770, loss: 0.343, accuracy: 0.800, training set size: 2129\n",
      "Finished training for epoch 2771, loss: 0.247, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2772, loss: 0.213, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2773, loss: 0.237, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2774, loss: 0.240, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2775, loss: 0.202, accuracy: 0.863, training set size: 2129\n",
      "Finished training for epoch 2776, loss: 0.291, accuracy: 0.814, training set size: 2129\n",
      "Finished training for epoch 2777, loss: 0.212, accuracy: 0.856, training set size: 2129\n",
      "Finished training for epoch 2778, loss: 0.219, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2779, loss: 0.218, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2780, loss: 0.250, accuracy: 0.830, training set size: 2129\n",
      "Finished training for epoch 2781, loss: 0.282, accuracy: 0.806, training set size: 2129\n",
      "Finished training for epoch 2782, loss: 0.229, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2783, loss: 0.247, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2784, loss: 0.237, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2785, loss: 0.248, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2786, loss: 0.258, accuracy: 0.822, training set size: 2129\n",
      "Finished training for epoch 2787, loss: 0.242, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2788, loss: 0.219, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2789, loss: 0.223, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2790, loss: 0.234, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2791, loss: 0.226, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2792, loss: 0.238, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2793, loss: 0.216, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2794, loss: 0.232, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2795, loss: 0.232, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2796, loss: 0.222, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2797, loss: 0.223, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2798, loss: 0.229, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2799, loss: 0.201, accuracy: 0.862, training set size: 2129\n",
      "Finished training for epoch 2800, loss: 0.291, accuracy: 0.814, training set size: 2129\n",
      "Finished training for epoch 2801, loss: 0.215, accuracy: 0.860, training set size: 2129\n",
      "Finished training for epoch 2802, loss: 0.241, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2803, loss: 0.237, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2804, loss: 0.242, accuracy: 0.835, training set size: 2129\n",
      "Finished training for epoch 2805, loss: 0.209, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2806, loss: 0.222, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2807, loss: 0.206, accuracy: 0.860, training set size: 2129\n",
      "Finished training for epoch 2808, loss: 0.212, accuracy: 0.856, training set size: 2129\n",
      "Finished training for epoch 2809, loss: 0.221, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2810, loss: 0.262, accuracy: 0.819, training set size: 2129\n",
      "Finished training for epoch 2811, loss: 0.244, accuracy: 0.835, training set size: 2129\n",
      "Finished training for epoch 2812, loss: 0.230, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2813, loss: 0.213, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2814, loss: 0.210, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2815, loss: 0.225, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2816, loss: 0.205, accuracy: 0.860, training set size: 2129\n",
      "Finished training for epoch 2817, loss: 0.214, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2818, loss: 0.224, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2819, loss: 0.239, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2820, loss: 0.204, accuracy: 0.859, training set size: 2129\n",
      "Finished training for epoch 2821, loss: 0.245, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2822, loss: 0.222, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2823, loss: 0.214, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2824, loss: 0.224, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2825, loss: 0.219, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2826, loss: 0.229, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2827, loss: 0.283, accuracy: 0.814, training set size: 2129\n",
      "Finished training for epoch 2828, loss: 0.229, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2829, loss: 0.215, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2830, loss: 0.227, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2831, loss: 0.263, accuracy: 0.821, training set size: 2129\n",
      "Finished training for epoch 2832, loss: 0.222, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2833, loss: 0.207, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2834, loss: 0.226, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2835, loss: 0.210, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2836, loss: 0.241, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2837, loss: 0.217, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2838, loss: 0.242, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2839, loss: 0.226, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2840, loss: 0.245, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2841, loss: 0.217, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2842, loss: 0.249, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2843, loss: 0.261, accuracy: 0.817, training set size: 2129\n",
      "Finished training for epoch 2844, loss: 0.229, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2845, loss: 0.214, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2846, loss: 0.246, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2847, loss: 0.228, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2848, loss: 0.223, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2849, loss: 0.210, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2850, loss: 0.222, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2851, loss: 0.214, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2852, loss: 0.251, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2853, loss: 0.228, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2854, loss: 0.208, accuracy: 0.859, training set size: 2129\n",
      "Finished training for epoch 2855, loss: 0.228, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2856, loss: 0.240, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2857, loss: 0.209, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2858, loss: 0.215, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2859, loss: 0.221, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2860, loss: 0.230, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2861, loss: 0.245, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2862, loss: 0.237, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2863, loss: 0.287, accuracy: 0.816, training set size: 2129\n",
      "Finished training for epoch 2864, loss: 0.227, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2865, loss: 0.220, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2866, loss: 0.225, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2867, loss: 0.233, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2868, loss: 0.254, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2869, loss: 0.215, accuracy: 0.856, training set size: 2129\n",
      "Finished training for epoch 2870, loss: 0.230, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2871, loss: 0.220, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2872, loss: 0.222, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2873, loss: 0.217, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2874, loss: 0.215, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2875, loss: 0.236, accuracy: 0.836, training set size: 2129\n",
      "Finished training for epoch 2876, loss: 0.223, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2877, loss: 0.222, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2878, loss: 0.212, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2879, loss: 0.227, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2880, loss: 0.232, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2881, loss: 0.238, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2882, loss: 0.228, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2883, loss: 0.217, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2884, loss: 0.214, accuracy: 0.860, training set size: 2129\n",
      "Finished training for epoch 2885, loss: 0.222, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2886, loss: 0.223, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2887, loss: 0.257, accuracy: 0.819, training set size: 2129\n",
      "Finished training for epoch 2888, loss: 0.228, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2889, loss: 0.231, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2890, loss: 0.206, accuracy: 0.861, training set size: 2129\n",
      "Finished training for epoch 2891, loss: 0.223, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2892, loss: 0.263, accuracy: 0.823, training set size: 2129\n",
      "Finished training for epoch 2893, loss: 0.249, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2894, loss: 0.220, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2895, loss: 0.212, accuracy: 0.860, training set size: 2129\n",
      "Finished training for epoch 2896, loss: 0.226, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2897, loss: 0.230, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2898, loss: 0.249, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2899, loss: 0.224, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2900, loss: 0.242, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2901, loss: 0.206, accuracy: 0.857, training set size: 2129\n",
      "Finished training for epoch 2902, loss: 0.225, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2903, loss: 0.207, accuracy: 0.859, training set size: 2129\n",
      "Finished training for epoch 2904, loss: 0.205, accuracy: 0.860, training set size: 2129\n",
      "Finished training for epoch 2905, loss: 0.222, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2906, loss: 0.233, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2907, loss: 0.225, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2908, loss: 0.265, accuracy: 0.828, training set size: 2129\n",
      "Finished training for epoch 2909, loss: 0.214, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2910, loss: 0.230, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2911, loss: 0.215, accuracy: 0.859, training set size: 2129\n",
      "Finished training for epoch 2912, loss: 0.203, accuracy: 0.859, training set size: 2129\n",
      "Finished training for epoch 2913, loss: 0.213, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2914, loss: 0.235, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2915, loss: 0.246, accuracy: 0.826, training set size: 2129\n",
      "Finished training for epoch 2916, loss: 0.222, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2917, loss: 0.208, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2918, loss: 0.226, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2919, loss: 0.246, accuracy: 0.825, training set size: 2129\n",
      "Finished training for epoch 2920, loss: 0.207, accuracy: 0.859, training set size: 2129\n",
      "Finished training for epoch 2921, loss: 0.236, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2922, loss: 0.230, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2923, loss: 0.237, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2924, loss: 0.215, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2925, loss: 0.243, accuracy: 0.827, training set size: 2129\n",
      "Finished training for epoch 2926, loss: 0.226, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2927, loss: 0.235, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2928, loss: 0.242, accuracy: 0.835, training set size: 2129\n",
      "Finished training for epoch 2929, loss: 0.209, accuracy: 0.856, training set size: 2129\n",
      "Finished training for epoch 2930, loss: 0.212, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2931, loss: 0.233, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2932, loss: 0.240, accuracy: 0.833, training set size: 2129\n",
      "Finished training for epoch 2933, loss: 0.209, accuracy: 0.855, training set size: 2129\n",
      "Finished training for epoch 2934, loss: 0.211, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2935, loss: 0.249, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2936, loss: 0.227, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2937, loss: 0.207, accuracy: 0.855, training set size: 2129\n",
      "Finished training for epoch 2938, loss: 0.215, accuracy: 0.848, training set size: 2129\n",
      "Finished training for epoch 2939, loss: 0.225, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2940, loss: 0.243, accuracy: 0.832, training set size: 2129\n",
      "Finished training for epoch 2941, loss: 0.225, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2942, loss: 0.238, accuracy: 0.835, training set size: 2129\n",
      "Finished training for epoch 2943, loss: 0.242, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2944, loss: 0.223, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2945, loss: 0.203, accuracy: 0.858, training set size: 2129\n",
      "Finished training for epoch 2946, loss: 0.229, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2947, loss: 0.228, accuracy: 0.839, training set size: 2129\n",
      "Finished training for epoch 2948, loss: 0.218, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2949, loss: 0.217, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2950, loss: 0.220, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2951, loss: 0.242, accuracy: 0.831, training set size: 2129\n",
      "Finished training for epoch 2952, loss: 0.214, accuracy: 0.856, training set size: 2129\n",
      "Finished training for epoch 2953, loss: 0.221, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2954, loss: 0.227, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2955, loss: 0.205, accuracy: 0.857, training set size: 2129\n",
      "Finished training for epoch 2956, loss: 0.208, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2957, loss: 0.212, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2958, loss: 0.209, accuracy: 0.856, training set size: 2129\n",
      "Finished training for epoch 2959, loss: 0.219, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2960, loss: 0.246, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2961, loss: 0.232, accuracy: 0.837, training set size: 2129\n",
      "Finished training for epoch 2962, loss: 0.206, accuracy: 0.850, training set size: 2129\n",
      "Finished training for epoch 2963, loss: 0.221, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2964, loss: 0.216, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2965, loss: 0.236, accuracy: 0.838, training set size: 2129\n",
      "Finished training for epoch 2966, loss: 0.208, accuracy: 0.853, training set size: 2129\n",
      "Finished training for epoch 2967, loss: 0.204, accuracy: 0.860, training set size: 2129\n",
      "Finished training for epoch 2968, loss: 0.203, accuracy: 0.855, training set size: 2129\n",
      "Finished training for epoch 2969, loss: 0.235, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2970, loss: 0.211, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2971, loss: 0.252, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2972, loss: 0.232, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2973, loss: 0.215, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2974, loss: 0.203, accuracy: 0.862, training set size: 2129\n",
      "Finished training for epoch 2975, loss: 0.224, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2976, loss: 0.212, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2977, loss: 0.220, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2978, loss: 0.217, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2979, loss: 0.209, accuracy: 0.855, training set size: 2129\n",
      "Finished training for epoch 2980, loss: 0.275, accuracy: 0.823, training set size: 2129\n",
      "Finished training for epoch 2981, loss: 0.245, accuracy: 0.845, training set size: 2129\n",
      "Finished training for epoch 2982, loss: 0.222, accuracy: 0.849, training set size: 2129\n",
      "Finished training for epoch 2983, loss: 0.231, accuracy: 0.842, training set size: 2129\n",
      "Finished training for epoch 2984, loss: 0.217, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 2985, loss: 0.222, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2986, loss: 0.256, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2987, loss: 0.205, accuracy: 0.855, training set size: 2129\n",
      "Finished training for epoch 2988, loss: 0.215, accuracy: 0.852, training set size: 2129\n",
      "Finished training for epoch 2989, loss: 0.226, accuracy: 0.844, training set size: 2129\n",
      "Finished training for epoch 2990, loss: 0.248, accuracy: 0.829, training set size: 2129\n",
      "Finished training for epoch 2991, loss: 0.220, accuracy: 0.851, training set size: 2129\n",
      "Finished training for epoch 2992, loss: 0.232, accuracy: 0.841, training set size: 2129\n",
      "Finished training for epoch 2993, loss: 0.220, accuracy: 0.843, training set size: 2129\n",
      "Finished training for epoch 2994, loss: 0.202, accuracy: 0.859, training set size: 2129\n",
      "Finished training for epoch 2995, loss: 0.213, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 2996, loss: 0.226, accuracy: 0.840, training set size: 2129\n",
      "Finished training for epoch 2997, loss: 0.232, accuracy: 0.834, training set size: 2129\n",
      "Finished training for epoch 2998, loss: 0.222, accuracy: 0.847, training set size: 2129\n",
      "Finished training for epoch 2999, loss: 0.221, accuracy: 0.846, training set size: 2129\n",
      "Finished training for epoch 3000, loss: 0.212, accuracy: 0.854, training set size: 2129\n",
      "Finished training for epoch 3001, loss: 0.322, accuracy: 0.736, training set size: 2440\n",
      "Finished training for epoch 3002, loss: 0.280, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3003, loss: 0.302, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3004, loss: 0.282, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3005, loss: 0.314, accuracy: 0.736, training set size: 2440\n",
      "Finished training for epoch 3006, loss: 0.304, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3007, loss: 0.304, accuracy: 0.736, training set size: 2440\n",
      "Finished training for epoch 3008, loss: 0.296, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3009, loss: 0.279, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3010, loss: 0.282, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3011, loss: 0.286, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3012, loss: 0.290, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3013, loss: 0.324, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3014, loss: 0.304, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3015, loss: 0.288, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3016, loss: 0.273, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3017, loss: 0.286, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3018, loss: 0.279, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3019, loss: 0.281, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3020, loss: 0.278, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3021, loss: 0.282, accuracy: 0.765, training set size: 2440\n",
      "Finished training for epoch 3022, loss: 0.290, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3023, loss: 0.294, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3024, loss: 0.323, accuracy: 0.740, training set size: 2440\n",
      "Finished training for epoch 3025, loss: 0.291, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3026, loss: 0.288, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3027, loss: 0.294, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3028, loss: 0.301, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3029, loss: 0.267, accuracy: 0.771, training set size: 2440\n",
      "Finished training for epoch 3030, loss: 0.283, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3031, loss: 0.278, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3032, loss: 0.287, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3033, loss: 0.270, accuracy: 0.771, training set size: 2440\n",
      "Finished training for epoch 3034, loss: 0.288, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3035, loss: 0.330, accuracy: 0.733, training set size: 2440\n",
      "Finished training for epoch 3036, loss: 0.293, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3037, loss: 0.294, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3038, loss: 0.297, accuracy: 0.742, training set size: 2440\n",
      "Finished training for epoch 3039, loss: 0.290, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3040, loss: 0.294, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3041, loss: 0.295, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3042, loss: 0.306, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3043, loss: 0.277, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3044, loss: 0.285, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3045, loss: 0.310, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3046, loss: 0.279, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3047, loss: 0.293, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3048, loss: 0.297, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3049, loss: 0.288, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3050, loss: 0.306, accuracy: 0.739, training set size: 2440\n",
      "Finished training for epoch 3051, loss: 0.289, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3052, loss: 0.300, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3053, loss: 0.286, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3054, loss: 0.280, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3055, loss: 0.292, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3056, loss: 0.285, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3057, loss: 0.292, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3058, loss: 0.317, accuracy: 0.730, training set size: 2440\n",
      "Finished training for epoch 3059, loss: 0.291, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3060, loss: 0.303, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3061, loss: 0.271, accuracy: 0.771, training set size: 2440\n",
      "Finished training for epoch 3062, loss: 0.296, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3063, loss: 0.293, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3064, loss: 0.337, accuracy: 0.722, training set size: 2440\n",
      "Finished training for epoch 3065, loss: 0.294, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3066, loss: 0.293, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3067, loss: 0.300, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3068, loss: 0.299, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3069, loss: 0.289, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3070, loss: 0.305, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3071, loss: 0.279, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3072, loss: 0.287, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3073, loss: 0.302, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3074, loss: 0.279, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3075, loss: 0.287, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3076, loss: 0.295, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3077, loss: 0.292, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3078, loss: 0.315, accuracy: 0.739, training set size: 2440\n",
      "Finished training for epoch 3079, loss: 0.279, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3080, loss: 0.293, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3081, loss: 0.277, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3082, loss: 0.314, accuracy: 0.742, training set size: 2440\n",
      "Finished training for epoch 3083, loss: 0.305, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3084, loss: 0.331, accuracy: 0.729, training set size: 2440\n",
      "Finished training for epoch 3085, loss: 0.310, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3086, loss: 0.283, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3087, loss: 0.275, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3088, loss: 0.330, accuracy: 0.734, training set size: 2440\n",
      "Finished training for epoch 3089, loss: 0.279, accuracy: 0.768, training set size: 2440\n",
      "Finished training for epoch 3090, loss: 0.269, accuracy: 0.765, training set size: 2440\n",
      "Finished training for epoch 3091, loss: 0.302, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3092, loss: 0.297, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3093, loss: 0.269, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3094, loss: 0.308, accuracy: 0.744, training set size: 2440\n",
      "Finished training for epoch 3095, loss: 0.289, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3096, loss: 0.343, accuracy: 0.729, training set size: 2440\n",
      "Finished training for epoch 3097, loss: 0.302, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3098, loss: 0.276, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3099, loss: 0.277, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3100, loss: 0.297, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3101, loss: 0.292, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3102, loss: 0.273, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3103, loss: 0.286, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3104, loss: 0.291, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3105, loss: 0.272, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3106, loss: 0.293, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3107, loss: 0.303, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3108, loss: 0.292, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3109, loss: 0.312, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3110, loss: 0.290, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3111, loss: 0.283, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3112, loss: 0.310, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3113, loss: 0.297, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3114, loss: 0.290, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3115, loss: 0.277, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3116, loss: 0.272, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3117, loss: 0.272, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3118, loss: 0.278, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3119, loss: 0.282, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3120, loss: 0.278, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3121, loss: 0.280, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3122, loss: 0.317, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3123, loss: 0.287, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3124, loss: 0.284, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3125, loss: 0.298, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3126, loss: 0.279, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3127, loss: 0.289, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3128, loss: 0.276, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3129, loss: 0.279, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3130, loss: 0.278, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3131, loss: 0.295, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3132, loss: 0.264, accuracy: 0.770, training set size: 2440\n",
      "Finished training for epoch 3133, loss: 0.306, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3134, loss: 0.277, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3135, loss: 0.317, accuracy: 0.739, training set size: 2440\n",
      "Finished training for epoch 3136, loss: 0.301, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3137, loss: 0.291, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3138, loss: 0.279, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3139, loss: 0.285, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3140, loss: 0.281, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3141, loss: 0.298, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3142, loss: 0.325, accuracy: 0.726, training set size: 2440\n",
      "Finished training for epoch 3143, loss: 0.295, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3144, loss: 0.271, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3145, loss: 0.285, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3146, loss: 0.285, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3147, loss: 0.304, accuracy: 0.742, training set size: 2440\n",
      "Finished training for epoch 3148, loss: 0.284, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3149, loss: 0.273, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3150, loss: 0.298, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3151, loss: 0.276, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3152, loss: 0.287, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3153, loss: 0.279, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3154, loss: 0.291, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3155, loss: 0.293, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3156, loss: 0.277, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3157, loss: 0.278, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3158, loss: 0.280, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3159, loss: 0.295, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3160, loss: 0.275, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3161, loss: 0.292, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3162, loss: 0.296, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3163, loss: 0.265, accuracy: 0.772, training set size: 2440\n",
      "Finished training for epoch 3164, loss: 0.286, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3165, loss: 0.275, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3166, loss: 0.284, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3167, loss: 0.306, accuracy: 0.738, training set size: 2440\n",
      "Finished training for epoch 3168, loss: 0.278, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3169, loss: 0.281, accuracy: 0.765, training set size: 2440\n",
      "Finished training for epoch 3170, loss: 0.335, accuracy: 0.732, training set size: 2440\n",
      "Finished training for epoch 3171, loss: 0.301, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3172, loss: 0.276, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3173, loss: 0.280, accuracy: 0.765, training set size: 2440\n",
      "Finished training for epoch 3174, loss: 0.288, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3175, loss: 0.292, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3176, loss: 0.282, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3177, loss: 0.316, accuracy: 0.736, training set size: 2440\n",
      "Finished training for epoch 3178, loss: 0.295, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3179, loss: 0.287, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3180, loss: 0.277, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3181, loss: 0.302, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3182, loss: 0.286, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3183, loss: 0.283, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3184, loss: 0.300, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3185, loss: 0.292, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3186, loss: 0.275, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3187, loss: 0.300, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3188, loss: 0.284, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3189, loss: 0.285, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3190, loss: 0.315, accuracy: 0.740, training set size: 2440\n",
      "Finished training for epoch 3191, loss: 0.305, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3192, loss: 0.278, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3193, loss: 0.277, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3194, loss: 0.285, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3195, loss: 0.313, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3196, loss: 0.276, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3197, loss: 0.295, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3198, loss: 0.280, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3199, loss: 0.298, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3200, loss: 0.296, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3201, loss: 0.298, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3202, loss: 0.283, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3203, loss: 0.294, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3204, loss: 0.290, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3205, loss: 0.278, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3206, loss: 0.277, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3207, loss: 0.285, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3208, loss: 0.306, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3209, loss: 0.289, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3210, loss: 0.280, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3211, loss: 0.289, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3212, loss: 0.299, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3213, loss: 0.290, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3214, loss: 0.306, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3215, loss: 0.275, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3216, loss: 0.292, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3217, loss: 0.301, accuracy: 0.744, training set size: 2440\n",
      "Finished training for epoch 3218, loss: 0.293, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3219, loss: 0.280, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3220, loss: 0.312, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3221, loss: 0.288, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3222, loss: 0.312, accuracy: 0.735, training set size: 2440\n",
      "Finished training for epoch 3223, loss: 0.290, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3224, loss: 0.277, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3225, loss: 0.307, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3226, loss: 0.307, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3227, loss: 0.289, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3228, loss: 0.288, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3229, loss: 0.289, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3230, loss: 0.281, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3231, loss: 0.272, accuracy: 0.765, training set size: 2440\n",
      "Finished training for epoch 3232, loss: 0.286, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3233, loss: 0.276, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3234, loss: 0.286, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3235, loss: 0.287, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3236, loss: 0.260, accuracy: 0.775, training set size: 2440\n",
      "Finished training for epoch 3237, loss: 0.308, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3238, loss: 0.276, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3239, loss: 0.282, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3240, loss: 0.280, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3241, loss: 0.290, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3242, loss: 0.293, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3243, loss: 0.278, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3244, loss: 0.286, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3245, loss: 0.290, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3246, loss: 0.295, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3247, loss: 0.294, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3248, loss: 0.288, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3249, loss: 0.293, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3250, loss: 0.308, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3251, loss: 0.302, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3252, loss: 0.285, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3253, loss: 0.292, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3254, loss: 0.286, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3255, loss: 0.297, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3256, loss: 0.268, accuracy: 0.768, training set size: 2440\n",
      "Finished training for epoch 3257, loss: 0.292, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3258, loss: 0.288, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3259, loss: 0.282, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3260, loss: 0.289, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3261, loss: 0.298, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3262, loss: 0.337, accuracy: 0.733, training set size: 2440\n",
      "Finished training for epoch 3263, loss: 0.301, accuracy: 0.739, training set size: 2440\n",
      "Finished training for epoch 3264, loss: 0.269, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3265, loss: 0.281, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3266, loss: 0.283, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3267, loss: 0.271, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3268, loss: 0.296, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3269, loss: 0.287, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3270, loss: 0.284, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3271, loss: 0.297, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3272, loss: 0.305, accuracy: 0.742, training set size: 2440\n",
      "Finished training for epoch 3273, loss: 0.283, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3274, loss: 0.288, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3275, loss: 0.275, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3276, loss: 0.303, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3277, loss: 0.296, accuracy: 0.742, training set size: 2440\n",
      "Finished training for epoch 3278, loss: 0.296, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3279, loss: 0.331, accuracy: 0.732, training set size: 2440\n",
      "Finished training for epoch 3280, loss: 0.308, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3281, loss: 0.290, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3282, loss: 0.299, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3283, loss: 0.277, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3284, loss: 0.296, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3285, loss: 0.299, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3286, loss: 0.279, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3287, loss: 0.291, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3288, loss: 0.351, accuracy: 0.731, training set size: 2440\n",
      "Finished training for epoch 3289, loss: 0.289, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3290, loss: 0.281, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3291, loss: 0.278, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3292, loss: 0.291, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3293, loss: 0.296, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3294, loss: 0.275, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3295, loss: 0.281, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3296, loss: 0.294, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3297, loss: 0.285, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3298, loss: 0.315, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3299, loss: 0.316, accuracy: 0.730, training set size: 2440\n",
      "Finished training for epoch 3300, loss: 0.307, accuracy: 0.744, training set size: 2440\n",
      "Finished training for epoch 3301, loss: 0.312, accuracy: 0.742, training set size: 2440\n",
      "Finished training for epoch 3302, loss: 0.279, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3303, loss: 0.295, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3304, loss: 0.280, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3305, loss: 0.294, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3306, loss: 0.326, accuracy: 0.736, training set size: 2440\n",
      "Finished training for epoch 3307, loss: 0.289, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3308, loss: 0.283, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3309, loss: 0.285, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3310, loss: 0.300, accuracy: 0.744, training set size: 2440\n",
      "Finished training for epoch 3311, loss: 0.293, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3312, loss: 0.263, accuracy: 0.771, training set size: 2440\n",
      "Finished training for epoch 3313, loss: 0.280, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3314, loss: 0.302, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3315, loss: 0.297, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3316, loss: 0.276, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3317, loss: 0.295, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3318, loss: 0.274, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3319, loss: 0.291, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3320, loss: 0.315, accuracy: 0.737, training set size: 2440\n",
      "Finished training for epoch 3321, loss: 0.284, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3322, loss: 0.280, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3323, loss: 0.277, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3324, loss: 0.288, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3325, loss: 0.297, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3326, loss: 0.273, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3327, loss: 0.289, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3328, loss: 0.297, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3329, loss: 0.295, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3330, loss: 0.287, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3331, loss: 0.292, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3332, loss: 0.294, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3333, loss: 0.308, accuracy: 0.739, training set size: 2440\n",
      "Finished training for epoch 3334, loss: 0.274, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3335, loss: 0.283, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3336, loss: 0.327, accuracy: 0.736, training set size: 2440\n",
      "Finished training for epoch 3337, loss: 0.309, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3338, loss: 0.293, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3339, loss: 0.270, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3340, loss: 0.274, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3341, loss: 0.292, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3342, loss: 0.305, accuracy: 0.740, training set size: 2440\n",
      "Finished training for epoch 3343, loss: 0.291, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3344, loss: 0.313, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3345, loss: 0.276, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3346, loss: 0.296, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3347, loss: 0.271, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3348, loss: 0.280, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3349, loss: 0.281, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3350, loss: 0.313, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3351, loss: 0.287, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3352, loss: 0.275, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3353, loss: 0.326, accuracy: 0.735, training set size: 2440\n",
      "Finished training for epoch 3354, loss: 0.298, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3355, loss: 0.276, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3356, loss: 0.276, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3357, loss: 0.294, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3358, loss: 0.280, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3359, loss: 0.284, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3360, loss: 0.289, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3361, loss: 0.315, accuracy: 0.736, training set size: 2440\n",
      "Finished training for epoch 3362, loss: 0.280, accuracy: 0.770, training set size: 2440\n",
      "Finished training for epoch 3363, loss: 0.286, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3364, loss: 0.283, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3365, loss: 0.308, accuracy: 0.742, training set size: 2440\n",
      "Finished training for epoch 3366, loss: 0.285, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3367, loss: 0.283, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3368, loss: 0.273, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3369, loss: 0.303, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3370, loss: 0.282, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3371, loss: 0.277, accuracy: 0.765, training set size: 2440\n",
      "Finished training for epoch 3372, loss: 0.285, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3373, loss: 0.283, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3374, loss: 0.264, accuracy: 0.771, training set size: 2440\n",
      "Finished training for epoch 3375, loss: 0.297, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3376, loss: 0.300, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3377, loss: 0.291, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3378, loss: 0.299, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3379, loss: 0.287, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3380, loss: 0.278, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3381, loss: 0.299, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3382, loss: 0.267, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3383, loss: 0.283, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3384, loss: 0.301, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3385, loss: 0.283, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3386, loss: 0.281, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3387, loss: 0.313, accuracy: 0.740, training set size: 2440\n",
      "Finished training for epoch 3388, loss: 0.280, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3389, loss: 0.276, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3390, loss: 0.302, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3391, loss: 0.284, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3392, loss: 0.302, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3393, loss: 0.269, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3394, loss: 0.270, accuracy: 0.769, training set size: 2440\n",
      "Finished training for epoch 3395, loss: 0.283, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3396, loss: 0.315, accuracy: 0.736, training set size: 2440\n",
      "Finished training for epoch 3397, loss: 0.287, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3398, loss: 0.302, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3399, loss: 0.280, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3400, loss: 0.267, accuracy: 0.768, training set size: 2440\n",
      "Finished training for epoch 3401, loss: 0.278, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3402, loss: 0.342, accuracy: 0.727, training set size: 2440\n",
      "Finished training for epoch 3403, loss: 0.273, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3404, loss: 0.281, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3405, loss: 0.283, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3406, loss: 0.293, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3407, loss: 0.293, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3408, loss: 0.288, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3409, loss: 0.285, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3410, loss: 0.278, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3411, loss: 0.318, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3412, loss: 0.292, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3413, loss: 0.273, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3414, loss: 0.318, accuracy: 0.742, training set size: 2440\n",
      "Finished training for epoch 3415, loss: 0.282, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3416, loss: 0.287, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3417, loss: 0.261, accuracy: 0.773, training set size: 2440\n",
      "Finished training for epoch 3418, loss: 0.291, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3419, loss: 0.277, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3420, loss: 0.313, accuracy: 0.738, training set size: 2440\n",
      "Finished training for epoch 3421, loss: 0.303, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3422, loss: 0.307, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3423, loss: 0.279, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3424, loss: 0.275, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3425, loss: 0.325, accuracy: 0.737, training set size: 2440\n",
      "Finished training for epoch 3426, loss: 0.281, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3427, loss: 0.286, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3428, loss: 0.294, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3429, loss: 0.316, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3430, loss: 0.305, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3431, loss: 0.304, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3432, loss: 0.292, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3433, loss: 0.290, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3434, loss: 0.287, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3435, loss: 0.306, accuracy: 0.744, training set size: 2440\n",
      "Finished training for epoch 3436, loss: 0.294, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3437, loss: 0.282, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3438, loss: 0.278, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3439, loss: 0.291, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3440, loss: 0.271, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3441, loss: 0.288, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3442, loss: 0.283, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3443, loss: 0.282, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3444, loss: 0.289, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3445, loss: 0.288, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3446, loss: 0.296, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3447, loss: 0.272, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3448, loss: 0.323, accuracy: 0.733, training set size: 2440\n",
      "Finished training for epoch 3449, loss: 0.286, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3450, loss: 0.291, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3451, loss: 0.294, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3452, loss: 0.303, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3453, loss: 0.300, accuracy: 0.740, training set size: 2440\n",
      "Finished training for epoch 3454, loss: 0.279, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3455, loss: 0.274, accuracy: 0.771, training set size: 2440\n",
      "Finished training for epoch 3456, loss: 0.336, accuracy: 0.732, training set size: 2440\n",
      "Finished training for epoch 3457, loss: 0.283, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3458, loss: 0.290, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3459, loss: 0.291, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3460, loss: 0.293, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3461, loss: 0.290, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3462, loss: 0.297, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3463, loss: 0.282, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3464, loss: 0.276, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3465, loss: 0.280, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3466, loss: 0.272, accuracy: 0.765, training set size: 2440\n",
      "Finished training for epoch 3467, loss: 0.292, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3468, loss: 0.280, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3469, loss: 0.303, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3470, loss: 0.341, accuracy: 0.718, training set size: 2440\n",
      "Finished training for epoch 3471, loss: 0.286, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3472, loss: 0.309, accuracy: 0.740, training set size: 2440\n",
      "Finished training for epoch 3473, loss: 0.286, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3474, loss: 0.294, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3475, loss: 0.291, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3476, loss: 0.274, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3477, loss: 0.303, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3478, loss: 0.288, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3479, loss: 0.313, accuracy: 0.744, training set size: 2440\n",
      "Finished training for epoch 3480, loss: 0.276, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3481, loss: 0.270, accuracy: 0.773, training set size: 2440\n",
      "Finished training for epoch 3482, loss: 0.328, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3483, loss: 0.304, accuracy: 0.742, training set size: 2440\n",
      "Finished training for epoch 3484, loss: 0.282, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3485, loss: 0.288, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3486, loss: 0.292, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3487, loss: 0.284, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3488, loss: 0.287, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3489, loss: 0.289, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3490, loss: 0.303, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3491, loss: 0.289, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3492, loss: 0.296, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3493, loss: 0.312, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3494, loss: 0.272, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3495, loss: 0.290, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3496, loss: 0.296, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3497, loss: 0.301, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3498, loss: 0.269, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3499, loss: 0.285, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3500, loss: 0.297, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3501, loss: 0.286, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3502, loss: 0.296, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3503, loss: 0.324, accuracy: 0.732, training set size: 2440\n",
      "Finished training for epoch 3504, loss: 0.285, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3505, loss: 0.280, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3506, loss: 0.296, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3507, loss: 0.284, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3508, loss: 0.326, accuracy: 0.740, training set size: 2440\n",
      "Finished training for epoch 3509, loss: 0.282, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3510, loss: 0.281, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3511, loss: 0.276, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3512, loss: 0.287, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3513, loss: 0.294, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3514, loss: 0.278, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3515, loss: 0.279, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3516, loss: 0.278, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3517, loss: 0.267, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3518, loss: 0.288, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3519, loss: 0.274, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3520, loss: 0.288, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3521, loss: 0.299, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3522, loss: 0.281, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3523, loss: 0.315, accuracy: 0.740, training set size: 2440\n",
      "Finished training for epoch 3524, loss: 0.275, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3525, loss: 0.270, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3526, loss: 0.325, accuracy: 0.737, training set size: 2440\n",
      "Finished training for epoch 3527, loss: 0.292, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3528, loss: 0.276, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3529, loss: 0.275, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3530, loss: 0.284, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3531, loss: 0.288, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3532, loss: 0.288, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3533, loss: 0.303, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3534, loss: 0.272, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3535, loss: 0.282, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3536, loss: 0.266, accuracy: 0.773, training set size: 2440\n",
      "Finished training for epoch 3537, loss: 0.298, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3538, loss: 0.285, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3539, loss: 0.280, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3540, loss: 0.287, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3541, loss: 0.305, accuracy: 0.744, training set size: 2440\n",
      "Finished training for epoch 3542, loss: 0.287, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3543, loss: 0.309, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3544, loss: 0.303, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3545, loss: 0.290, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3546, loss: 0.327, accuracy: 0.732, training set size: 2440\n",
      "Finished training for epoch 3547, loss: 0.278, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3548, loss: 0.272, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3549, loss: 0.277, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3550, loss: 0.295, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3551, loss: 0.281, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3552, loss: 0.275, accuracy: 0.768, training set size: 2440\n",
      "Finished training for epoch 3553, loss: 0.277, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3554, loss: 0.275, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3555, loss: 0.292, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3556, loss: 0.291, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3557, loss: 0.276, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3558, loss: 0.297, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3559, loss: 0.281, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3560, loss: 0.300, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3561, loss: 0.288, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3562, loss: 0.330, accuracy: 0.728, training set size: 2440\n",
      "Finished training for epoch 3563, loss: 0.278, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3564, loss: 0.276, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3565, loss: 0.279, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3566, loss: 0.280, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3567, loss: 0.296, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3568, loss: 0.270, accuracy: 0.768, training set size: 2440\n",
      "Finished training for epoch 3569, loss: 0.294, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3570, loss: 0.282, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3571, loss: 0.294, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3572, loss: 0.279, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3573, loss: 0.288, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3574, loss: 0.275, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3575, loss: 0.286, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3576, loss: 0.320, accuracy: 0.736, training set size: 2440\n",
      "Finished training for epoch 3577, loss: 0.283, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3578, loss: 0.277, accuracy: 0.769, training set size: 2440\n",
      "Finished training for epoch 3579, loss: 0.314, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3580, loss: 0.280, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3581, loss: 0.283, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3582, loss: 0.289, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3583, loss: 0.314, accuracy: 0.737, training set size: 2440\n",
      "Finished training for epoch 3584, loss: 0.273, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3585, loss: 0.270, accuracy: 0.768, training set size: 2440\n",
      "Finished training for epoch 3586, loss: 0.289, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3587, loss: 0.297, accuracy: 0.744, training set size: 2440\n",
      "Finished training for epoch 3588, loss: 0.286, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3589, loss: 0.278, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3590, loss: 0.304, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3591, loss: 0.307, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3592, loss: 0.278, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3593, loss: 0.281, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3594, loss: 0.277, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3595, loss: 0.278, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3596, loss: 0.300, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3597, loss: 0.287, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3598, loss: 0.283, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3599, loss: 0.296, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3600, loss: 0.290, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3601, loss: 0.282, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3602, loss: 0.294, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3603, loss: 0.348, accuracy: 0.727, training set size: 2440\n",
      "Finished training for epoch 3604, loss: 0.280, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3605, loss: 0.292, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3606, loss: 0.321, accuracy: 0.739, training set size: 2440\n",
      "Finished training for epoch 3607, loss: 0.283, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3608, loss: 0.272, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3609, loss: 0.305, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3610, loss: 0.307, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3611, loss: 0.292, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3612, loss: 0.274, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3613, loss: 0.270, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3614, loss: 0.292, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3615, loss: 0.303, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3616, loss: 0.294, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3617, loss: 0.289, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3618, loss: 0.274, accuracy: 0.768, training set size: 2440\n",
      "Finished training for epoch 3619, loss: 0.274, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3620, loss: 0.285, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3621, loss: 0.286, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3622, loss: 0.279, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3623, loss: 0.297, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3624, loss: 0.295, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3625, loss: 0.282, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3626, loss: 0.278, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3627, loss: 0.278, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3628, loss: 0.300, accuracy: 0.744, training set size: 2440\n",
      "Finished training for epoch 3629, loss: 0.277, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3630, loss: 0.280, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3631, loss: 0.274, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3632, loss: 0.274, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3633, loss: 0.308, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3634, loss: 0.290, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3635, loss: 0.292, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3636, loss: 0.313, accuracy: 0.734, training set size: 2440\n",
      "Finished training for epoch 3637, loss: 0.295, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3638, loss: 0.283, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3639, loss: 0.284, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3640, loss: 0.278, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3641, loss: 0.281, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3642, loss: 0.280, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3643, loss: 0.281, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3644, loss: 0.290, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3645, loss: 0.287, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3646, loss: 0.294, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3647, loss: 0.309, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3648, loss: 0.292, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3649, loss: 0.303, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3650, loss: 0.350, accuracy: 0.728, training set size: 2440\n",
      "Finished training for epoch 3651, loss: 0.285, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3652, loss: 0.278, accuracy: 0.765, training set size: 2440\n",
      "Finished training for epoch 3653, loss: 0.293, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3654, loss: 0.287, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3655, loss: 0.304, accuracy: 0.744, training set size: 2440\n",
      "Finished training for epoch 3656, loss: 0.296, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3657, loss: 0.310, accuracy: 0.735, training set size: 2440\n",
      "Finished training for epoch 3658, loss: 0.281, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3659, loss: 0.278, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3660, loss: 0.282, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3661, loss: 0.282, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3662, loss: 0.321, accuracy: 0.738, training set size: 2440\n",
      "Finished training for epoch 3663, loss: 0.277, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3664, loss: 0.268, accuracy: 0.768, training set size: 2440\n",
      "Finished training for epoch 3665, loss: 0.280, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3666, loss: 0.276, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3667, loss: 0.307, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3668, loss: 0.281, accuracy: 0.765, training set size: 2440\n",
      "Finished training for epoch 3669, loss: 0.271, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3670, loss: 0.285, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3671, loss: 0.281, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3672, loss: 0.296, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3673, loss: 0.291, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3674, loss: 0.288, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3675, loss: 0.270, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3676, loss: 0.295, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3677, loss: 0.294, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3678, loss: 0.276, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3679, loss: 0.283, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3680, loss: 0.330, accuracy: 0.739, training set size: 2440\n",
      "Finished training for epoch 3681, loss: 0.302, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3682, loss: 0.280, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3683, loss: 0.280, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3684, loss: 0.281, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3685, loss: 0.298, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3686, loss: 0.297, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3687, loss: 0.270, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3688, loss: 0.292, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3689, loss: 0.283, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3690, loss: 0.275, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3691, loss: 0.318, accuracy: 0.738, training set size: 2440\n",
      "Finished training for epoch 3692, loss: 0.288, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3693, loss: 0.283, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3694, loss: 0.272, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3695, loss: 0.290, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3696, loss: 0.286, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3697, loss: 0.275, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3698, loss: 0.273, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3699, loss: 0.281, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3700, loss: 0.288, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3701, loss: 0.279, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3702, loss: 0.274, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3703, loss: 0.296, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3704, loss: 0.285, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3705, loss: 0.292, accuracy: 0.744, training set size: 2440\n",
      "Finished training for epoch 3706, loss: 0.297, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3707, loss: 0.268, accuracy: 0.769, training set size: 2440\n",
      "Finished training for epoch 3708, loss: 0.289, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3709, loss: 0.330, accuracy: 0.731, training set size: 2440\n",
      "Finished training for epoch 3710, loss: 0.285, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3711, loss: 0.289, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3712, loss: 0.265, accuracy: 0.768, training set size: 2440\n",
      "Finished training for epoch 3713, loss: 0.289, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3714, loss: 0.277, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3715, loss: 0.273, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3716, loss: 0.281, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3717, loss: 0.296, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3718, loss: 0.294, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3719, loss: 0.285, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3720, loss: 0.274, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3721, loss: 0.311, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3722, loss: 0.271, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3723, loss: 0.295, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3724, loss: 0.287, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3725, loss: 0.264, accuracy: 0.773, training set size: 2440\n",
      "Finished training for epoch 3726, loss: 0.334, accuracy: 0.735, training set size: 2440\n",
      "Finished training for epoch 3727, loss: 0.284, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3728, loss: 0.272, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3729, loss: 0.314, accuracy: 0.736, training set size: 2440\n",
      "Finished training for epoch 3730, loss: 0.289, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3731, loss: 0.294, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3732, loss: 0.289, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3733, loss: 0.292, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3734, loss: 0.280, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3735, loss: 0.265, accuracy: 0.768, training set size: 2440\n",
      "Finished training for epoch 3736, loss: 0.277, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3737, loss: 0.288, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3738, loss: 0.276, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3739, loss: 0.268, accuracy: 0.769, training set size: 2440\n",
      "Finished training for epoch 3740, loss: 0.303, accuracy: 0.744, training set size: 2440\n",
      "Finished training for epoch 3741, loss: 0.299, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3742, loss: 0.283, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3743, loss: 0.272, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3744, loss: 0.295, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3745, loss: 0.276, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3746, loss: 0.297, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3747, loss: 0.292, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3748, loss: 0.266, accuracy: 0.769, training set size: 2440\n",
      "Finished training for epoch 3749, loss: 0.298, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3750, loss: 0.284, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3751, loss: 0.288, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3752, loss: 0.299, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3753, loss: 0.281, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3754, loss: 0.281, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3755, loss: 0.298, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3756, loss: 0.287, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3757, loss: 0.277, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3758, loss: 0.310, accuracy: 0.739, training set size: 2440\n",
      "Finished training for epoch 3759, loss: 0.279, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3760, loss: 0.276, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3761, loss: 0.286, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3762, loss: 0.283, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3763, loss: 0.285, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3764, loss: 0.270, accuracy: 0.765, training set size: 2440\n",
      "Finished training for epoch 3765, loss: 0.316, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3766, loss: 0.293, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3767, loss: 0.303, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3768, loss: 0.284, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3769, loss: 0.292, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3770, loss: 0.268, accuracy: 0.770, training set size: 2440\n",
      "Finished training for epoch 3771, loss: 0.289, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3772, loss: 0.265, accuracy: 0.771, training set size: 2440\n",
      "Finished training for epoch 3773, loss: 0.309, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3774, loss: 0.279, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3775, loss: 0.272, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3776, loss: 0.292, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3777, loss: 0.315, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3778, loss: 0.305, accuracy: 0.744, training set size: 2440\n",
      "Finished training for epoch 3779, loss: 0.294, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3780, loss: 0.278, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3781, loss: 0.295, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3782, loss: 0.300, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3783, loss: 0.284, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3784, loss: 0.287, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3785, loss: 0.292, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3786, loss: 0.291, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3787, loss: 0.292, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3788, loss: 0.283, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3789, loss: 0.305, accuracy: 0.739, training set size: 2440\n",
      "Finished training for epoch 3790, loss: 0.277, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3791, loss: 0.270, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3792, loss: 0.270, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3793, loss: 0.316, accuracy: 0.732, training set size: 2440\n",
      "Finished training for epoch 3794, loss: 0.303, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3795, loss: 0.270, accuracy: 0.769, training set size: 2440\n",
      "Finished training for epoch 3796, loss: 0.264, accuracy: 0.768, training set size: 2440\n",
      "Finished training for epoch 3797, loss: 0.269, accuracy: 0.769, training set size: 2440\n",
      "Finished training for epoch 3798, loss: 0.275, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3799, loss: 0.279, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3800, loss: 0.300, accuracy: 0.744, training set size: 2440\n",
      "Finished training for epoch 3801, loss: 0.309, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3802, loss: 0.269, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3803, loss: 0.295, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3804, loss: 0.288, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3805, loss: 0.279, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3806, loss: 0.281, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3807, loss: 0.271, accuracy: 0.768, training set size: 2440\n",
      "Finished training for epoch 3808, loss: 0.287, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3809, loss: 0.285, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3810, loss: 0.271, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3811, loss: 0.303, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3812, loss: 0.289, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3813, loss: 0.283, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3814, loss: 0.277, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3815, loss: 0.283, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3816, loss: 0.306, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3817, loss: 0.276, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3818, loss: 0.277, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3819, loss: 0.311, accuracy: 0.735, training set size: 2440\n",
      "Finished training for epoch 3820, loss: 0.269, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3821, loss: 0.310, accuracy: 0.739, training set size: 2440\n",
      "Finished training for epoch 3822, loss: 0.284, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3823, loss: 0.279, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3824, loss: 0.292, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3825, loss: 0.273, accuracy: 0.768, training set size: 2440\n",
      "Finished training for epoch 3826, loss: 0.286, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3827, loss: 0.281, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3828, loss: 0.288, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3829, loss: 0.316, accuracy: 0.739, training set size: 2440\n",
      "Finished training for epoch 3830, loss: 0.278, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3831, loss: 0.273, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3832, loss: 0.321, accuracy: 0.735, training set size: 2440\n",
      "Finished training for epoch 3833, loss: 0.276, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3834, loss: 0.291, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3835, loss: 0.338, accuracy: 0.732, training set size: 2440\n",
      "Finished training for epoch 3836, loss: 0.291, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3837, loss: 0.283, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3838, loss: 0.297, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3839, loss: 0.331, accuracy: 0.735, training set size: 2440\n",
      "Finished training for epoch 3840, loss: 0.283, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3841, loss: 0.274, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3842, loss: 0.262, accuracy: 0.774, training set size: 2440\n",
      "Finished training for epoch 3843, loss: 0.283, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3844, loss: 0.273, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3845, loss: 0.318, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3846, loss: 0.297, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3847, loss: 0.299, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3848, loss: 0.285, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3849, loss: 0.301, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3850, loss: 0.286, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3851, loss: 0.273, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3852, loss: 0.290, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3853, loss: 0.270, accuracy: 0.770, training set size: 2440\n",
      "Finished training for epoch 3854, loss: 0.271, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3855, loss: 0.278, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3856, loss: 0.289, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3857, loss: 0.293, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3858, loss: 0.286, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3859, loss: 0.254, accuracy: 0.776, training set size: 2440\n",
      "Finished training for epoch 3860, loss: 0.283, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3861, loss: 0.283, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3862, loss: 0.292, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3863, loss: 0.293, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3864, loss: 0.280, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3865, loss: 0.294, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3866, loss: 0.291, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3867, loss: 0.276, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3868, loss: 0.277, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3869, loss: 0.260, accuracy: 0.772, training set size: 2440\n",
      "Finished training for epoch 3870, loss: 0.288, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3871, loss: 0.273, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3872, loss: 0.283, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3873, loss: 0.279, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3874, loss: 0.276, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3875, loss: 0.289, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3876, loss: 0.288, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3877, loss: 0.283, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3878, loss: 0.289, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3879, loss: 0.274, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3880, loss: 0.278, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3881, loss: 0.280, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3882, loss: 0.271, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3883, loss: 0.288, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3884, loss: 0.270, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3885, loss: 0.289, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3886, loss: 0.279, accuracy: 0.763, training set size: 2440\n",
      "Finished training for epoch 3887, loss: 0.319, accuracy: 0.736, training set size: 2440\n",
      "Finished training for epoch 3888, loss: 0.274, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3889, loss: 0.278, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3890, loss: 0.287, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3891, loss: 0.304, accuracy: 0.744, training set size: 2440\n",
      "Finished training for epoch 3892, loss: 0.294, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3893, loss: 0.317, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3894, loss: 0.275, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3895, loss: 0.270, accuracy: 0.769, training set size: 2440\n",
      "Finished training for epoch 3896, loss: 0.283, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3897, loss: 0.309, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3898, loss: 0.295, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3899, loss: 0.318, accuracy: 0.738, training set size: 2440\n",
      "Finished training for epoch 3900, loss: 0.305, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3901, loss: 0.270, accuracy: 0.768, training set size: 2440\n",
      "Finished training for epoch 3902, loss: 0.307, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3903, loss: 0.267, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3904, loss: 0.300, accuracy: 0.743, training set size: 2440\n",
      "Finished training for epoch 3905, loss: 0.283, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3906, loss: 0.307, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3907, loss: 0.275, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3908, loss: 0.294, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3909, loss: 0.297, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3910, loss: 0.277, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3911, loss: 0.280, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3912, loss: 0.295, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3913, loss: 0.287, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3914, loss: 0.277, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3915, loss: 0.290, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3916, loss: 0.270, accuracy: 0.765, training set size: 2440\n",
      "Finished training for epoch 3917, loss: 0.292, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3918, loss: 0.275, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3919, loss: 0.290, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3920, loss: 0.301, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3921, loss: 0.274, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3922, loss: 0.274, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3923, loss: 0.288, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3924, loss: 0.273, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3925, loss: 0.273, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3926, loss: 0.282, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3927, loss: 0.315, accuracy: 0.734, training set size: 2440\n",
      "Finished training for epoch 3928, loss: 0.290, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3929, loss: 0.270, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3930, loss: 0.319, accuracy: 0.735, training set size: 2440\n",
      "Finished training for epoch 3931, loss: 0.298, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3932, loss: 0.291, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3933, loss: 0.286, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3934, loss: 0.276, accuracy: 0.765, training set size: 2440\n",
      "Finished training for epoch 3935, loss: 0.303, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3936, loss: 0.285, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3937, loss: 0.293, accuracy: 0.745, training set size: 2440\n",
      "Finished training for epoch 3938, loss: 0.277, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3939, loss: 0.282, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3940, loss: 0.275, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3941, loss: 0.294, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3942, loss: 0.286, accuracy: 0.759, training set size: 2440\n",
      "Finished training for epoch 3943, loss: 0.303, accuracy: 0.744, training set size: 2440\n",
      "Finished training for epoch 3944, loss: 0.290, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3945, loss: 0.297, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3946, loss: 0.280, accuracy: 0.760, training set size: 2440\n",
      "Finished training for epoch 3947, loss: 0.267, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3948, loss: 0.281, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3949, loss: 0.263, accuracy: 0.768, training set size: 2440\n",
      "Finished training for epoch 3950, loss: 0.276, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3951, loss: 0.289, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3952, loss: 0.336, accuracy: 0.735, training set size: 2440\n",
      "Finished training for epoch 3953, loss: 0.282, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3954, loss: 0.267, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3955, loss: 0.287, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3956, loss: 0.288, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3957, loss: 0.278, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3958, loss: 0.275, accuracy: 0.768, training set size: 2440\n",
      "Finished training for epoch 3959, loss: 0.291, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3960, loss: 0.300, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3961, loss: 0.268, accuracy: 0.770, training set size: 2440\n",
      "Finished training for epoch 3962, loss: 0.322, accuracy: 0.737, training set size: 2440\n",
      "Finished training for epoch 3963, loss: 0.273, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3964, loss: 0.282, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3965, loss: 0.289, accuracy: 0.758, training set size: 2440\n",
      "Finished training for epoch 3966, loss: 0.295, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3967, loss: 0.294, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3968, loss: 0.280, accuracy: 0.757, training set size: 2440\n",
      "Finished training for epoch 3969, loss: 0.290, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3970, loss: 0.267, accuracy: 0.768, training set size: 2440\n",
      "Finished training for epoch 3971, loss: 0.288, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3972, loss: 0.302, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3973, loss: 0.294, accuracy: 0.750, training set size: 2440\n",
      "Finished training for epoch 3974, loss: 0.300, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 3975, loss: 0.262, accuracy: 0.777, training set size: 2440\n",
      "Finished training for epoch 3976, loss: 0.285, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3977, loss: 0.284, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3978, loss: 0.272, accuracy: 0.766, training set size: 2440\n",
      "Finished training for epoch 3979, loss: 0.295, accuracy: 0.747, training set size: 2440\n",
      "Finished training for epoch 3980, loss: 0.279, accuracy: 0.761, training set size: 2440\n",
      "Finished training for epoch 3981, loss: 0.311, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3982, loss: 0.278, accuracy: 0.756, training set size: 2440\n",
      "Finished training for epoch 3983, loss: 0.285, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3984, loss: 0.296, accuracy: 0.748, training set size: 2440\n",
      "Finished training for epoch 3985, loss: 0.300, accuracy: 0.749, training set size: 2440\n",
      "Finished training for epoch 3986, loss: 0.291, accuracy: 0.754, training set size: 2440\n",
      "Finished training for epoch 3987, loss: 0.291, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3988, loss: 0.315, accuracy: 0.735, training set size: 2440\n",
      "Finished training for epoch 3989, loss: 0.293, accuracy: 0.752, training set size: 2440\n",
      "Finished training for epoch 3990, loss: 0.281, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3991, loss: 0.306, accuracy: 0.741, training set size: 2440\n",
      "Finished training for epoch 3992, loss: 0.276, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3993, loss: 0.282, accuracy: 0.762, training set size: 2440\n",
      "Finished training for epoch 3994, loss: 0.279, accuracy: 0.764, training set size: 2440\n",
      "Finished training for epoch 3995, loss: 0.277, accuracy: 0.755, training set size: 2440\n",
      "Finished training for epoch 3996, loss: 0.300, accuracy: 0.751, training set size: 2440\n",
      "Finished training for epoch 3997, loss: 0.291, accuracy: 0.753, training set size: 2440\n",
      "Finished training for epoch 3998, loss: 0.278, accuracy: 0.767, training set size: 2440\n",
      "Finished training for epoch 3999, loss: 0.305, accuracy: 0.740, training set size: 2440\n",
      "Finished training for epoch 4000, loss: 0.292, accuracy: 0.746, training set size: 2440\n",
      "Finished training for epoch 4001, loss: 0.370, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4002, loss: 0.368, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4003, loss: 0.353, accuracy: 0.632, training set size: 3060\n",
      "Finished training for epoch 4004, loss: 0.374, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4005, loss: 0.376, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4006, loss: 0.372, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4007, loss: 0.362, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4008, loss: 0.376, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4009, loss: 0.391, accuracy: 0.609, training set size: 3060\n",
      "Finished training for epoch 4010, loss: 0.357, accuracy: 0.632, training set size: 3060\n",
      "Finished training for epoch 4011, loss: 0.371, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4012, loss: 0.373, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4013, loss: 0.369, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4014, loss: 0.371, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4015, loss: 0.363, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4016, loss: 0.375, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4017, loss: 0.367, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4018, loss: 0.387, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4019, loss: 0.368, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4020, loss: 0.362, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4021, loss: 0.376, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4022, loss: 0.361, accuracy: 0.634, training set size: 3060\n",
      "Finished training for epoch 4023, loss: 0.370, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4024, loss: 0.372, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4025, loss: 0.365, accuracy: 0.632, training set size: 3060\n",
      "Finished training for epoch 4026, loss: 0.353, accuracy: 0.639, training set size: 3060\n",
      "Finished training for epoch 4027, loss: 0.363, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4028, loss: 0.371, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4029, loss: 0.367, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4030, loss: 0.377, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4031, loss: 0.372, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4032, loss: 0.377, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4033, loss: 0.399, accuracy: 0.606, training set size: 3060\n",
      "Finished training for epoch 4034, loss: 0.363, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4035, loss: 0.369, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4036, loss: 0.361, accuracy: 0.632, training set size: 3060\n",
      "Finished training for epoch 4037, loss: 0.369, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4038, loss: 0.379, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4039, loss: 0.373, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4040, loss: 0.390, accuracy: 0.604, training set size: 3060\n",
      "Finished training for epoch 4041, loss: 0.388, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4042, loss: 0.376, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4043, loss: 0.364, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4044, loss: 0.363, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4045, loss: 0.364, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4046, loss: 0.379, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4047, loss: 0.377, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4048, loss: 0.372, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4049, loss: 0.363, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4050, loss: 0.385, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4051, loss: 0.372, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4052, loss: 0.369, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4053, loss: 0.373, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4054, loss: 0.368, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4055, loss: 0.385, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4056, loss: 0.367, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4057, loss: 0.373, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4058, loss: 0.371, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4059, loss: 0.372, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4060, loss: 0.363, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4061, loss: 0.402, accuracy: 0.602, training set size: 3060\n",
      "Finished training for epoch 4062, loss: 0.371, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4063, loss: 0.385, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4064, loss: 0.364, accuracy: 0.631, training set size: 3060\n",
      "Finished training for epoch 4065, loss: 0.367, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4066, loss: 0.403, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4067, loss: 0.384, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4068, loss: 0.361, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4069, loss: 0.375, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4070, loss: 0.371, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4071, loss: 0.356, accuracy: 0.636, training set size: 3060\n",
      "Finished training for epoch 4072, loss: 0.371, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4073, loss: 0.371, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4074, loss: 0.364, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4075, loss: 0.390, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4076, loss: 0.366, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4077, loss: 0.369, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4078, loss: 0.359, accuracy: 0.633, training set size: 3060\n",
      "Finished training for epoch 4079, loss: 0.375, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4080, loss: 0.368, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4081, loss: 0.365, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4082, loss: 0.372, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4083, loss: 0.365, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4084, loss: 0.385, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4085, loss: 0.373, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4086, loss: 0.373, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4087, loss: 0.365, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4088, loss: 0.374, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4089, loss: 0.373, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4090, loss: 0.371, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4091, loss: 0.383, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4092, loss: 0.361, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4093, loss: 0.372, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4094, loss: 0.361, accuracy: 0.632, training set size: 3060\n",
      "Finished training for epoch 4095, loss: 0.389, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4096, loss: 0.374, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4097, loss: 0.362, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4098, loss: 0.366, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4099, loss: 0.365, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4100, loss: 0.407, accuracy: 0.604, training set size: 3060\n",
      "Finished training for epoch 4101, loss: 0.369, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4102, loss: 0.378, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4103, loss: 0.372, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4104, loss: 0.371, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4105, loss: 0.377, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4106, loss: 0.375, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4107, loss: 0.368, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4108, loss: 0.382, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4109, loss: 0.380, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4110, loss: 0.399, accuracy: 0.604, training set size: 3060\n",
      "Finished training for epoch 4111, loss: 0.373, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4112, loss: 0.365, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4113, loss: 0.383, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4114, loss: 0.370, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4115, loss: 0.382, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4116, loss: 0.362, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4117, loss: 0.404, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4118, loss: 0.373, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4119, loss: 0.390, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4120, loss: 0.375, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4121, loss: 0.374, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4122, loss: 0.378, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4123, loss: 0.394, accuracy: 0.609, training set size: 3060\n",
      "Finished training for epoch 4124, loss: 0.384, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4125, loss: 0.364, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4126, loss: 0.368, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4127, loss: 0.376, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4128, loss: 0.368, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4129, loss: 0.385, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4130, loss: 0.385, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4131, loss: 0.382, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4132, loss: 0.369, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4133, loss: 0.379, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4134, loss: 0.385, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4135, loss: 0.371, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4136, loss: 0.367, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4137, loss: 0.372, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4138, loss: 0.375, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4139, loss: 0.378, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4140, loss: 0.387, accuracy: 0.608, training set size: 3060\n",
      "Finished training for epoch 4141, loss: 0.368, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4142, loss: 0.361, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4143, loss: 0.377, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4144, loss: 0.379, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4145, loss: 0.374, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4146, loss: 0.374, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4147, loss: 0.372, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4148, loss: 0.389, accuracy: 0.610, training set size: 3060\n",
      "Finished training for epoch 4149, loss: 0.387, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4150, loss: 0.374, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4151, loss: 0.374, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4152, loss: 0.367, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4153, loss: 0.377, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4154, loss: 0.374, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4155, loss: 0.351, accuracy: 0.636, training set size: 3060\n",
      "Finished training for epoch 4156, loss: 0.372, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4157, loss: 0.372, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4158, loss: 0.370, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4159, loss: 0.373, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4160, loss: 0.376, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4161, loss: 0.372, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4162, loss: 0.380, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4163, loss: 0.371, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4164, loss: 0.369, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4165, loss: 0.391, accuracy: 0.609, training set size: 3060\n",
      "Finished training for epoch 4166, loss: 0.366, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4167, loss: 0.381, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4168, loss: 0.379, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4169, loss: 0.365, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4170, loss: 0.370, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4171, loss: 0.369, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4172, loss: 0.376, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4173, loss: 0.360, accuracy: 0.633, training set size: 3060\n",
      "Finished training for epoch 4174, loss: 0.367, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4175, loss: 0.380, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4176, loss: 0.375, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4177, loss: 0.377, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4178, loss: 0.366, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4179, loss: 0.369, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4180, loss: 0.357, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4181, loss: 0.372, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4182, loss: 0.368, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4183, loss: 0.392, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4184, loss: 0.368, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4185, loss: 0.369, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4186, loss: 0.373, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4187, loss: 0.369, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4188, loss: 0.375, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4189, loss: 0.384, accuracy: 0.610, training set size: 3060\n",
      "Finished training for epoch 4190, loss: 0.373, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4191, loss: 0.388, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4192, loss: 0.379, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4193, loss: 0.360, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4194, loss: 0.381, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4195, loss: 0.368, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4196, loss: 0.373, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4197, loss: 0.370, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4198, loss: 0.389, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4199, loss: 0.373, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4200, loss: 0.383, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4201, loss: 0.383, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4202, loss: 0.380, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4203, loss: 0.366, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4204, loss: 0.366, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4205, loss: 0.373, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4206, loss: 0.373, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4207, loss: 0.366, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4208, loss: 0.375, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4209, loss: 0.373, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4210, loss: 0.377, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4211, loss: 0.374, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4212, loss: 0.373, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4213, loss: 0.365, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4214, loss: 0.388, accuracy: 0.610, training set size: 3060\n",
      "Finished training for epoch 4215, loss: 0.371, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4216, loss: 0.379, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4217, loss: 0.374, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4218, loss: 0.364, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4219, loss: 0.375, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4220, loss: 0.370, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4221, loss: 0.372, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4222, loss: 0.377, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4223, loss: 0.367, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4224, loss: 0.373, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4225, loss: 0.373, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4226, loss: 0.394, accuracy: 0.608, training set size: 3060\n",
      "Finished training for epoch 4227, loss: 0.376, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4228, loss: 0.378, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4229, loss: 0.362, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4230, loss: 0.385, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4231, loss: 0.379, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4232, loss: 0.368, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4233, loss: 0.385, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4234, loss: 0.367, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4235, loss: 0.368, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4236, loss: 0.362, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4237, loss: 0.370, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4238, loss: 0.378, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4239, loss: 0.362, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4240, loss: 0.375, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4241, loss: 0.379, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4242, loss: 0.372, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4243, loss: 0.379, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4244, loss: 0.379, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4245, loss: 0.385, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4246, loss: 0.375, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4247, loss: 0.361, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4248, loss: 0.387, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4249, loss: 0.369, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4250, loss: 0.380, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4251, loss: 0.368, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4252, loss: 0.376, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4253, loss: 0.369, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4254, loss: 0.372, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4255, loss: 0.368, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4256, loss: 0.365, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4257, loss: 0.378, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4258, loss: 0.377, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4259, loss: 0.362, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4260, loss: 0.367, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4261, loss: 0.376, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4262, loss: 0.366, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4263, loss: 0.367, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4264, loss: 0.374, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4265, loss: 0.371, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4266, loss: 0.381, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4267, loss: 0.377, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4268, loss: 0.376, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4269, loss: 0.375, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4270, loss: 0.366, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4271, loss: 0.372, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4272, loss: 0.377, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4273, loss: 0.382, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4274, loss: 0.363, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4275, loss: 0.386, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4276, loss: 0.377, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4277, loss: 0.382, accuracy: 0.609, training set size: 3060\n",
      "Finished training for epoch 4278, loss: 0.365, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4279, loss: 0.359, accuracy: 0.632, training set size: 3060\n",
      "Finished training for epoch 4280, loss: 0.365, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4281, loss: 0.382, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4282, loss: 0.384, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4283, loss: 0.367, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4284, loss: 0.381, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4285, loss: 0.374, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4286, loss: 0.383, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4287, loss: 0.372, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4288, loss: 0.374, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4289, loss: 0.374, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4290, loss: 0.358, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4291, loss: 0.361, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4292, loss: 0.367, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4293, loss: 0.362, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4294, loss: 0.388, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4295, loss: 0.379, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4296, loss: 0.366, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4297, loss: 0.366, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4298, loss: 0.384, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4299, loss: 0.369, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4300, loss: 0.360, accuracy: 0.631, training set size: 3060\n",
      "Finished training for epoch 4301, loss: 0.381, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4302, loss: 0.380, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4303, loss: 0.388, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4304, loss: 0.370, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4305, loss: 0.387, accuracy: 0.608, training set size: 3060\n",
      "Finished training for epoch 4306, loss: 0.363, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4307, loss: 0.361, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4308, loss: 0.365, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4309, loss: 0.381, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4310, loss: 0.373, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4311, loss: 0.370, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4312, loss: 0.370, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4313, loss: 0.379, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4314, loss: 0.358, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4315, loss: 0.387, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4316, loss: 0.366, accuracy: 0.632, training set size: 3060\n",
      "Finished training for epoch 4317, loss: 0.371, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4318, loss: 0.394, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4319, loss: 0.372, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4320, loss: 0.388, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4321, loss: 0.375, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4322, loss: 0.386, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4323, loss: 0.374, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4324, loss: 0.379, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4325, loss: 0.377, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4326, loss: 0.367, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4327, loss: 0.390, accuracy: 0.608, training set size: 3060\n",
      "Finished training for epoch 4328, loss: 0.368, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4329, loss: 0.362, accuracy: 0.631, training set size: 3060\n",
      "Finished training for epoch 4330, loss: 0.364, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4331, loss: 0.387, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4332, loss: 0.381, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4333, loss: 0.360, accuracy: 0.632, training set size: 3060\n",
      "Finished training for epoch 4334, loss: 0.389, accuracy: 0.610, training set size: 3060\n",
      "Finished training for epoch 4335, loss: 0.371, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4336, loss: 0.367, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4337, loss: 0.386, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4338, loss: 0.381, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4339, loss: 0.374, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4340, loss: 0.369, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4341, loss: 0.367, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4342, loss: 0.364, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4343, loss: 0.373, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4344, loss: 0.378, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4345, loss: 0.366, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4346, loss: 0.372, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4347, loss: 0.374, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4348, loss: 0.357, accuracy: 0.632, training set size: 3060\n",
      "Finished training for epoch 4349, loss: 0.374, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4350, loss: 0.386, accuracy: 0.609, training set size: 3060\n",
      "Finished training for epoch 4351, loss: 0.371, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4352, loss: 0.373, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4353, loss: 0.364, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4354, loss: 0.365, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4355, loss: 0.385, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4356, loss: 0.373, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4357, loss: 0.369, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4358, loss: 0.377, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4359, loss: 0.370, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4360, loss: 0.361, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4361, loss: 0.385, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4362, loss: 0.363, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4363, loss: 0.379, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4364, loss: 0.397, accuracy: 0.605, training set size: 3060\n",
      "Finished training for epoch 4365, loss: 0.387, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4366, loss: 0.367, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4367, loss: 0.367, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4368, loss: 0.365, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4369, loss: 0.379, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4370, loss: 0.378, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4371, loss: 0.374, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4372, loss: 0.371, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4373, loss: 0.372, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4374, loss: 0.360, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4375, loss: 0.369, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4376, loss: 0.367, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4377, loss: 0.382, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4378, loss: 0.366, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4379, loss: 0.388, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4380, loss: 0.371, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4381, loss: 0.376, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4382, loss: 0.375, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4383, loss: 0.372, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4384, loss: 0.374, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4385, loss: 0.372, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4386, loss: 0.379, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4387, loss: 0.385, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4388, loss: 0.372, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4389, loss: 0.370, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4390, loss: 0.368, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4391, loss: 0.370, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4392, loss: 0.375, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4393, loss: 0.370, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4394, loss: 0.370, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4395, loss: 0.366, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4396, loss: 0.369, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4397, loss: 0.366, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4398, loss: 0.385, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4399, loss: 0.370, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4400, loss: 0.382, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4401, loss: 0.372, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4402, loss: 0.371, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4403, loss: 0.365, accuracy: 0.633, training set size: 3060\n",
      "Finished training for epoch 4404, loss: 0.380, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4405, loss: 0.368, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4406, loss: 0.376, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4407, loss: 0.369, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4408, loss: 0.373, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4409, loss: 0.392, accuracy: 0.607, training set size: 3060\n",
      "Finished training for epoch 4410, loss: 0.376, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4411, loss: 0.387, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4412, loss: 0.359, accuracy: 0.632, training set size: 3060\n",
      "Finished training for epoch 4413, loss: 0.355, accuracy: 0.634, training set size: 3060\n",
      "Finished training for epoch 4414, loss: 0.387, accuracy: 0.610, training set size: 3060\n",
      "Finished training for epoch 4415, loss: 0.375, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4416, loss: 0.363, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4417, loss: 0.375, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4418, loss: 0.375, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4419, loss: 0.363, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4420, loss: 0.365, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4421, loss: 0.365, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4422, loss: 0.371, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4423, loss: 0.364, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4424, loss: 0.365, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4425, loss: 0.390, accuracy: 0.605, training set size: 3060\n",
      "Finished training for epoch 4426, loss: 0.367, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4427, loss: 0.371, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4428, loss: 0.364, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4429, loss: 0.371, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4430, loss: 0.354, accuracy: 0.634, training set size: 3060\n",
      "Finished training for epoch 4431, loss: 0.364, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4432, loss: 0.380, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4433, loss: 0.373, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4434, loss: 0.366, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4435, loss: 0.369, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4436, loss: 0.377, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4437, loss: 0.373, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4438, loss: 0.375, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4439, loss: 0.376, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4440, loss: 0.382, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4441, loss: 0.378, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4442, loss: 0.356, accuracy: 0.633, training set size: 3060\n",
      "Finished training for epoch 4443, loss: 0.375, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4444, loss: 0.372, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4445, loss: 0.367, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4446, loss: 0.378, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4447, loss: 0.368, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4448, loss: 0.369, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4449, loss: 0.368, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4450, loss: 0.380, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4451, loss: 0.388, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4452, loss: 0.390, accuracy: 0.608, training set size: 3060\n",
      "Finished training for epoch 4453, loss: 0.372, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4454, loss: 0.370, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4455, loss: 0.376, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4456, loss: 0.369, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4457, loss: 0.379, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4458, loss: 0.361, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4459, loss: 0.369, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4460, loss: 0.368, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4461, loss: 0.379, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4462, loss: 0.382, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4463, loss: 0.363, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4464, loss: 0.402, accuracy: 0.604, training set size: 3060\n",
      "Finished training for epoch 4465, loss: 0.375, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4466, loss: 0.363, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4467, loss: 0.381, accuracy: 0.609, training set size: 3060\n",
      "Finished training for epoch 4468, loss: 0.375, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4469, loss: 0.383, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4470, loss: 0.359, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4471, loss: 0.377, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4472, loss: 0.371, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4473, loss: 0.375, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4474, loss: 0.363, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4475, loss: 0.382, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4476, loss: 0.374, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4477, loss: 0.367, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4478, loss: 0.375, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4479, loss: 0.356, accuracy: 0.633, training set size: 3060\n",
      "Finished training for epoch 4480, loss: 0.363, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4481, loss: 0.360, accuracy: 0.633, training set size: 3060\n",
      "Finished training for epoch 4482, loss: 0.363, accuracy: 0.631, training set size: 3060\n",
      "Finished training for epoch 4483, loss: 0.377, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4484, loss: 0.370, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4485, loss: 0.376, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4486, loss: 0.364, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4487, loss: 0.385, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4488, loss: 0.389, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4489, loss: 0.373, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4490, loss: 0.359, accuracy: 0.632, training set size: 3060\n",
      "Finished training for epoch 4491, loss: 0.371, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4492, loss: 0.367, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4493, loss: 0.379, accuracy: 0.610, training set size: 3060\n",
      "Finished training for epoch 4494, loss: 0.380, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4495, loss: 0.378, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4496, loss: 0.366, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4497, loss: 0.376, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4498, loss: 0.376, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4499, loss: 0.389, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4500, loss: 0.374, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4501, loss: 0.379, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4502, loss: 0.376, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4503, loss: 0.368, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4504, loss: 0.389, accuracy: 0.605, training set size: 3060\n",
      "Finished training for epoch 4505, loss: 0.392, accuracy: 0.606, training set size: 3060\n",
      "Finished training for epoch 4506, loss: 0.360, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4507, loss: 0.363, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4508, loss: 0.384, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4509, loss: 0.366, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4510, loss: 0.378, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4511, loss: 0.372, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4512, loss: 0.364, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4513, loss: 0.373, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4514, loss: 0.372, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4515, loss: 0.364, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4516, loss: 0.361, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4517, loss: 0.361, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4518, loss: 0.370, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4519, loss: 0.363, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4520, loss: 0.379, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4521, loss: 0.370, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4522, loss: 0.373, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4523, loss: 0.370, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4524, loss: 0.370, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4525, loss: 0.367, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4526, loss: 0.372, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4527, loss: 0.367, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4528, loss: 0.362, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4529, loss: 0.386, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4530, loss: 0.376, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4531, loss: 0.362, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4532, loss: 0.366, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4533, loss: 0.364, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4534, loss: 0.357, accuracy: 0.635, training set size: 3060\n",
      "Finished training for epoch 4535, loss: 0.375, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4536, loss: 0.366, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4537, loss: 0.365, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4538, loss: 0.374, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4539, loss: 0.379, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4540, loss: 0.378, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4541, loss: 0.367, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4542, loss: 0.375, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4543, loss: 0.373, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4544, loss: 0.364, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4545, loss: 0.380, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4546, loss: 0.389, accuracy: 0.608, training set size: 3060\n",
      "Finished training for epoch 4547, loss: 0.360, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4548, loss: 0.389, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4549, loss: 0.367, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4550, loss: 0.383, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4551, loss: 0.383, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4552, loss: 0.369, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4553, loss: 0.363, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4554, loss: 0.375, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4555, loss: 0.364, accuracy: 0.631, training set size: 3060\n",
      "Finished training for epoch 4556, loss: 0.371, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4557, loss: 0.366, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4558, loss: 0.360, accuracy: 0.635, training set size: 3060\n",
      "Finished training for epoch 4559, loss: 0.372, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4560, loss: 0.361, accuracy: 0.631, training set size: 3060\n",
      "Finished training for epoch 4561, loss: 0.373, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4562, loss: 0.387, accuracy: 0.610, training set size: 3060\n",
      "Finished training for epoch 4563, loss: 0.366, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4564, loss: 0.369, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4565, loss: 0.396, accuracy: 0.610, training set size: 3060\n",
      "Finished training for epoch 4566, loss: 0.381, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4567, loss: 0.376, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4568, loss: 0.362, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4569, loss: 0.370, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4570, loss: 0.363, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4571, loss: 0.379, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4572, loss: 0.380, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4573, loss: 0.373, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4574, loss: 0.356, accuracy: 0.632, training set size: 3060\n",
      "Finished training for epoch 4575, loss: 0.364, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4576, loss: 0.378, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4577, loss: 0.382, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4578, loss: 0.368, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4579, loss: 0.377, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4580, loss: 0.366, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4581, loss: 0.363, accuracy: 0.631, training set size: 3060\n",
      "Finished training for epoch 4582, loss: 0.401, accuracy: 0.609, training set size: 3060\n",
      "Finished training for epoch 4583, loss: 0.379, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4584, loss: 0.371, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4585, loss: 0.347, accuracy: 0.643, training set size: 3060\n",
      "Finished training for epoch 4586, loss: 0.405, accuracy: 0.599, training set size: 3060\n",
      "Finished training for epoch 4587, loss: 0.366, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4588, loss: 0.376, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4589, loss: 0.385, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4590, loss: 0.373, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4591, loss: 0.371, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4592, loss: 0.362, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4593, loss: 0.383, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4594, loss: 0.368, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4595, loss: 0.382, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4596, loss: 0.372, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4597, loss: 0.372, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4598, loss: 0.402, accuracy: 0.605, training set size: 3060\n",
      "Finished training for epoch 4599, loss: 0.374, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4600, loss: 0.368, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4601, loss: 0.374, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4602, loss: 0.373, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4603, loss: 0.356, accuracy: 0.632, training set size: 3060\n",
      "Finished training for epoch 4604, loss: 0.372, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4605, loss: 0.360, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4606, loss: 0.373, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4607, loss: 0.374, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4608, loss: 0.386, accuracy: 0.608, training set size: 3060\n",
      "Finished training for epoch 4609, loss: 0.375, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4610, loss: 0.361, accuracy: 0.633, training set size: 3060\n",
      "Finished training for epoch 4611, loss: 0.377, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4612, loss: 0.361, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4613, loss: 0.359, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4614, loss: 0.358, accuracy: 0.633, training set size: 3060\n",
      "Finished training for epoch 4615, loss: 0.381, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4616, loss: 0.367, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4617, loss: 0.380, accuracy: 0.609, training set size: 3060\n",
      "Finished training for epoch 4618, loss: 0.368, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4619, loss: 0.379, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4620, loss: 0.374, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4621, loss: 0.373, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4622, loss: 0.388, accuracy: 0.607, training set size: 3060\n",
      "Finished training for epoch 4623, loss: 0.405, accuracy: 0.601, training set size: 3060\n",
      "Finished training for epoch 4624, loss: 0.379, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4625, loss: 0.368, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4626, loss: 0.386, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4627, loss: 0.375, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4628, loss: 0.363, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4629, loss: 0.386, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4630, loss: 0.419, accuracy: 0.600, training set size: 3060\n",
      "Finished training for epoch 4631, loss: 0.370, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4632, loss: 0.370, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4633, loss: 0.368, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4634, loss: 0.379, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4635, loss: 0.387, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4636, loss: 0.385, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4637, loss: 0.361, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4638, loss: 0.366, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4639, loss: 0.366, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4640, loss: 0.365, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4641, loss: 0.357, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4642, loss: 0.369, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4643, loss: 0.374, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4644, loss: 0.374, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4645, loss: 0.402, accuracy: 0.601, training set size: 3060\n",
      "Finished training for epoch 4646, loss: 0.377, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4647, loss: 0.392, accuracy: 0.610, training set size: 3060\n",
      "Finished training for epoch 4648, loss: 0.375, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4649, loss: 0.364, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4650, loss: 0.371, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4651, loss: 0.376, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4652, loss: 0.392, accuracy: 0.609, training set size: 3060\n",
      "Finished training for epoch 4653, loss: 0.369, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4654, loss: 0.365, accuracy: 0.632, training set size: 3060\n",
      "Finished training for epoch 4655, loss: 0.378, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4656, loss: 0.393, accuracy: 0.609, training set size: 3060\n",
      "Finished training for epoch 4657, loss: 0.374, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4658, loss: 0.389, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4659, loss: 0.375, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4660, loss: 0.380, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4661, loss: 0.364, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4662, loss: 0.379, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4663, loss: 0.376, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4664, loss: 0.385, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4665, loss: 0.371, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4666, loss: 0.375, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4667, loss: 0.365, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4668, loss: 0.364, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4669, loss: 0.379, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4670, loss: 0.382, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4671, loss: 0.381, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4672, loss: 0.389, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4673, loss: 0.370, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4674, loss: 0.377, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4675, loss: 0.379, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4676, loss: 0.373, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4677, loss: 0.377, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4678, loss: 0.372, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4679, loss: 0.360, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4680, loss: 0.376, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4681, loss: 0.387, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4682, loss: 0.374, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4683, loss: 0.371, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4684, loss: 0.364, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4685, loss: 0.365, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4686, loss: 0.381, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4687, loss: 0.383, accuracy: 0.609, training set size: 3060\n",
      "Finished training for epoch 4688, loss: 0.383, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4689, loss: 0.374, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4690, loss: 0.360, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4691, loss: 0.371, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4692, loss: 0.384, accuracy: 0.609, training set size: 3060\n",
      "Finished training for epoch 4693, loss: 0.376, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4694, loss: 0.365, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4695, loss: 0.376, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4696, loss: 0.365, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4697, loss: 0.365, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4698, loss: 0.373, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4699, loss: 0.370, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4700, loss: 0.373, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4701, loss: 0.371, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4702, loss: 0.377, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4703, loss: 0.375, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4704, loss: 0.363, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4705, loss: 0.380, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4706, loss: 0.372, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4707, loss: 0.361, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4708, loss: 0.357, accuracy: 0.633, training set size: 3060\n",
      "Finished training for epoch 4709, loss: 0.376, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4710, loss: 0.370, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4711, loss: 0.372, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4712, loss: 0.374, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4713, loss: 0.369, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4714, loss: 0.360, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4715, loss: 0.373, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4716, loss: 0.364, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4717, loss: 0.379, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4718, loss: 0.366, accuracy: 0.632, training set size: 3060\n",
      "Finished training for epoch 4719, loss: 0.359, accuracy: 0.634, training set size: 3060\n",
      "Finished training for epoch 4720, loss: 0.391, accuracy: 0.607, training set size: 3060\n",
      "Finished training for epoch 4721, loss: 0.364, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4722, loss: 0.391, accuracy: 0.608, training set size: 3060\n",
      "Finished training for epoch 4723, loss: 0.389, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4724, loss: 0.378, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4725, loss: 0.382, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4726, loss: 0.378, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4727, loss: 0.372, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4728, loss: 0.373, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4729, loss: 0.381, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4730, loss: 0.358, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4731, loss: 0.394, accuracy: 0.609, training set size: 3060\n",
      "Finished training for epoch 4732, loss: 0.378, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4733, loss: 0.365, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4734, loss: 0.385, accuracy: 0.608, training set size: 3060\n",
      "Finished training for epoch 4735, loss: 0.387, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4736, loss: 0.376, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4737, loss: 0.369, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4738, loss: 0.363, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4739, loss: 0.379, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4740, loss: 0.379, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4741, loss: 0.366, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4742, loss: 0.362, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4743, loss: 0.362, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4744, loss: 0.389, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4745, loss: 0.387, accuracy: 0.606, training set size: 3060\n",
      "Finished training for epoch 4746, loss: 0.367, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4747, loss: 0.372, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4748, loss: 0.385, accuracy: 0.607, training set size: 3060\n",
      "Finished training for epoch 4749, loss: 0.366, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4750, loss: 0.365, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4751, loss: 0.369, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4752, loss: 0.365, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4753, loss: 0.380, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4754, loss: 0.389, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4755, loss: 0.373, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4756, loss: 0.387, accuracy: 0.605, training set size: 3060\n",
      "Finished training for epoch 4757, loss: 0.370, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4758, loss: 0.379, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4759, loss: 0.376, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4760, loss: 0.382, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4761, loss: 0.384, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4762, loss: 0.369, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4763, loss: 0.365, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4764, loss: 0.379, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4765, loss: 0.379, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4766, loss: 0.377, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4767, loss: 0.376, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4768, loss: 0.369, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4769, loss: 0.387, accuracy: 0.608, training set size: 3060\n",
      "Finished training for epoch 4770, loss: 0.369, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4771, loss: 0.370, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4772, loss: 0.394, accuracy: 0.610, training set size: 3060\n",
      "Finished training for epoch 4773, loss: 0.371, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4774, loss: 0.380, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4775, loss: 0.361, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4776, loss: 0.372, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4777, loss: 0.368, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4778, loss: 0.379, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4779, loss: 0.365, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4780, loss: 0.362, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4781, loss: 0.372, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4782, loss: 0.375, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4783, loss: 0.368, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4784, loss: 0.368, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4785, loss: 0.358, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4786, loss: 0.373, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4787, loss: 0.373, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4788, loss: 0.389, accuracy: 0.610, training set size: 3060\n",
      "Finished training for epoch 4789, loss: 0.376, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4790, loss: 0.382, accuracy: 0.610, training set size: 3060\n",
      "Finished training for epoch 4791, loss: 0.371, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4792, loss: 0.375, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4793, loss: 0.365, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4794, loss: 0.378, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4795, loss: 0.396, accuracy: 0.607, training set size: 3060\n",
      "Finished training for epoch 4796, loss: 0.389, accuracy: 0.609, training set size: 3060\n",
      "Finished training for epoch 4797, loss: 0.364, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4798, loss: 0.376, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4799, loss: 0.365, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4800, loss: 0.394, accuracy: 0.605, training set size: 3060\n",
      "Finished training for epoch 4801, loss: 0.376, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4802, loss: 0.376, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4803, loss: 0.380, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4804, loss: 0.376, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4805, loss: 0.366, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4806, loss: 0.364, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4807, loss: 0.380, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4808, loss: 0.371, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4809, loss: 0.374, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4810, loss: 0.391, accuracy: 0.608, training set size: 3060\n",
      "Finished training for epoch 4811, loss: 0.397, accuracy: 0.608, training set size: 3060\n",
      "Finished training for epoch 4812, loss: 0.377, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4813, loss: 0.370, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4814, loss: 0.369, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4815, loss: 0.382, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4816, loss: 0.389, accuracy: 0.610, training set size: 3060\n",
      "Finished training for epoch 4817, loss: 0.385, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4818, loss: 0.390, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4819, loss: 0.387, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4820, loss: 0.373, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4821, loss: 0.365, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4822, loss: 0.383, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4823, loss: 0.371, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4824, loss: 0.366, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4825, loss: 0.376, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4826, loss: 0.378, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4827, loss: 0.366, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4828, loss: 0.376, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4829, loss: 0.387, accuracy: 0.608, training set size: 3060\n",
      "Finished training for epoch 4830, loss: 0.375, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4831, loss: 0.391, accuracy: 0.610, training set size: 3060\n",
      "Finished training for epoch 4832, loss: 0.370, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4833, loss: 0.376, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4834, loss: 0.378, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4835, loss: 0.361, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4836, loss: 0.363, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4837, loss: 0.368, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4838, loss: 0.370, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4839, loss: 0.389, accuracy: 0.608, training set size: 3060\n",
      "Finished training for epoch 4840, loss: 0.370, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4841, loss: 0.380, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4842, loss: 0.385, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4843, loss: 0.361, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4844, loss: 0.372, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4845, loss: 0.380, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4846, loss: 0.378, accuracy: 0.610, training set size: 3060\n",
      "Finished training for epoch 4847, loss: 0.359, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4848, loss: 0.391, accuracy: 0.602, training set size: 3060\n",
      "Finished training for epoch 4849, loss: 0.370, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4850, loss: 0.369, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4851, loss: 0.372, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4852, loss: 0.374, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4853, loss: 0.363, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4854, loss: 0.376, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4855, loss: 0.362, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4856, loss: 0.376, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4857, loss: 0.376, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4858, loss: 0.386, accuracy: 0.610, training set size: 3060\n",
      "Finished training for epoch 4859, loss: 0.373, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4860, loss: 0.364, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4861, loss: 0.372, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4862, loss: 0.381, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4863, loss: 0.366, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4864, loss: 0.387, accuracy: 0.608, training set size: 3060\n",
      "Finished training for epoch 4865, loss: 0.378, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4866, loss: 0.376, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4867, loss: 0.382, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4868, loss: 0.366, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4869, loss: 0.372, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4870, loss: 0.373, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4871, loss: 0.379, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4872, loss: 0.364, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4873, loss: 0.366, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4874, loss: 0.365, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4875, loss: 0.371, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4876, loss: 0.369, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4877, loss: 0.371, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4878, loss: 0.379, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4879, loss: 0.362, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4880, loss: 0.371, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4881, loss: 0.366, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4882, loss: 0.363, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4883, loss: 0.372, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4884, loss: 0.365, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4885, loss: 0.372, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4886, loss: 0.372, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4887, loss: 0.384, accuracy: 0.608, training set size: 3060\n",
      "Finished training for epoch 4888, loss: 0.354, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4889, loss: 0.376, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4890, loss: 0.366, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4891, loss: 0.390, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4892, loss: 0.371, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4893, loss: 0.362, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4894, loss: 0.372, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4895, loss: 0.367, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4896, loss: 0.365, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4897, loss: 0.385, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4898, loss: 0.371, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4899, loss: 0.366, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4900, loss: 0.381, accuracy: 0.610, training set size: 3060\n",
      "Finished training for epoch 4901, loss: 0.376, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4902, loss: 0.370, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4903, loss: 0.369, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4904, loss: 0.361, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4905, loss: 0.380, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4906, loss: 0.368, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4907, loss: 0.373, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4908, loss: 0.375, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4909, loss: 0.365, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4910, loss: 0.370, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 4911, loss: 0.393, accuracy: 0.603, training set size: 3060\n",
      "Finished training for epoch 4912, loss: 0.373, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4913, loss: 0.366, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4914, loss: 0.372, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4915, loss: 0.370, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4916, loss: 0.379, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4917, loss: 0.364, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4918, loss: 0.364, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4919, loss: 0.371, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4920, loss: 0.372, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4921, loss: 0.376, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4922, loss: 0.350, accuracy: 0.638, training set size: 3060\n",
      "Finished training for epoch 4923, loss: 0.369, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4924, loss: 0.402, accuracy: 0.604, training set size: 3060\n",
      "Finished training for epoch 4925, loss: 0.364, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4926, loss: 0.367, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4927, loss: 0.366, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4928, loss: 0.392, accuracy: 0.604, training set size: 3060\n",
      "Finished training for epoch 4929, loss: 0.378, accuracy: 0.613, training set size: 3060\n",
      "Finished training for epoch 4930, loss: 0.376, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4931, loss: 0.370, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4932, loss: 0.369, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4933, loss: 0.382, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4934, loss: 0.371, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4935, loss: 0.374, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4936, loss: 0.376, accuracy: 0.614, training set size: 3060\n",
      "Finished training for epoch 4937, loss: 0.367, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4938, loss: 0.385, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4939, loss: 0.399, accuracy: 0.630, training set size: 3060\n",
      "Finished training for epoch 4940, loss: 0.373, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4941, loss: 0.388, accuracy: 0.609, training set size: 3060\n",
      "Finished training for epoch 4942, loss: 0.375, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4943, loss: 0.357, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4944, loss: 0.369, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4945, loss: 0.357, accuracy: 0.633, training set size: 3060\n",
      "Finished training for epoch 4946, loss: 0.364, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4947, loss: 0.371, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4948, loss: 0.373, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4949, loss: 0.368, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4950, loss: 0.379, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4951, loss: 0.379, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4952, loss: 0.361, accuracy: 0.632, training set size: 3060\n",
      "Finished training for epoch 4953, loss: 0.359, accuracy: 0.629, training set size: 3060\n",
      "Finished training for epoch 4954, loss: 0.376, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4955, loss: 0.374, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4956, loss: 0.376, accuracy: 0.611, training set size: 3060\n",
      "Finished training for epoch 4957, loss: 0.368, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4958, loss: 0.378, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4959, loss: 0.371, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4960, loss: 0.373, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4961, loss: 0.376, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4962, loss: 0.372, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4963, loss: 0.375, accuracy: 0.616, training set size: 3060\n",
      "Finished training for epoch 4964, loss: 0.365, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4965, loss: 0.372, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4966, loss: 0.394, accuracy: 0.605, training set size: 3060\n",
      "Finished training for epoch 4967, loss: 0.368, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4968, loss: 0.368, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4969, loss: 0.393, accuracy: 0.609, training set size: 3060\n",
      "Finished training for epoch 4970, loss: 0.377, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4971, loss: 0.363, accuracy: 0.622, training set size: 3060\n",
      "Finished training for epoch 4972, loss: 0.358, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4973, loss: 0.357, accuracy: 0.632, training set size: 3060\n",
      "Finished training for epoch 4974, loss: 0.374, accuracy: 0.623, training set size: 3060\n",
      "Finished training for epoch 4975, loss: 0.367, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4976, loss: 0.361, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4977, loss: 0.366, accuracy: 0.624, training set size: 3060\n",
      "Finished training for epoch 4978, loss: 0.394, accuracy: 0.606, training set size: 3060\n",
      "Finished training for epoch 4979, loss: 0.393, accuracy: 0.602, training set size: 3060\n",
      "Finished training for epoch 4980, loss: 0.369, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4981, loss: 0.383, accuracy: 0.612, training set size: 3060\n",
      "Finished training for epoch 4982, loss: 0.378, accuracy: 0.620, training set size: 3060\n",
      "Finished training for epoch 4983, loss: 0.367, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4984, loss: 0.366, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4985, loss: 0.361, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4986, loss: 0.365, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4987, loss: 0.374, accuracy: 0.618, training set size: 3060\n",
      "Finished training for epoch 4988, loss: 0.361, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4989, loss: 0.379, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4990, loss: 0.366, accuracy: 0.626, training set size: 3060\n",
      "Finished training for epoch 4991, loss: 0.371, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4992, loss: 0.378, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4993, loss: 0.361, accuracy: 0.625, training set size: 3060\n",
      "Finished training for epoch 4994, loss: 0.386, accuracy: 0.615, training set size: 3060\n",
      "Finished training for epoch 4995, loss: 0.372, accuracy: 0.621, training set size: 3060\n",
      "Finished training for epoch 4996, loss: 0.360, accuracy: 0.628, training set size: 3060\n",
      "Finished training for epoch 4997, loss: 0.376, accuracy: 0.617, training set size: 3060\n",
      "Finished training for epoch 4998, loss: 0.369, accuracy: 0.619, training set size: 3060\n",
      "Finished training for epoch 4999, loss: 0.370, accuracy: 0.627, training set size: 3060\n",
      "Finished training for epoch 5000, loss: 0.401, accuracy: 0.607, training set size: 3060\n"
     ]
    }
   ],
   "source": [
    "net_adaptive = Net()\n",
    "ner_adaptive = train_model_custom_augmented(net_adaptive, dataset_uniform_train_modified, dataset_near_train_modified, 32, 5000, 0.001, best_magnitude, generate_close_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9988499879837036\n",
      "Accuracy: 0.7835000157356262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7835)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_modified(net_adaptive, dataset_uniform_test_modified)\n",
    "test_model_modified(net_adaptive, dataset_near_test_modified)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
